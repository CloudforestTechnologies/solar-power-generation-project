{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36664bitd546b3131dc04b45b27adb02c244c21c",
   "display_name": "Python 3.6.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "3f92393cf9312ed24f4ccae2fdf5dee1635074d2034ccfaec2d070f8b1ae4f04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "keras version = 2.4.0\nnumpy version = 1.19.4\nsklearn version = 0.22.2.post1\ntensorflow version = 2.4.1\n"
     ]
    }
   ],
   "source": [
    "# Module Importations\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "\n",
    "# Print versioning information\n",
    "print('keras version =', keras.__version__)\n",
    "print('numpy version =', np.__version__)  \n",
    "print('sklearn version =', sklearn.__version__)\n",
    "print('tensorflow version =', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[keras_helpers]Tensorflow version: 2.4.1\n[keras_helpers]keras version = 2.4.0\n"
     ]
    }
   ],
   "source": [
    "# Custom Module Imports\n",
    "from Source.data import load_data\n",
    "from Source.data import split_data\n",
    "from Source.models import model_evaluation\n",
    "from Source.models import keras_helpers\n",
    "from Source.models import tensorboard_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TRAIN_MODELS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading pickled dataframe started ...\n",
      "Loading pickled dataframe complete ...\n",
      "Loading pickled dataframe started ...\n",
      "Loading pickled dataframe complete ...\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df_plant1 = load_data.load_pickled_data(\"df_plant1_feat_eng.pkl\")\n",
    "df_plant2 = load_data.load_pickled_data(\"df_plant2_feat_eng.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 71808 entries, 0 to 71806\nData columns (total 20 columns):\n #   Column           Non-Null Count  Dtype         \n---  ------           --------------  -----         \n 0   DATE_TIME        71808 non-null  datetime64[ns]\n 1   PLANT_ID         71808 non-null  object        \n 2   SOURCE_KEY       71808 non-null  object        \n 3   DC_POWER         71808 non-null  float64       \n 4   DAILY_YIELD      71808 non-null  float64       \n 5   AMB_TEMP         71808 non-null  float64       \n 6   MOD_TEMP         71808 non-null  float64       \n 7   IRRADIATION      71808 non-null  float64       \n 8   DATE             71808 non-null  object        \n 9   TIME_OF_DAY      71808 non-null  object        \n 10  HOUR             71808 non-null  int64         \n 11  DAY              71808 non-null  int64         \n 12  WEEKDAY          71808 non-null  object        \n 13  MONTH            71808 non-null  int64         \n 14  YEAR             71808 non-null  int64         \n 15  AVG_HR_DC        71808 non-null  float64       \n 16  AVG_HR_YIELD     71808 non-null  float64       \n 17  AVG_DAILY_DC     71808 non-null  float64       \n 18  AVG_DAILY_YIELD  71808 non-null  float64       \n 19  DC-IRR_RATIO     71808 non-null  float64       \ndtypes: datetime64[ns](1), float64(10), int64(4), object(5)\nmemory usage: 11.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_plant1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 71808 entries, 0 to 71807\nData columns (total 4 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   DC_POWER     71808 non-null  float64\n 1   AMB_TEMP     71808 non-null  float64\n 2   MOD_TEMP     71808 non-null  float64\n 3   IRRADIATION  71808 non-null  float64\ndtypes: float64(4)\nmemory usage: 2.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Drop unrequired data columns\n",
    "\n",
    "# Identify columns to drop\n",
    "cols_to_keep = ['DC_POWER', 'AMB_TEMP', 'MOD_TEMP', 'IRRADIATION', 'TIME_FLOAT']\n",
    "cols_to_drop = []\n",
    "\n",
    "for col in df_plant1.columns:\n",
    "    if col not in cols_to_keep:\n",
    "        cols_to_drop.append(col)\n",
    "\n",
    "for df in [df_plant1, df_plant2]:\n",
    "    df.drop(cols_to_drop, axis = 1, inplace = True)\n",
    "\n",
    "df_plant2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original Data Items: 71808\n",
      "Training Data Items: 57447\n",
      "Evaluation Data Items: 14361\n",
      "Original Data Items: 71808\n",
      "Training Data Items: 57447\n",
      "Evaluation Data Items: 14361\n"
     ]
    }
   ],
   "source": [
    "# Split data into training / evaluation sets\n",
    "training_set_plant1, evaluation_set_plant1 = split_data.split_train_eval(df_plant1, 0.2)\n",
    "training_set_plant2, evaluation_set_plant2 = split_data.split_train_eval(df_plant2, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DC Power Target datasets\n",
    "\n",
    "# Modify training sets\n",
    "dc_power_training_data_pt1 = training_set_plant1.drop('DC_POWER', axis = 1)\n",
    "dc_label_data_pt1 = training_set_plant1['DC_POWER'].copy()\n",
    "\n",
    "dc_power_training_data_pt2 = training_set_plant2.drop('DC_POWER', axis = 1)\n",
    "dc_label_data_pt2 = training_set_plant2['DC_POWER'].copy()\n",
    "\n",
    "# Modify evaluation sets\n",
    "dc_evaluation_data_pt1 = evaluation_set_plant1.drop('DC_POWER', axis = 1)\n",
    "dc_eval_label_data_pt1 = evaluation_set_plant1['DC_POWER'].copy()\n",
    "\n",
    "dc_evaluation_data_pt2 = evaluation_set_plant2.drop('DC_POWER', axis = 1)\n",
    "dc_eval_label_data_pt2 = evaluation_set_plant2['DC_POWER'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Plant 1:\nFit Train: (57447, 3)\nFit Label: (57447,)\nEval Train: (14361, 3)\nEval Label: (14361,)\nPlant 2:\nFit Train: (57447, 3)\nFit Label: (57447,)\nEval Train: (14361, 3)\nEval Label: (14361,)\n"
     ]
    }
   ],
   "source": [
    "# Check shape of arrays\n",
    "print('Plant 1:')\n",
    "print('Fit Train:', dc_power_training_data_pt1.shape)\n",
    "print('Fit Label:', dc_label_data_pt1.shape)\n",
    "print('Eval Train:', dc_evaluation_data_pt1.shape)\n",
    "print('Eval Label:', dc_eval_label_data_pt1.shape)\n",
    "\n",
    "print('Plant 2:')\n",
    "print('Fit Train:', dc_power_training_data_pt2.shape)\n",
    "print('Fit Label:', dc_label_data_pt2.shape)\n",
    "print('Eval Train:', dc_evaluation_data_pt2.shape)\n",
    "print('Eval Label:', dc_eval_label_data_pt2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise Inputs\n",
    "normalise_inputs = True\n",
    "normalise_outputs = False\n",
    "\n",
    "normaliser = MinMaxScaler()\n",
    "\n",
    "if normalise_inputs == True:\n",
    "\n",
    "    # Transform training sets\n",
    "    dc_power_training_data_pt1 = normaliser.fit_transform(dc_power_training_data_pt1)\n",
    "    dc_power_training_data_pt2 = normaliser.fit_transform(dc_power_training_data_pt2)\n",
    "\n",
    "    # Transform evaluation sets\n",
    "    dc_evaluation_data_pt1 = normaliser.fit_transform(dc_evaluation_data_pt1)\n",
    "    dc_evaluation_data_pt2 = normaliser.fit_transform(dc_evaluation_data_pt2)\n",
    "\n",
    "if normalise_outputs == True:\n",
    "\n",
    "    # Transform training sets\n",
    "    dc_label_data_pt1 = normaliser.fit_transform(dc_label_data_pt1)\n",
    "    dc_label_data_pt2 = normaliser.fit_transform(dc_label_data_pt2)\n",
    "\n",
    "    # Transform evaluation sets\n",
    "    dc_eval_label_data_pt1 = normaliser.fit_transform(dc_eval_label_data_pt1)\n",
    "    dc_eval_label_data_pt2 = normaliser.fit_transform(dc_eval_label_data_pt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.69418927, 0.39836143, 0.24685468],\n",
       "       [0.10297219, 0.06348367, 0.02010156],\n",
       "       [0.10195445, 0.0510256 , 0.        ],\n",
       "       ...,\n",
       "       [0.3994604 , 0.20367104, 0.07955333],\n",
       "       [0.31878711, 0.09578908, 0.        ],\n",
       "       [0.45269604, 0.48094315, 0.44556097]])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Check values after normalisation\n",
    "dc_power_training_data_pt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.77310878 0.77031963 0.62255649]\n",
      " [0.31338184 0.08745068 0.        ]\n",
      " [0.26876718 0.23906034 0.09710624]\n",
      " ...\n",
      " [0.11465821 0.06056427 0.        ]\n",
      " [0.15250767 0.05541926 0.        ]\n",
      " [0.25835535 0.07128375 0.        ]]\n",
      "16030    936.842857\n",
      "4052       0.000000\n",
      "71148    178.350000\n",
      "71233    154.514286\n",
      "24592    414.100000\n",
      "            ...    \n",
      "14020    560.000000\n",
      "50198     31.471429\n",
      "65767      0.000000\n",
      "50797      0.000000\n",
      "12524      0.000000\n",
      "Name: DC_POWER, Length: 45957, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create train and test arrays (plant 1)\n",
    "X_train_pt1, X_test_pt1, y_train_pt1, y_test_pt1 = train_test_split(dc_power_training_data_pt1, dc_label_data_pt1, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(X_train_pt1)\n",
    "print(y_train_pt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Building Model ...\n",
      "Hidden Layers: 2, Neurons: 6, LR: 0.001\n",
      "Epoch 1/20\n",
      "1437/1437 [==============================] - 3s 1ms/step - loss: 253715.9745 - val_loss: 210553.7188\n",
      "Epoch 2/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 182256.8947 - val_loss: 88315.4531\n",
      "Epoch 3/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 74569.8966 - val_loss: 46883.3750\n",
      "Epoch 4/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 38563.2911 - val_loss: 17845.1660\n",
      "Epoch 5/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 12949.6395 - val_loss: 7484.0674\n",
      "Epoch 6/20\n",
      "1437/1437 [==============================] - 3s 2ms/step - loss: 6201.2936 - val_loss: 6066.8979\n",
      "Epoch 7/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 5295.5387 - val_loss: 5268.1426\n",
      "Epoch 8/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 4468.6744 - val_loss: 4745.0962\n",
      "Epoch 9/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 4475.4746 - val_loss: 4492.0659\n",
      "Epoch 10/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3986.4887 - val_loss: 4378.2529\n",
      "Epoch 11/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3751.5799 - val_loss: 4325.7764\n",
      "Epoch 12/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3836.6173 - val_loss: 4307.4307\n",
      "Epoch 13/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3786.3744 - val_loss: 4283.8467\n",
      "Epoch 14/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3681.8860 - val_loss: 4269.4331\n",
      "Epoch 15/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 4094.5145 - val_loss: 4254.2163\n",
      "Epoch 16/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3451.0076 - val_loss: 4240.5430\n",
      "Epoch 17/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3788.5061 - val_loss: 4208.8994\n",
      "Epoch 18/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3565.3403 - val_loss: 4195.9556\n",
      "Epoch 19/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3496.1314 - val_loss: 4169.1714\n",
      "Epoch 20/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3850.1174 - val_loss: 4152.5161\n"
     ]
    }
   ],
   "source": [
    "# Initial MLP (Target - DC Power, Plant 1)\n",
    "\n",
    "if TRAIN_MODELS == True:\n",
    "    # Clear existing models\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Build model\n",
    "    model = keras_helpers.build_multilayer_perceptron()\n",
    "\n",
    "    # Name model\n",
    "    model_type = \"MLP_DC_Plant1\"\n",
    "    model_id = keras_helpers.name_model(model_type)\n",
    "    filepath_full = keras_helpers.make_save_string(model_id)\n",
    "\n",
    "    # Set save and earlystop callbacks\n",
    "    earlystop_cb = keras.callbacks.EarlyStopping(patience = 5)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = filepath_full, save_best_only = True)\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train_pt1, y_train_pt1, epochs = 20, validation_data = (X_test_pt1, y_test_pt1), callbacks =[checkpoint_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 73\n",
      "Trainable params: 73\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "MLP_DC rmse (Eval): 58.986103785887295\n",
      "MLP_DC mae (Eval): 26.15867207226759\n",
      "MLP_DC r2 (Eval): 0.9781705984639255\n"
     ]
    }
   ],
   "source": [
    "# Evaluate MLP Model (DC Power, Plant 1)\n",
    "\n",
    "if TRAIN_MODELS == False:\n",
    "    filepath_full = r'C:\\Developer\\solar-power-generation-project\\Models\\WJ_MLP_DC_2021_01_13-16_10_50.h5'\n",
    "\n",
    "# Load model\n",
    "model = keras.models.load_model(filepath_full)\n",
    "\n",
    "# Summarise model\n",
    "model.summary()\n",
    "\n",
    "# Make predictions\n",
    "dc_pred_eval = model.predict(dc_evaluation_data_pt1)\n",
    "\n",
    "# Determine model prediction stats\n",
    "model_name = \"MLP_DC_Plant1\"\n",
    "model_evaluation.evaluate_model(model_name, dc_eval_label_data_pt1, dc_pred_eval)\n",
    "rmse, mae, r2 = model_evaluation.return_model_evaluation_stats(dc_eval_label_data_pt1, dc_pred_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "c:\\Developer\\solar-power-generation-project\\Models\\TensorBoard\\run_2021_06_08-11_05_48\n"
     ]
    }
   ],
   "source": [
    "# Setup tensorboard for logging \n",
    "x = tensorboard_helpers.get_run_logdir()\n",
    "\n",
    "# Print tensorboard directory\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 43, LR: 0.01\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 4s 3ms/step - loss: 72423.5390 - val_loss: 38929.5820\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 9041.2308 - val_loss: 3940.3416\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 6254.1341 - val_loss: 4199.5493\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 5234.8638 - val_loss: 26148.3945\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4838.0796 - val_loss: 4940.4219\n",
      "479/479 [==============================] - 1s 3ms/step - loss: 5010.5513\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 43, LR: 0.01\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 7s 4ms/step - loss: 69977.1646 - val_loss: 29090.7969\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 10141.1780 - val_loss: 10075.1426\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 7118.5662 - val_loss: 5793.7896\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 5771.4671 - val_loss: 5690.9438\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 5440.6926 - val_loss: 4750.3105\n",
      "Epoch 6/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 5396.2720 - val_loss: 3617.1689\n",
      "Epoch 7/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4830.4516 - val_loss: 5260.3340\n",
      "Epoch 8/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4775.2792 - val_loss: 4542.9624\n",
      "Epoch 9/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4065.5070 - val_loss: 7612.1538\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 7241.5571\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 43, LR: 0.01\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 4s 2ms/step - loss: 63518.2463 - val_loss: 18104.3574\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 10144.0174 - val_loss: 6959.2075\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 6496.3730 - val_loss: 3802.5869\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 5704.9162 - val_loss: 4362.2656\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 5104.7653 - val_loss: 6952.1914\n",
      "Epoch 6/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4529.7353 - val_loss: 4485.9277\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 3650.2188\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 33, LR: 0.01\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 4s 3ms/step - loss: 50653.0249 - val_loss: 6174.8579\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 9490.9189 - val_loss: 5451.6016\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 6639.6773 - val_loss: 29031.8203\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 5821.5586 - val_loss: 10644.8086\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 5130.3213 - val_loss: 3720.6941\n",
      "Epoch 6/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4505.1414 - val_loss: 3901.3557\n",
      "Epoch 7/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4261.0017 - val_loss: 5177.9375\n",
      "Epoch 8/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4336.0396 - val_loss: 4285.3745\n",
      "479/479 [==============================] - 0s 913us/step - loss: 4242.1943\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 33, LR: 0.01\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 4s 3ms/step - loss: 50121.0873 - val_loss: 5890.6904\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 3s 4ms/step - loss: 10395.1234 - val_loss: 4049.8513\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 6824.0955 - val_loss: 3991.3921\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 5964.8168 - val_loss: 4639.2334\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4917.4734 - val_loss: 6096.9072\n",
      "Epoch 6/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4293.0490 - val_loss: 5433.0288\n",
      "479/479 [==============================] - 0s 923us/step - loss: 4788.7251\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 33, LR: 0.01\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 3s 2ms/step - loss: 65336.8523 - val_loss: 18500.2422\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 10452.8900 - val_loss: 4519.4355\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 6041.0191 - val_loss: 14299.7197\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 5481.2806 - val_loss: 6239.1714\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4855.3578 - val_loss: 8391.3418\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 7711.7476\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 54, LR: 0.001\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 4s 3ms/step - loss: 31353.9900 - val_loss: 3843.1770\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4644.0690 - val_loss: 4757.6616\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 2s 3ms/step - loss: 4365.0398 - val_loss: 3642.1245\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 4523.9533 - val_loss: 5169.4316\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4187.6272 - val_loss: 3543.7771\n",
      "Epoch 6/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4335.7750 - val_loss: 12061.8389\n",
      "Epoch 7/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4009.1622 - val_loss: 5652.8008\n",
      "Epoch 8/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3725.9668 - val_loss: 6460.2993\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 6427.6729\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 54, LR: 0.001\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 4s 3ms/step - loss: 33546.7173 - val_loss: 3999.2859\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 5112.9710 - val_loss: 6080.8110\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 5283.9785 - val_loss: 3727.6353\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 4s 4ms/step - loss: 5188.9038 - val_loss: 7478.5566\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 4s 4ms/step - loss: 4840.8128 - val_loss: 7258.6060\n",
      "Epoch 6/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 4399.1654 - val_loss: 3684.4585\n",
      "Epoch 7/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4167.6296 - val_loss: 3878.2607\n",
      "Epoch 8/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4748.2333 - val_loss: 4388.1064\n",
      "Epoch 9/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4696.6849 - val_loss: 3739.9834\n",
      "479/479 [==============================] - 0s 991us/step - loss: 3063.4507\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 54, LR: 0.001\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 4s 3ms/step - loss: 37451.5125 - val_loss: 3764.3335\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4958.8496 - val_loss: 3857.3442\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4874.9492 - val_loss: 5623.8203\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4412.0395 - val_loss: 4043.8081\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 3133.0806\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 88, LR: 0.0001\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 4s 3ms/step - loss: 147756.0131 - val_loss: 4613.1191\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 3188.6088 - val_loss: 3836.6155\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 3093.1977 - val_loss: 3851.9380\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 3111.1812 - val_loss: 4669.9697\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 3352.6482 - val_loss: 4052.3091\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 4000.5334\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 88, LR: 0.0001\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 5s 4ms/step - loss: 133936.5544 - val_loss: 4518.4707\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 4152.6552 - val_loss: 3957.1377\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 3343.2084 - val_loss: 3717.9341\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 3076.1255 - val_loss: 3684.6401\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 3237.9590 - val_loss: 3650.3010\n",
      "Epoch 6/100\n",
      "958/958 [==============================] - 4s 5ms/step - loss: 3595.3218 - val_loss: 3652.3079\n",
      "Epoch 7/100\n",
      "958/958 [==============================] - 4s 4ms/step - loss: 3451.1384 - val_loss: 3865.6880\n",
      "Epoch 8/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 3103.0822 - val_loss: 4916.6084\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 4329.5938\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 88, LR: 0.0001\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 4s 3ms/step - loss: 137636.6733 - val_loss: 4173.1260\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 3539.3338 - val_loss: 3740.3081\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 3447.1647 - val_loss: 3674.7358\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 3223.7878 - val_loss: 3644.2615\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 3269.9985 - val_loss: 3688.8025\n",
      "Epoch 6/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 3316.3299 - val_loss: 3764.0811\n",
      "Epoch 7/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 3174.9751 - val_loss: 3571.9990\n",
      "Epoch 8/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 3431.5748 - val_loss: 3576.2910\n",
      "Epoch 9/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 3934.9466 - val_loss: 3591.2793\n",
      "Epoch 10/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 3339.1172 - val_loss: 3818.9390\n",
      "479/479 [==============================] - 0s 946us/step - loss: 2936.8928\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 14, LR: 0.0001\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 4s 3ms/step - loss: 252133.5668 - val_loss: 241726.9688\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 210343.3353 - val_loss: 67623.9219\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 58149.3785 - val_loss: 30816.6191\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 22383.8670 - val_loss: 9885.4268\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 8521.4378 - val_loss: 7442.0269\n",
      "Epoch 6/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 5905.7083 - val_loss: 5986.1592\n",
      "Epoch 7/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 5048.8936 - val_loss: 5067.4541\n",
      "Epoch 8/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4065.2652 - val_loss: 4512.8823\n",
      "Epoch 9/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 3645.7681 - val_loss: 4336.9771\n",
      "Epoch 10/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3529.5400 - val_loss: 4264.7319\n",
      "Epoch 11/100\n",
      "958/958 [==============================] - 1s 2ms/step - loss: 3492.7397 - val_loss: 4226.5757\n",
      "Epoch 12/100\n",
      "958/958 [==============================] - 1s 1ms/step - loss: 3344.2341 - val_loss: 4262.3057\n",
      "Epoch 13/100\n",
      "958/958 [==============================] - 1s 1ms/step - loss: 3388.8578 - val_loss: 4225.7637\n",
      "Epoch 14/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3371.1783 - val_loss: 4113.1592\n",
      "Epoch 15/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3309.7168 - val_loss: 4183.9902\n",
      "Epoch 16/100\n",
      "958/958 [==============================] - 2s 3ms/step - loss: 3650.0154 - val_loss: 4052.0222\n",
      "Epoch 17/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3243.7055 - val_loss: 4027.2097\n",
      "Epoch 18/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 2990.4444 - val_loss: 3978.9014\n",
      "Epoch 19/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3099.8909 - val_loss: 3977.7336\n",
      "Epoch 20/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 2897.4460 - val_loss: 3929.0574\n",
      "Epoch 21/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3197.3497 - val_loss: 3957.9993\n",
      "Epoch 22/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3013.0906 - val_loss: 3887.3660\n",
      "Epoch 23/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3200.3668 - val_loss: 3872.7280\n",
      "Epoch 24/100\n",
      "958/958 [==============================] - 2s 3ms/step - loss: 3054.4832 - val_loss: 3855.9905\n",
      "Epoch 25/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3011.6348 - val_loss: 3828.8428\n",
      "Epoch 26/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 2763.0169 - val_loss: 3796.9639\n",
      "Epoch 27/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 2951.7363 - val_loss: 3795.5186\n",
      "Epoch 28/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 2903.3603 - val_loss: 3765.4998\n",
      "Epoch 29/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3078.5379 - val_loss: 3755.3232\n",
      "Epoch 30/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 2866.5205 - val_loss: 3758.3582\n",
      "Epoch 31/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3179.0744 - val_loss: 3758.1235\n",
      "Epoch 32/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 2966.5866 - val_loss: 3732.5950\n",
      "Epoch 33/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3129.9284 - val_loss: 3698.4236\n",
      "Epoch 34/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 2706.4941 - val_loss: 3732.3022\n",
      "Epoch 35/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 2907.9971 - val_loss: 3666.2749\n",
      "Epoch 36/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 2780.9010 - val_loss: 3686.4326\n",
      "Epoch 37/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 2930.6289 - val_loss: 3702.5654\n",
      "Epoch 38/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 2916.1244 - val_loss: 3644.5237\n",
      "Epoch 39/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 2842.8145 - val_loss: 3637.3635\n",
      "Epoch 40/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 2762.5567 - val_loss: 3638.1938\n",
      "Epoch 41/100\n",
      "958/958 [==============================] - 2s 3ms/step - loss: 3043.4530 - val_loss: 3624.5486\n",
      "Epoch 42/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3077.7215 - val_loss: 3622.3035\n",
      "Epoch 43/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 2724.8879 - val_loss: 3645.0193\n",
      "Epoch 44/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 2712.1516 - val_loss: 3622.9668\n",
      "Epoch 45/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 2769.1335 - val_loss: 3598.1514\n",
      "Epoch 46/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 2712.6172 - val_loss: 3598.2878\n",
      "Epoch 47/100\n",
      "958/958 [==============================] - 1s 2ms/step - loss: 2891.3506 - val_loss: 3598.7419\n",
      "Epoch 48/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 2880.4623 - val_loss: 3628.8555\n",
      "479/479 [==============================] - 0s 863us/step - loss: 3544.4260\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 14, LR: 0.0001\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 4s 3ms/step - loss: 252673.9516 - val_loss: 252178.1875\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 242928.8609 - val_loss: 163818.2812\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 114971.4088 - val_loss: 58882.5664\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 44711.7838 - val_loss: 9222.6582\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 6540.2245 - val_loss: 4621.4067\n",
      "Epoch 6/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4278.4082 - val_loss: 3924.9121\n",
      "Epoch 7/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3405.1833 - val_loss: 3861.9111\n",
      "Epoch 8/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3100.8073 - val_loss: 3758.6299\n",
      "Epoch 9/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3091.0832 - val_loss: 3768.4331\n",
      "Epoch 10/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3135.0051 - val_loss: 3751.3911\n",
      "Epoch 11/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3744.6428 - val_loss: 3701.5752\n",
      "Epoch 12/100\n",
      "958/958 [==============================] - 1s 2ms/step - loss: 3174.5378 - val_loss: 3680.6987\n",
      "Epoch 13/100\n",
      "958/958 [==============================] - 1s 2ms/step - loss: 3787.8425 - val_loss: 3639.4573\n",
      "Epoch 14/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3029.9186 - val_loss: 3649.9475\n",
      "Epoch 15/100\n",
      "958/958 [==============================] - 1s 2ms/step - loss: 3082.4120 - val_loss: 3665.6528\n",
      "Epoch 16/100\n",
      "958/958 [==============================] - 1s 2ms/step - loss: 3679.4948 - val_loss: 3608.1919\n",
      "Epoch 17/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3319.8873 - val_loss: 3599.9258\n",
      "Epoch 18/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 2967.4196 - val_loss: 3602.5378\n",
      "Epoch 19/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 2966.7349 - val_loss: 3590.4133\n",
      "Epoch 20/100\n",
      "958/958 [==============================] - 1s 2ms/step - loss: 3150.1184 - val_loss: 3622.3782\n",
      "Epoch 21/100\n",
      "958/958 [==============================] - 1s 2ms/step - loss: 2990.0945 - val_loss: 3734.6389\n",
      "Epoch 22/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3050.9223 - val_loss: 3619.1582\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 2940.9250\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 14, LR: 0.0001\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 5s 3ms/step - loss: 251928.5822 - val_loss: 223614.1719\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 163723.1144 - val_loss: 48583.4297\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 30074.3430 - val_loss: 4661.4102\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4076.9684 - val_loss: 4154.1953\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3685.1835 - val_loss: 4080.1472\n",
      "Epoch 6/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3343.4613 - val_loss: 4041.8718\n",
      "Epoch 7/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3683.5337 - val_loss: 4074.5989\n",
      "Epoch 8/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3461.1434 - val_loss: 3955.3372\n",
      "Epoch 9/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3795.7626 - val_loss: 3854.3350\n",
      "Epoch 10/100\n",
      "958/958 [==============================] - 1s 2ms/step - loss: 3570.3521 - val_loss: 3798.6162\n",
      "Epoch 11/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3339.7780 - val_loss: 3757.2490\n",
      "Epoch 12/100\n",
      "958/958 [==============================] - 1s 2ms/step - loss: 3403.9440 - val_loss: 3719.1890\n",
      "Epoch 13/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3276.6278 - val_loss: 3691.9834\n",
      "Epoch 14/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3622.1579 - val_loss: 3712.8887\n",
      "Epoch 15/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3537.1537 - val_loss: 3645.4280\n",
      "Epoch 16/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3093.0040 - val_loss: 3629.5586\n",
      "Epoch 17/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3424.0733 - val_loss: 3618.7756\n",
      "Epoch 18/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3298.3996 - val_loss: 3614.0222\n",
      "Epoch 19/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3449.6241 - val_loss: 3599.7639\n",
      "Epoch 20/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3624.5655 - val_loss: 3584.7031\n",
      "Epoch 21/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3206.0945 - val_loss: 3668.6541\n",
      "Epoch 22/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3339.9798 - val_loss: 3603.4043\n",
      "Epoch 23/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3123.5338 - val_loss: 3579.4868\n",
      "Epoch 24/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3222.1618 - val_loss: 3601.2366\n",
      "Epoch 25/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 2953.4226 - val_loss: 3592.1604\n",
      "Epoch 26/100\n",
      "958/958 [==============================] - 1s 2ms/step - loss: 3205.6296 - val_loss: 3573.5889\n",
      "Epoch 27/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3489.7988 - val_loss: 3555.0039\n",
      "Epoch 28/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3535.8951 - val_loss: 3590.5793\n",
      "Epoch 29/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 2785.4986 - val_loss: 3574.9519\n",
      "Epoch 30/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 2971.9749 - val_loss: 3548.6274\n",
      "Epoch 31/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3741.5763 - val_loss: 3733.5806\n",
      "Epoch 32/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3023.0926 - val_loss: 3615.3823\n",
      "Epoch 33/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 3611.8480 - val_loss: 3570.0049\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 2702.7454\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 16, LR: 0.1\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 6s 3ms/step - loss: 6777785.5414 - val_loss: 160590.7969\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 162820.2177 - val_loss: 168539.7812\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 2s 3ms/step - loss: 162022.0423 - val_loss: 160643.1875\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 163107.9447 - val_loss: 163306.2812\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 163061.0781\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 16, LR: 0.1\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 4s 2ms/step - loss: 1935062.9177 - val_loss: 165100.0000\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 162849.3462 - val_loss: 161753.2031\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 162447.8029 - val_loss: 164649.8281\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 162758.4660 - val_loss: 161441.1406\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 161378.6890 - val_loss: 161290.5469\n",
      "Epoch 6/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 163652.2434 - val_loss: 160574.5781\n",
      "Epoch 7/100\n",
      "958/958 [==============================] - 1s 2ms/step - loss: 160277.4236 - val_loss: 161161.0938\n",
      "Epoch 8/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 159205.2625 - val_loss: 162450.7031\n",
      "Epoch 9/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 162211.9448 - val_loss: 160585.5625\n",
      "479/479 [==============================] - 0s 825us/step - loss: 161526.5625\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 16, LR: 0.1\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 3s 2ms/step - loss: 256902216.9035 - val_loss: 160857.5000\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 163418.6183 - val_loss: 160575.7500\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 161245.7301 - val_loss: 165064.5938\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 161062.7028 - val_loss: 161293.8281\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 162516.5412 - val_loss: 160671.6250\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 160980.7188\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 69, LR: 0.001\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 4s 3ms/step - loss: 31835.2457 - val_loss: 4291.5581\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 5129.6209 - val_loss: 12969.5635\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 5216.2037 - val_loss: 4560.9580\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 4982.9434 - val_loss: 3576.0386\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 4721.9355 - val_loss: 4048.5994\n",
      "Epoch 6/100\n",
      "958/958 [==============================] - 4s 4ms/step - loss: 4424.6694 - val_loss: 4437.4668\n",
      "Epoch 7/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 4064.8407 - val_loss: 4063.1614\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 3959.9377\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 69, LR: 0.001\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 5s 4ms/step - loss: 35366.8920 - val_loss: 5910.9199\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 5811.8127 - val_loss: 10486.9375\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 5334.8759 - val_loss: 8136.5132\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 5333.8544 - val_loss: 4042.3655\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 4594.6318 - val_loss: 10842.6250\n",
      "Epoch 6/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 5173.3622 - val_loss: 6924.9150\n",
      "Epoch 7/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 4445.9365 - val_loss: 4856.9497\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 4270.8657\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 69, LR: 0.001\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 5s 4ms/step - loss: 26040.7642 - val_loss: 3753.8857\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 5649.1532 - val_loss: 12008.4287\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 5335.2414 - val_loss: 6748.4277\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 4906.1340 - val_loss: 3722.9521\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 4799.9785 - val_loss: 3760.1223\n",
      "Epoch 6/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4681.6028 - val_loss: 4155.1763\n",
      "Epoch 7/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4707.0450 - val_loss: 9823.5264\n",
      "479/479 [==============================] - 0s 992us/step - loss: 8903.0479\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 7, LR: 0.01\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 3s 2ms/step - loss: 253438.8905 - val_loss: 247554.0781\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 247660.9163 - val_loss: 242141.8438\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 243855.8979 - val_loss: 236934.2812\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 240608.3527 - val_loss: 231912.8125\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 2s 3ms/step - loss: 239204.7670 - val_loss: 227061.7031\n",
      "Epoch 6/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 228581.9547 - val_loss: 222404.0938\n",
      "Epoch 7/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 221648.8093 - val_loss: 217905.5938\n",
      "Epoch 8/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 220304.0591 - val_loss: 213603.9219\n",
      "Epoch 9/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 216169.4663 - val_loss: 209478.8906\n",
      "Epoch 10/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 210093.6731 - val_loss: 205553.1406\n",
      "Epoch 11/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 206072.8569 - val_loss: 201795.2812\n",
      "Epoch 12/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 201991.8885 - val_loss: 198236.9375\n",
      "Epoch 13/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 197306.2877 - val_loss: 194834.0938\n",
      "Epoch 14/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 197786.1600 - val_loss: 191634.6562\n",
      "Epoch 15/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 192640.0554 - val_loss: 188603.3281\n",
      "Epoch 16/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 189219.8829 - val_loss: 185758.2969\n",
      "Epoch 17/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 186402.0576 - val_loss: 183092.2969\n",
      "Epoch 18/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 183915.7274 - val_loss: 180610.0938\n",
      "Epoch 19/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 183432.6202 - val_loss: 178279.4844\n",
      "Epoch 20/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 179735.6262 - val_loss: 176105.3125\n",
      "Epoch 21/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 175585.8450 - val_loss: 174151.8125\n",
      "Epoch 22/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 174401.8160 - val_loss: 172316.4531\n",
      "Epoch 23/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 173498.3219 - val_loss: 170661.8281\n",
      "Epoch 24/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 170835.2138 - val_loss: 169178.0312\n",
      "Epoch 25/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 170569.1447 - val_loss: 167833.0469\n",
      "Epoch 26/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 169301.8089 - val_loss: 166673.2656\n",
      "Epoch 27/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 164157.7574 - val_loss: 165657.5000\n",
      "Epoch 28/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 167858.0090 - val_loss: 164762.3438\n",
      "Epoch 29/100\n",
      "958/958 [==============================] - 1s 1ms/step - loss: 165695.3851 - val_loss: 163963.8750\n",
      "Epoch 30/100\n",
      "958/958 [==============================] - 1s 1ms/step - loss: 167657.8191 - val_loss: 163311.7656\n",
      "Epoch 31/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 166576.8839 - val_loss: 162770.7031\n",
      "Epoch 32/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 163714.5719 - val_loss: 162298.1406\n",
      "Epoch 33/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 162332.0165 - val_loss: 161924.2812\n",
      "Epoch 34/100\n",
      "958/958 [==============================] - 4s 4ms/step - loss: 162018.0176 - val_loss: 161629.5625\n",
      "Epoch 35/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 160606.4597 - val_loss: 161390.2812\n",
      "Epoch 36/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 161256.9966 - val_loss: 161200.5000\n",
      "Epoch 37/100\n",
      "958/958 [==============================] - 1s 1ms/step - loss: 161838.4748 - val_loss: 161049.1719\n",
      "Epoch 38/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 161500.2540 - val_loss: 160934.8906\n",
      "Epoch 39/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 160400.2899 - val_loss: 160844.9062\n",
      "Epoch 40/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 162264.0290 - val_loss: 160777.1562\n",
      "Epoch 41/100\n",
      "958/958 [==============================] - 1s 1ms/step - loss: 161906.9084 - val_loss: 160726.6875\n",
      "Epoch 42/100\n",
      "958/958 [==============================] - 1s 2ms/step - loss: 160557.8361 - val_loss: 160687.3281\n",
      "Epoch 43/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 161781.2207 - val_loss: 160656.7812\n",
      "Epoch 44/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 162244.0359 - val_loss: 160632.6406\n",
      "Epoch 45/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 161017.3266 - val_loss: 160615.5312\n",
      "Epoch 46/100\n",
      "958/958 [==============================] - 1s 2ms/step - loss: 160961.1540 - val_loss: 160602.2969\n",
      "Epoch 47/100\n",
      "958/958 [==============================] - 1s 1ms/step - loss: 160247.5965 - val_loss: 160593.0312\n",
      "Epoch 48/100\n",
      "958/958 [==============================] - 1s 2ms/step - loss: 161209.3894 - val_loss: 160586.9219\n",
      "Epoch 49/100\n",
      "958/958 [==============================] - 1s 1ms/step - loss: 160573.9106 - val_loss: 160582.1562\n",
      "Epoch 50/100\n",
      "958/958 [==============================] - 1s 2ms/step - loss: 162197.9381 - val_loss: 160579.2031\n",
      "Epoch 51/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 159813.4258 - val_loss: 160576.8438\n",
      "Epoch 52/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 160931.2087 - val_loss: 160575.1250\n",
      "Epoch 53/100\n",
      "958/958 [==============================] - 1s 2ms/step - loss: 161814.6847 - val_loss: 160574.0469\n",
      "Epoch 54/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 161250.0841 - val_loss: 160573.5625\n",
      "Epoch 55/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 161317.6050 - val_loss: 160573.4219\n",
      "Epoch 56/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 160831.8314 - val_loss: 160573.4688\n",
      "Epoch 57/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 157758.7447 - val_loss: 160573.7344\n",
      "Epoch 58/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 160207.0000 - val_loss: 160573.8750\n",
      "479/479 [==============================] - 0s 887us/step - loss: 160671.1562\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 7, LR: 0.01\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 4s 3ms/step - loss: 198456.2884 - val_loss: 160683.9375\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 159617.9158 - val_loss: 160669.9375\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 161157.8781 - val_loss: 161349.3594\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 159921.2234 - val_loss: 161353.0625\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 160477.3989 - val_loss: 160580.9844\n",
      "Epoch 6/100\n",
      "958/958 [==============================] - 3s 4ms/step - loss: 159573.7726 - val_loss: 160625.8594\n",
      "Epoch 7/100\n",
      "958/958 [==============================] - 4s 4ms/step - loss: 162717.4138 - val_loss: 160573.3750\n",
      "Epoch 8/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 161174.4487 - val_loss: 160575.7812\n",
      "Epoch 9/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 160909.8324 - val_loss: 160622.7812\n",
      "Epoch 10/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 159277.0925 - val_loss: 160752.9531\n",
      "479/479 [==============================] - 0s 865us/step - loss: 161616.6875\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 7, LR: 0.01\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 4s 2ms/step - loss: 48667.4620 - val_loss: 5726.5752\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 6167.2233 - val_loss: 4282.0747\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 6150.5114 - val_loss: 18702.2402\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 5556.2861 - val_loss: 6950.6465\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 5295.0382 - val_loss: 15220.8984\n",
      "479/479 [==============================] - 0s 893us/step - loss: 14556.0391\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 64, LR: 0.001\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 4s 3ms/step - loss: 34476.1293 - val_loss: 3686.9644\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 2s 3ms/step - loss: 5524.8923 - val_loss: 4295.0640\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 2s 3ms/step - loss: 4639.7583 - val_loss: 6119.2124\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 5030.3009 - val_loss: 6227.0615\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 6174.5986\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 64, LR: 0.001\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 4s 3ms/step - loss: 28910.4924 - val_loss: 4025.3665\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 2s 3ms/step - loss: 5539.4481 - val_loss: 4099.4658\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 5110.1559 - val_loss: 4551.0254\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4572.8386 - val_loss: 3576.8977\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 5181.7402 - val_loss: 3887.4509\n",
      "Epoch 6/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4904.9416 - val_loss: 5581.0117\n",
      "Epoch 7/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4468.1987 - val_loss: 4738.0356\n",
      "479/479 [==============================] - 0s 999us/step - loss: 3931.8530\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 64, LR: 0.001\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 4s 3ms/step - loss: 29114.7234 - val_loss: 3739.9390\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 3s 3ms/step - loss: 5597.7816 - val_loss: 8256.5605\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 4s 4ms/step - loss: 5264.1362 - val_loss: 4000.8147\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 4s 4ms/step - loss: 5187.0947 - val_loss: 4225.3062\n",
      "479/479 [==============================] - 1s 2ms/step - loss: 3355.0762\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 12, LR: 0.01\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 3s 2ms/step - loss: 28305.9214 - val_loss: 4104.6714\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 9071.3256 - val_loss: 8145.9746\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 8141.2844 - val_loss: 50467.4766\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 7056.9510 - val_loss: 11374.2480\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 11379.4355\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 12, LR: 0.01\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 3s 2ms/step - loss: 30573.3040 - val_loss: 3871.5134\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 9529.4538 - val_loss: 7824.0474\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 7567.2368 - val_loss: 4790.7393\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 6150.3812 - val_loss: 3580.5420\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 5514.1082 - val_loss: 19935.0566\n",
      "Epoch 6/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4935.6228 - val_loss: 3866.1204\n",
      "Epoch 7/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4588.1894 - val_loss: 5314.9810\n",
      "479/479 [==============================] - 0s 836us/step - loss: 4565.9331\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 12, LR: 0.01\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 4s 3ms/step - loss: 31450.0490 - val_loss: 4403.5908\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 8494.5338 - val_loss: 4822.5947\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 7262.5594 - val_loss: 3724.5876\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 6859.7615 - val_loss: 8352.8330\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 6005.6767 - val_loss: 12419.7236\n",
      "Epoch 6/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 5789.4295 - val_loss: 3723.6116\n",
      "Epoch 7/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 5005.7535 - val_loss: 4282.6250\n",
      "Epoch 8/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 5276.0810 - val_loss: 3595.2979\n",
      "Epoch 9/100\n",
      "958/958 [==============================] - 2s 2ms/step - loss: 4861.6202 - val_loss: 4644.1411\n",
      "Epoch 10/100\n",
      "958/958 [==============================] - 1s 2ms/step - loss: 4412.6717 - val_loss: 3551.4966\n",
      "Epoch 11/100\n",
      "958/958 [==============================] - 1s 2ms/step - loss: 4816.1794 - val_loss: 13700.0830\n",
      "Epoch 12/100\n",
      "958/958 [==============================] - 1s 2ms/step - loss: 4138.3000 - val_loss: 3930.7224\n",
      "Epoch 13/100\n",
      "958/958 [==============================] - 2s 3ms/step - loss: 4311.7754 - val_loss: 3973.6851\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 3181.7283\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x0000024A791FC1D0>, as the constructor either does not set or modifies parameter n_neurons",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-b4b3da082ca3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# Train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mrnd_search_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_pt1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_pt1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test_pt1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_pt1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcheckpoint_cb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearlystop_cb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensorboard_cb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Developer\\Python\\Python366\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m             \u001b[1;31m# of the params are estimators as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[1;32m--> 736\u001b[1;33m                 **self.best_params_))\n\u001b[0m\u001b[0;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Developer\\Python\\Python366\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     80\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0;32m     81\u001b[0m                                \u001b[1;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m                                (estimator, name))\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x0000024A791FC1D0>, as the constructor either does not set or modifies parameter n_neurons"
     ]
    }
   ],
   "source": [
    "# Optimised MLP (Target - DC Power, Plant 1)\n",
    "\n",
    "if TRAIN_MODELS == True:\n",
    "    \n",
    "    # Clear existing models\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Establish parameter distribution for tuning\n",
    "    param_distribs = {\n",
    "        \"n_hidden\":[12],\n",
    "        \"n_neurons\": np.arange(1, 100),\n",
    "        \"learning_rate\": [1e-1, 1e-2, 1e-3, 1e-4],\n",
    "    }\n",
    "\n",
    "    # Build model\n",
    "    wrapped_model = keras_helpers.wrap_model()\n",
    "\n",
    "    # Initialise random search\n",
    "    rnd_search_cv = RandomizedSearchCV(wrapped_model, param_distribs, n_iter = 10, cv = 3)\n",
    "\n",
    "    # Name model\n",
    "    model_type = \"MLP_Opt_DC_Plant1\"\n",
    "    model_id = keras_helpers.name_model(model_type)\n",
    "    filepath_full = keras_helpers.make_save_string(model_id)\n",
    "\n",
    "    # Set save and earlystop callbacks\n",
    "    earlystop_cb = keras.callbacks.EarlyStopping(patience = 3)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = filepath_full, save_best_only = True)\n",
    "\n",
    "    # Set TensorBoard callback for logging\n",
    "    tb_logdir = tensorboard_helpers.get_run_logdir()\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(tb_logdir)\n",
    "\n",
    "    # Train model\n",
    "    rnd_search_cv.fit(X_train_pt1, y_train_pt1, epochs = 100, validation_data = (X_test_pt1, y_test_pt1), callbacks = [checkpoint_cb, earlystop_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_169 (Dense)            (None, 40)                280       \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 8,521\n",
      "Trainable params: 8,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "MLP_Opt_DC rmse (Eval): 1155.8620532143577\n",
      "MLP_Opt_DC mae (Eval): 545.58045225204\n",
      "MLP_Opt_DC r2 (Eval): 0.9181278609504048\n",
      "MLP_Opt_DC % Acc: 91.10875343681263\n"
     ]
    }
   ],
   "source": [
    "# Evaluate MLP Model (DC Power, Plant 1)\n",
    "\n",
    "if TRAIN_MODELS == False:\n",
    "    filepath_full = r'C:\\Developer\\solar-power-generation-project\\Models\\WJ_MLP_Opt_DC_2021_01_13-15_30_27.h5'\n",
    "\n",
    "wrapped_model = keras.models.load_model(filepath_full)\n",
    "\n",
    "# Summarise model\n",
    "wrapped_model.summary()\n",
    "\n",
    "# Make predictions\n",
    "dc_pred_eval = wrapped_model.predict(dc_evaluation_data)\n",
    "\n",
    "model_name = \"MLP_Opt_DC_pt1\"\n",
    "model_evaluation.evaluate_model(model_name, dc_eval_label_data_pt1, dc_pred_eval)\n",
    "rmse, mae, r2 = model_evaluation.return_model_evaluation_stats(dc_eval_label_data_pt1, dc_pred_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial MLP (Target - DC Power, Plant 2)\n",
    "\n",
    "if TRAIN_MODELS == True:\n",
    "    \n",
    "    # Clear existing models\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Build model\n",
    "    model = keras_helpers.build_multilayer_perceptron()\n",
    "\n",
    "    # Name model\n",
    "    model_type = \"MLP_DC_Plant2\"\n",
    "    model_id = keras_helpers.name_model(model_type)\n",
    "    filepath_full = keras_helpers.make_save_string(model_id)\n",
    "\n",
    "    # Set save and earlystop callbacks\n",
    "    earlystop_cb = keras.callbacks.EarlyStopping(patience = 5)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = filepath_full, save_best_only = True)\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train_pt2, y_train_pt2, epochs = 20, validation_data = (X_test_pt2, y_test_pt2), callbacks =[checkpoint_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate MLP Model (DC Power, Plant 2)\n",
    "\n",
    "if TRAIN_MODELS == False:\n",
    "    filepath_full = r'C:\\Developer\\solar-power-generation-project\\Models\\WJ_MLP_DC_2021_01_13-16_10_50.h5'\n",
    "\n",
    "# Load model\n",
    "model = keras.models.load_model(filepath_full)\n",
    "\n",
    "# Summarise model\n",
    "model.summary()\n",
    "\n",
    "# Make predictions\n",
    "dc_pred_eval = model.predict(dc_evaluation_data_pt2)\n",
    "\n",
    "# Determine model prediction stats\n",
    "model_name = \"MLP_DC\"\n",
    "model_evaluation.evaluate_model(model_name, dc_eval_label_data_pt2, dc_pred_eval)\n",
    "rmse, mae, r2 = model_evaluation.return_model_evaluation_stats(dc_eval_label_data_pt2, dc_pred_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup tensorboard for logging \n",
    "x = tensorboard_helpers.get_run_logdir()\n",
    "\n",
    "# Print tensorboard directory\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimised MLP (Target - DC Power, Plant 2)\n",
    "\n",
    "if TRAIN_MODELS == True:\n",
    "    \n",
    "    # Clear existing models\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Establish parameter distribution for tuning\n",
    "    param_distribs = {\n",
    "        \"n_hidden\":[12],\n",
    "        \"n_neurons\": np.arange(1, 100),\n",
    "        \"learning_rate\": [1e-1, 1e-2, 1e-3, 1e-4],\n",
    "    }\n",
    "\n",
    "    # Build model\n",
    "    wrapped_model = keras_helpers.wrap_model()\n",
    "\n",
    "    # Initialise random search\n",
    "    rnd_search_cv = RandomizedSearchCV(wrapped_model, param_distribs, n_iter = 10, cv = 3)\n",
    "\n",
    "    # Name model\n",
    "    model_type = \"MLP_Opt_DC_Plant1\"\n",
    "    model_id = keras_helpers.name_model(model_type)\n",
    "    filepath_full = keras_helpers.make_save_string(model_id)\n",
    "\n",
    "    # Set save and earlystop callbacks\n",
    "    earlystop_cb = keras.callbacks.EarlyStopping(patience = 3)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = filepath_full, save_best_only = True)\n",
    "\n",
    "    # Set TensorBoard callback for logging\n",
    "    tb_logdir = tensorboard_helpers.get_run_logdir()\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(tb_logdir)\n",
    "\n",
    "    # Train model\n",
    "    rnd_search_cv.fit(X_train_pt2, y_train_pt2, epochs = 100, validation_data = (X_test_pt2, y_test_pt2), callbacks = [checkpoint_cb, earlystop_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate MLP Model (DC Power, Plant 2)\n",
    "\n",
    "if TRAIN_MODELS == False:\n",
    "    filepath_full = r'C:\\Developer\\solar-power-generation-project\\Models\\WJ_MLP_Opt_DC_2021_01_13-15_30_27.h5'\n",
    "\n",
    "wrapped_model = keras.models.load_model(filepath_full)\n",
    "\n",
    "# Summarise model\n",
    "wrapped_model.summary()\n",
    "\n",
    "# Make predictions\n",
    "dc_pred_eval = wrapped_model.predict(dc_evaluation_data)\n",
    "\n",
    "model_name = \"MLP_Opt_DC_pt2\"\n",
    "model_evaluation.evaluate_model(model_name, dc_eval_label_data_pt2, dc_pred_eval)\n",
    "rmse, mae, r2 = model_evaluation.return_model_evaluation_stats(dc_eval_label_data_pt2, dc_pred_eval)"
   ]
  }
 ]
}