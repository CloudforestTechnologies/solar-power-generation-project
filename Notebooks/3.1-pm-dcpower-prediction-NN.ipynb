{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36664bitd546b3131dc04b45b27adb02c244c21c",
   "display_name": "Python 3.6.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "3f92393cf9312ed24f4ccae2fdf5dee1635074d2034ccfaec2d070f8b1ae4f04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "keras version = 2.4.0\nnumpy version = 1.19.4\nsklearn version = 0.22.2.post1\ntensorflow version = 2.4.1\n"
     ]
    }
   ],
   "source": [
    "# Module Importations\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "\n",
    "# Print versioning information\n",
    "print('keras version =', keras.__version__)\n",
    "print('numpy version =', np.__version__)  \n",
    "print('sklearn version =', sklearn.__version__)\n",
    "print('tensorflow version =', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[keras_helpers]Tensorflow version: 2.4.1\n[keras_helpers]keras version = 2.4.0\n"
     ]
    }
   ],
   "source": [
    "# Custom Module Imports\n",
    "from Source.data import load_data\n",
    "from Source.data import split_data\n",
    "from Source.models import model_evaluation\n",
    "from Source.models import keras_helpers\n",
    "from Source.models import tensorboard_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TRAIN_MODELS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading pickled dataframe started ...\n",
      "Loading pickled dataframe complete ...\n",
      "Loading pickled dataframe started ...\n",
      "Loading pickled dataframe complete ...\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df_plant1 = load_data.load_pickled_data(\"df_plant1_feat_eng.pkl\")\n",
    "df_plant2 = load_data.load_pickled_data(\"df_plant2_feat_eng.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 71808 entries, 0 to 71806\nData columns (total 20 columns):\n #   Column           Non-Null Count  Dtype         \n---  ------           --------------  -----         \n 0   DATE_TIME        71808 non-null  datetime64[ns]\n 1   PLANT_ID         71808 non-null  object        \n 2   SOURCE_KEY       71808 non-null  object        \n 3   DC_POWER         71808 non-null  float64       \n 4   DAILY_YIELD      71808 non-null  float64       \n 5   AMB_TEMP         71808 non-null  float64       \n 6   MOD_TEMP         71808 non-null  float64       \n 7   IRRADIATION      71808 non-null  float64       \n 8   DATE             71808 non-null  object        \n 9   TIME_OF_DAY      71808 non-null  object        \n 10  HOUR             71808 non-null  int64         \n 11  DAY              71808 non-null  int64         \n 12  WEEKDAY          71808 non-null  object        \n 13  MONTH            71808 non-null  int64         \n 14  YEAR             71808 non-null  int64         \n 15  AVG_HR_DC        71808 non-null  float64       \n 16  AVG_HR_YIELD     71808 non-null  float64       \n 17  AVG_DAILY_DC     71808 non-null  float64       \n 18  AVG_DAILY_YIELD  71808 non-null  float64       \n 19  DC-IRR_RATIO     71808 non-null  float64       \ndtypes: datetime64[ns](1), float64(10), int64(4), object(5)\nmemory usage: 11.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_plant1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 71808 entries, 0 to 71807\nData columns (total 4 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   DC_POWER     71808 non-null  float64\n 1   AMB_TEMP     71808 non-null  float64\n 2   MOD_TEMP     71808 non-null  float64\n 3   IRRADIATION  71808 non-null  float64\ndtypes: float64(4)\nmemory usage: 2.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Drop unrequired data columns\n",
    "\n",
    "# Identify columns to drop\n",
    "cols_to_keep = ['DC_POWER', 'AMB_TEMP', 'MOD_TEMP', 'IRRADIATION', 'TIME_FLOAT']\n",
    "cols_to_drop = []\n",
    "\n",
    "for col in df_plant1.columns:\n",
    "    if col not in cols_to_keep:\n",
    "        cols_to_drop.append(col)\n",
    "\n",
    "for df in [df_plant1, df_plant2]:\n",
    "    df.drop(cols_to_drop, axis = 1, inplace = True)\n",
    "\n",
    "df_plant2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original Data Items: 71808\nTraining Data Items: 57447\nEvaluation Data Items: 14361\nOriginal Data Items: 71808\nTraining Data Items: 57447\nEvaluation Data Items: 14361\n"
     ]
    }
   ],
   "source": [
    "# Split data into training / evaluation sets\n",
    "training_set_plant1, evaluation_set_plant1 = split_data.split_train_eval(df_plant1, 0.2)\n",
    "training_set_plant2, evaluation_set_plant2 = split_data.split_train_eval(df_plant2, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DC Power Target datasets\n",
    "\n",
    "# Modify training sets\n",
    "dc_power_training_data_pt1 = training_set_plant1.drop('DC_POWER', axis = 1)\n",
    "dc_label_data_pt1 = training_set_plant1['DC_POWER'].copy()\n",
    "\n",
    "dc_power_training_data_pt2 = training_set_plant2.drop('DC_POWER', axis = 1)\n",
    "dc_label_data_pt2 = training_set_plant2['DC_POWER'].copy()\n",
    "\n",
    "# Modify evaluation sets\n",
    "dc_evaluation_data_pt1 = evaluation_set_plant1.drop('DC_POWER', axis = 1)\n",
    "dc_eval_label_data_pt1 = evaluation_set_plant1['DC_POWER'].copy()\n",
    "\n",
    "dc_evaluation_data_pt2 = evaluation_set_plant2.drop('DC_POWER', axis = 1)\n",
    "dc_eval_label_data_pt2 = evaluation_set_plant2['DC_POWER'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Plant 1:\nFit Train: (57447, 3)\nFit Label: (57447,)\nEval Train: (14361, 3)\nEval Label: (14361,)\nPlant 2:\nFit Train: (57447, 3)\nFit Label: (57447,)\nEval Train: (14361, 3)\nEval Label: (14361,)\n"
     ]
    }
   ],
   "source": [
    "# Check shape of arrays\n",
    "print('Plant 1:')\n",
    "print('Fit Train:', dc_power_training_data_pt1.shape)\n",
    "print('Fit Label:', dc_label_data_pt1.shape)\n",
    "print('Eval Train:', dc_evaluation_data_pt1.shape)\n",
    "print('Eval Label:', dc_eval_label_data_pt1.shape)\n",
    "\n",
    "print('Plant 2:')\n",
    "print('Fit Train:', dc_power_training_data_pt2.shape)\n",
    "print('Fit Label:', dc_label_data_pt2.shape)\n",
    "print('Eval Train:', dc_evaluation_data_pt2.shape)\n",
    "print('Eval Label:', dc_eval_label_data_pt2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise Inputs\n",
    "normalise_inputs = False\n",
    "normalise_outputs = False\n",
    "\n",
    "normaliser = MinMaxScaler()\n",
    "\n",
    "if normalise_inputs == True:\n",
    "\n",
    "    # Transform training sets\n",
    "    dc_power_training_data_pt1 = normaliser.fit_transform(dc_power_training_data_pt1)\n",
    "    dc_power_training_data_pt2 = normaliser.fit_transform(dc_power_training_data_pt2)\n",
    "\n",
    "    # Transform evaluation sets\n",
    "    dc_evaluation_data_pt1 = normaliser.fit_transform(dc_evaluation_data_pt1)\n",
    "    dc_evaluation_data_pt2 = normaliser.fit_transform(dc_evaluation_data_pt2)\n",
    "\n",
    "if normalise_outputs == True:\n",
    "\n",
    "    # Transform training sets\n",
    "    dc_label_data_pt1 = normaliser.fit_transform(dc_label_data_pt1)\n",
    "    dc_label_data_pt2 = normaliser.fit_transform(dc_label_data_pt2)\n",
    "\n",
    "    # Transform evaluation sets\n",
    "    dc_eval_label_data_pt1 = normaliser.fit_transform(dc_eval_label_data_pt1)\n",
    "    dc_eval_label_data_pt2 = normaliser.fit_transform(dc_eval_label_data_pt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        AMB_TEMP   MOD_TEMP  IRRADIATION\n",
       "14143  30.709979  37.024858     0.301570\n",
       "57612  21.928052  21.149878     0.024557\n",
       "2193   21.912934  20.559299     0.000000\n",
       "45323  27.553448  47.849731     0.684174\n",
       "52973  21.649394  19.301268     0.000000\n",
       "...          ...        ...          ...\n",
       "28390  29.480094  54.250505     0.818236\n",
       "66023  21.658166  20.840604     0.033310\n",
       "58579  26.332082  27.795502     0.097186\n",
       "18920  25.133763  22.681325     0.000000\n",
       "60262  27.122843  40.939669     0.544320\n",
       "\n",
       "[57447 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AMB_TEMP</th>\n      <th>MOD_TEMP</th>\n      <th>IRRADIATION</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14143</th>\n      <td>30.709979</td>\n      <td>37.024858</td>\n      <td>0.301570</td>\n    </tr>\n    <tr>\n      <th>57612</th>\n      <td>21.928052</td>\n      <td>21.149878</td>\n      <td>0.024557</td>\n    </tr>\n    <tr>\n      <th>2193</th>\n      <td>21.912934</td>\n      <td>20.559299</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>45323</th>\n      <td>27.553448</td>\n      <td>47.849731</td>\n      <td>0.684174</td>\n    </tr>\n    <tr>\n      <th>52973</th>\n      <td>21.649394</td>\n      <td>19.301268</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>28390</th>\n      <td>29.480094</td>\n      <td>54.250505</td>\n      <td>0.818236</td>\n    </tr>\n    <tr>\n      <th>66023</th>\n      <td>21.658166</td>\n      <td>20.840604</td>\n      <td>0.033310</td>\n    </tr>\n    <tr>\n      <th>58579</th>\n      <td>26.332082</td>\n      <td>27.795502</td>\n      <td>0.097186</td>\n    </tr>\n    <tr>\n      <th>18920</th>\n      <td>25.133763</td>\n      <td>22.681325</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>60262</th>\n      <td>27.122843</td>\n      <td>40.939669</td>\n      <td>0.544320</td>\n    </tr>\n  </tbody>\n</table>\n<p>57447 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Check values after normalisation\n",
    "dc_power_training_data_pt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "        AMB_TEMP   MOD_TEMP  IRRADIATION\n16030  31.882248  54.657647     0.760547\n4052   25.053473  22.286041     0.000000\n71148  24.390767  29.473142     0.118630\n71233  24.196167  26.664971     0.104762\n24592  32.395532  42.827372     0.319141\n...          ...        ...          ...\n14020  31.933858  46.442515     0.355913\n50198  26.388254  25.753438     0.021628\n65767  22.101636  21.011483     0.000000\n50797  22.663851  20.767582     0.000000\n12524  24.236110  21.519643     0.000000\n\n[45957 rows x 3 columns]\n16030    936.842857\n4052       0.000000\n71148    178.350000\n71233    154.514286\n24592    414.100000\n            ...    \n14020    560.000000\n50198     31.471429\n65767      0.000000\n50797      0.000000\n12524      0.000000\nName: DC_POWER, Length: 45957, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create train and test arrays (plant 1)\n",
    "X_train_pt1, X_test_pt1, y_train_pt1, y_test_pt1 = train_test_split(dc_power_training_data_pt1, dc_label_data_pt1, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(X_train_pt1)\n",
    "print(y_train_pt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Building Model ...\n",
      "Hidden Layers: 2, Neurons: 6, LR: 0.001\n",
      "Epoch 1/20\n",
      "1437/1437 [==============================] - 3s 2ms/step - loss: 154658.4463 - val_loss: 70319.0781\n",
      "Epoch 2/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 54861.3180 - val_loss: 9938.6660\n",
      "Epoch 3/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 8334.6403 - val_loss: 8543.5732\n",
      "Epoch 4/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 7839.9018 - val_loss: 8534.1504\n",
      "Epoch 5/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 7777.4611 - val_loss: 8289.3896\n",
      "Epoch 6/20\n",
      "1437/1437 [==============================] - 3s 2ms/step - loss: 7582.3746 - val_loss: 8138.8228\n",
      "Epoch 7/20\n",
      "1437/1437 [==============================] - 2s 2ms/step - loss: 7568.5485 - val_loss: 8012.6260\n",
      "Epoch 8/20\n",
      "1437/1437 [==============================] - 2s 2ms/step - loss: 7628.4296 - val_loss: 7872.0962\n",
      "Epoch 9/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 7257.8870 - val_loss: 7805.4282\n",
      "Epoch 10/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 7545.8644 - val_loss: 7641.0479\n",
      "Epoch 11/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 7114.6109 - val_loss: 7507.0571\n",
      "Epoch 12/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 6739.1193 - val_loss: 7422.5986\n",
      "Epoch 13/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 6616.3762 - val_loss: 7282.9966\n",
      "Epoch 14/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 6666.4860 - val_loss: 7172.9780\n",
      "Epoch 15/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 6737.9978 - val_loss: 7065.2915\n",
      "Epoch 16/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 6585.4703 - val_loss: 6924.9600\n",
      "Epoch 17/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 6242.0293 - val_loss: 6826.8784\n",
      "Epoch 18/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 6145.1532 - val_loss: 6737.4448\n",
      "Epoch 19/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 6107.9890 - val_loss: 6558.1558\n",
      "Epoch 20/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 6325.9679 - val_loss: 6612.3955\n"
     ]
    }
   ],
   "source": [
    "# Initial MLP (Target - DC Power, Plant 1)\n",
    "\n",
    "if TRAIN_MODELS == True:\n",
    "    # Clear existing models\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Build model\n",
    "    model = keras_helpers.build_multilayer_perceptron()\n",
    "\n",
    "    # Name model\n",
    "    model_type = \"MLP_DC_Plant1\"\n",
    "    model_id = keras_helpers.name_model(model_type)\n",
    "    filepath_full = keras_helpers.make_save_string(model_id)\n",
    "\n",
    "    # Set save and earlystop callbacks\n",
    "    earlystop_cb = keras.callbacks.EarlyStopping(patience = 5)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = filepath_full, save_best_only = True)\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train_pt1, y_train_pt1, epochs = 20, validation_data = (X_test_pt1, y_test_pt1), callbacks =[checkpoint_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 73\n",
      "Trainable params: 73\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "MLP_DC rmse (Eval): 76.74447129784127\n",
      "MLP_DC mae (Eval): 38.42543503639796\n",
      "MLP_DC r2 (Eval): 0.9630481143508067\n"
     ]
    }
   ],
   "source": [
    "# Evaluate MLP Model (DC Power, Plant 1)\n",
    "\n",
    "if TRAIN_MODELS == False:\n",
    "    filepath_full = r'C:\\Developer\\solar-power-generation-project\\Models\\WJ_MLP_DC_2021_01_13-16_10_50.h5'\n",
    "\n",
    "# Load model\n",
    "model = keras.models.load_model(filepath_full)\n",
    "\n",
    "# Summarise model\n",
    "model.summary()\n",
    "\n",
    "# Make predictions\n",
    "dc_pred_eval = model.predict(dc_evaluation_data_pt1)\n",
    "\n",
    "# Determine model prediction stats\n",
    "model_name = \"MLP_DC\"\n",
    "model_evaluation.evaluate_model(model_name, dc_eval_label_data_pt1, dc_pred_eval)\n",
    "rmse, mae, r2 = model_evaluation.return_model_evaluation_stats(dc_eval_label_data_pt1, dc_pred_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "c:\\Developer\\solar-power-generation-project\\Models\\TensorBoard\\run_2021_06_08-10_58_32\n"
     ]
    }
   ],
   "source": [
    "# Setup tensorboard for logging \n",
    "x = tensorboard_helpers.get_run_logdir()\n",
    "\n",
    "# Print tensorboard directory\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-00a467062745>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m# Train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mrnd_search_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcheckpoint_cb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearlystop_cb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensorboard_cb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Optimised MLP (Target - DC Power, Plant 1)\n",
    "\n",
    "if TRAIN_MODELS == True:\n",
    "    \n",
    "    # Clear existing models\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Establish parameter distribution for tuning\n",
    "    param_distribs = {\n",
    "        \"n_hidden\":[12],\n",
    "        \"n_neurons\": np.arange(1, 100),\n",
    "        \"learning_rate\": [1e-1, 1e-2, 1e-3, 1e-4],\n",
    "    }\n",
    "\n",
    "    # Build model\n",
    "    wrapped_model = keras_helpers.wrap_model()\n",
    "\n",
    "    # Initialise random search\n",
    "    rnd_search_cv = RandomizedSearchCV(wrapped_model, param_distribs, n_iter = 10, cv = 3)\n",
    "\n",
    "    # Name model\n",
    "    model_type = \"MLP_Opt_DC_Pt1\"\n",
    "    model_id = keras_helpers.name_model(model_type)\n",
    "    filepath_full = keras_helpers.make_save_string(model_id)\n",
    "\n",
    "    # Set save and earlystop callbacks\n",
    "    earlystop_cb = keras.callbacks.EarlyStopping(patience = 3)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = filepath_full, save_best_only = True)\n",
    "\n",
    "    # Set TensorBoard callback for logging\n",
    "    tb_logdir = tensorboard_helpers.get_run_logdir()\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(tb_logdir)\n",
    "\n",
    "    # Train model\n",
    "    rnd_search_cv.fit(X_train_pt1, y_train_pt1, epochs = 100, validation_data = (X_test_pt1, y_test_pt1), callbacks = [checkpoint_cb, earlystop_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_169 (Dense)            (None, 40)                280       \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 8,521\n",
      "Trainable params: 8,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "MLP_Opt_DC rmse (Eval): 1155.8620532143577\n",
      "MLP_Opt_DC mae (Eval): 545.58045225204\n",
      "MLP_Opt_DC r2 (Eval): 0.9181278609504048\n",
      "MLP_Opt_DC % Acc: 91.10875343681263\n"
     ]
    }
   ],
   "source": [
    "# Evaluate MLP Model (DC Power, Plant 1)\n",
    "\n",
    "if TRAIN_MODELS == False:\n",
    "    filepath_full = r'C:\\Developer\\solar-power-generation-project\\Models\\WJ_MLP_Opt_DC_2021_01_13-15_30_27.h5'\n",
    "\n",
    "wrapped_model = keras.models.load_model(filepath_full)\n",
    "\n",
    "# Summarise model\n",
    "wrapped_model.summary()\n",
    "\n",
    "# Make predictions\n",
    "dc_pred_eval = wrapped_model.predict(dc_evaluation_data)\n",
    "\n",
    "model_name = \"MLP_Opt_DC_pt1\"\n",
    "model_evaluation.evaluate_model(model_name, dc_eval_label_data_pt1, dc_pred_eval)\n",
    "rmse, mae, r2 = model_evaluation.return_model_evaluation_stats(dc_eval_label_data_pt1, dc_pred_eval)"
   ]
  }
 ]
}