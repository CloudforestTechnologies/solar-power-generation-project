{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36664bitd546b3131dc04b45b27adb02c244c21c",
   "display_name": "Python 3.6.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "3f92393cf9312ed24f4ccae2fdf5dee1635074d2034ccfaec2d070f8b1ae4f04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "keras version = 2.4.0\nnumpy version = 1.19.4\nsklearn version = 0.22.2.post1\ntensorflow version = 2.4.1\n"
     ]
    }
   ],
   "source": [
    "# Module Importations\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "\n",
    "# Print versioning information\n",
    "print('keras version =', keras.__version__)\n",
    "print('numpy version =', np.__version__)  \n",
    "print('sklearn version =', sklearn.__version__)\n",
    "print('tensorflow version =', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[keras_helpers]Tensorflow version: 2.4.1\n[keras_helpers]keras version = 2.4.0\n"
     ]
    }
   ],
   "source": [
    "# Custom Module Imports\n",
    "from Source.data import load_data\n",
    "from Source.data import split_data\n",
    "from Source.models import model_evaluation\n",
    "from Source.models import keras_helpers\n",
    "from Source.models import tensorboard_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TRAIN_MODELS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading pickled dataframe started ...\n",
      "Loading pickled dataframe complete ...\n",
      "Loading pickled dataframe started ...\n",
      "Loading pickled dataframe complete ...\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df_plant1 = load_data.load_pickled_data(\"df_plant1_feat_eng.pkl\")\n",
    "df_plant2 = load_data.load_pickled_data(\"df_plant2_feat_eng.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 71808 entries, 0 to 71806\nData columns (total 20 columns):\n #   Column           Non-Null Count  Dtype         \n---  ------           --------------  -----         \n 0   DATE_TIME        71808 non-null  datetime64[ns]\n 1   PLANT_ID         71808 non-null  object        \n 2   SOURCE_KEY       71808 non-null  object        \n 3   DC_POWER         71808 non-null  float64       \n 4   DAILY_YIELD      71808 non-null  float64       \n 5   AMB_TEMP         71808 non-null  float64       \n 6   MOD_TEMP         71808 non-null  float64       \n 7   IRRADIATION      71808 non-null  float64       \n 8   DATE             71808 non-null  object        \n 9   TIME_OF_DAY      71808 non-null  object        \n 10  HOUR             71808 non-null  int64         \n 11  DAY              71808 non-null  int64         \n 12  WEEKDAY          71808 non-null  object        \n 13  MONTH            71808 non-null  int64         \n 14  YEAR             71808 non-null  int64         \n 15  AVG_HR_DC        71808 non-null  float64       \n 16  AVG_HR_YIELD     71808 non-null  float64       \n 17  AVG_DAILY_DC     71808 non-null  float64       \n 18  AVG_DAILY_YIELD  71808 non-null  float64       \n 19  DC-IRR_RATIO     71808 non-null  float64       \ndtypes: datetime64[ns](1), float64(10), int64(4), object(5)\nmemory usage: 11.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_plant1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 71808 entries, 0 to 71807\nData columns (total 4 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   DC_POWER     71808 non-null  float64\n 1   AMB_TEMP     71808 non-null  float64\n 2   MOD_TEMP     71808 non-null  float64\n 3   IRRADIATION  71808 non-null  float64\ndtypes: float64(4)\nmemory usage: 2.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Drop unrequired data columns\n",
    "\n",
    "# Identify columns to drop\n",
    "cols_to_keep = ['DC_POWER', 'AMB_TEMP', 'MOD_TEMP', 'IRRADIATION', 'TIME_FLOAT']\n",
    "cols_to_drop = []\n",
    "\n",
    "for col in df_plant1.columns:\n",
    "    if col not in cols_to_keep:\n",
    "        cols_to_drop.append(col)\n",
    "\n",
    "for df in [df_plant1, df_plant2]:\n",
    "    df.drop(cols_to_drop, axis = 1, inplace = True)\n",
    "\n",
    "df_plant2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original Data Items: 71808\nTraining Data Items: 57447\nEvaluation Data Items: 14361\nOriginal Data Items: 71808\nTraining Data Items: 57447\nEvaluation Data Items: 14361\n"
     ]
    }
   ],
   "source": [
    "# Split data into training / evaluation sets\n",
    "training_set_plant1, evaluation_set_plant1 = split_data.split_train_eval(df_plant1, 0.2)\n",
    "training_set_plant2, evaluation_set_plant2 = split_data.split_train_eval(df_plant2, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DC Power Target datasets\n",
    "\n",
    "# Modify training sets\n",
    "dc_power_training_data_pt1 = training_set_plant1.drop('DC_POWER', axis = 1)\n",
    "dc_label_data_pt1 = training_set_plant1['DC_POWER'].copy()\n",
    "\n",
    "dc_power_training_data_pt2 = training_set_plant2.drop('DC_POWER', axis = 1)\n",
    "dc_label_data_pt2 = training_set_plant2['DC_POWER'].copy()\n",
    "\n",
    "# Modify evaluation sets\n",
    "dc_evaluation_data_pt1 = evaluation_set_plant1.drop('DC_POWER', axis = 1)\n",
    "dc_eval_label_data_pt1 = evaluation_set_plant1['DC_POWER'].copy()\n",
    "\n",
    "dc_evaluation_data_pt2 = evaluation_set_plant2.drop('DC_POWER', axis = 1)\n",
    "dc_eval_label_data_pt2 = evaluation_set_plant2['DC_POWER'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Plant 1:\nFit Train: (57447, 3)\nFit Label: (57447,)\nEval Train: (14361, 3)\nEval Label: (14361,)\nPlant 2:\nFit Train: (57447, 3)\nFit Label: (57447,)\nEval Train: (14361, 3)\nEval Label: (14361,)\n"
     ]
    }
   ],
   "source": [
    "# Check shape of arrays\n",
    "print('Plant 1:')\n",
    "print('Fit Train:', dc_power_training_data_pt1.shape)\n",
    "print('Fit Label:', dc_label_data_pt1.shape)\n",
    "print('Eval Train:', dc_evaluation_data_pt1.shape)\n",
    "print('Eval Label:', dc_eval_label_data_pt1.shape)\n",
    "\n",
    "print('Plant 2:')\n",
    "print('Fit Train:', dc_power_training_data_pt2.shape)\n",
    "print('Fit Label:', dc_label_data_pt2.shape)\n",
    "print('Eval Train:', dc_evaluation_data_pt2.shape)\n",
    "print('Eval Label:', dc_eval_label_data_pt2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise Inputs\n",
    "normalise_inputs = True\n",
    "normalise_outputs = False\n",
    "\n",
    "normaliser = MinMaxScaler()\n",
    "\n",
    "if normalise_inputs == True:\n",
    "\n",
    "    # Transform training sets\n",
    "    dc_power_training_data_pt1 = normaliser.fit_transform(dc_power_training_data_pt1)\n",
    "    dc_power_training_data_pt2 = normaliser.fit_transform(dc_power_training_data_pt2)\n",
    "\n",
    "    # Transform evaluation sets\n",
    "    dc_evaluation_data_pt1 = normaliser.fit_transform(dc_evaluation_data_pt1)\n",
    "    dc_evaluation_data_pt2 = normaliser.fit_transform(dc_evaluation_data_pt2)\n",
    "\n",
    "if normalise_outputs == True:\n",
    "\n",
    "    # Transform training sets\n",
    "    dc_label_data_pt1 = normaliser.fit_transform(dc_label_data_pt1)\n",
    "    dc_label_data_pt2 = normaliser.fit_transform(dc_label_data_pt2)\n",
    "\n",
    "    # Transform evaluation sets\n",
    "    dc_eval_label_data_pt1 = normaliser.fit_transform(dc_eval_label_data_pt1)\n",
    "    dc_eval_label_data_pt2 = normaliser.fit_transform(dc_eval_label_data_pt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.69418927, 0.39836143, 0.24685468],\n",
       "       [0.10297219, 0.06348367, 0.02010156],\n",
       "       [0.10195445, 0.0510256 , 0.        ],\n",
       "       ...,\n",
       "       [0.3994604 , 0.20367104, 0.07955333],\n",
       "       [0.31878711, 0.09578908, 0.        ],\n",
       "       [0.45269604, 0.48094315, 0.44556097]])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Check values after normalisation\n",
    "dc_power_training_data_pt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.77310878 0.77031963 0.62255649]\n [0.31338184 0.08745068 0.        ]\n [0.26876718 0.23906034 0.09710624]\n ...\n [0.11465821 0.06056427 0.        ]\n [0.15250767 0.05541926 0.        ]\n [0.25835535 0.07128375 0.        ]]\n16030    936.842857\n4052       0.000000\n71148    178.350000\n71233    154.514286\n24592    414.100000\n            ...    \n14020    560.000000\n50198     31.471429\n65767      0.000000\n50797      0.000000\n12524      0.000000\nName: DC_POWER, Length: 45957, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create train and test arrays (plant 1)\n",
    "X_train_pt1, X_test_pt1, y_train_pt1, y_test_pt1 = train_test_split(dc_power_training_data_pt1, dc_label_data_pt1, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(X_train_pt1)\n",
    "print(y_train_pt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Building Model ...\n",
      "Hidden Layers: 2, Neurons: 6, LR: 0.001\n",
      "Epoch 1/20\n",
      "1437/1437 [==============================] - 3s 2ms/step - loss: 253079.2749 - val_loss: 230518.6406\n",
      "Epoch 2/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 214021.5542 - val_loss: 142003.7969\n",
      "Epoch 3/20\n",
      "1437/1437 [==============================] - 4s 3ms/step - loss: 119865.3620 - val_loss: 74890.5547\n",
      "Epoch 4/20\n",
      "1437/1437 [==============================] - 2s 2ms/step - loss: 67270.2282 - val_loss: 46768.8555\n",
      "Epoch 5/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 39692.7710 - val_loss: 21804.9648\n",
      "Epoch 6/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 16685.9653 - val_loss: 9288.6934\n",
      "Epoch 7/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 8286.8625 - val_loss: 7260.3906\n",
      "Epoch 8/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 6741.0564 - val_loss: 6304.8208\n",
      "Epoch 9/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 5867.5989 - val_loss: 5624.1226\n",
      "Epoch 10/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 5056.6328 - val_loss: 5137.0000\n",
      "Epoch 11/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 4508.0617 - val_loss: 4827.2002\n",
      "Epoch 12/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 4559.4936 - val_loss: 4642.6279\n",
      "Epoch 13/20\n",
      "1437/1437 [==============================] - 1s 1ms/step - loss: 4014.2581 - val_loss: 4563.2451\n",
      "Epoch 14/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3820.8378 - val_loss: 4492.1865\n",
      "Epoch 15/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 4073.8906 - val_loss: 4466.0625\n",
      "Epoch 16/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 4070.5957 - val_loss: 4442.1436\n",
      "Epoch 17/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 4131.5928 - val_loss: 4426.9072\n",
      "Epoch 18/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3591.6398 - val_loss: 4408.1646\n",
      "Epoch 19/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3597.2542 - val_loss: 4394.9404\n",
      "Epoch 20/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3952.3591 - val_loss: 4389.0884\n"
     ]
    }
   ],
   "source": [
    "# Initial MLP (Target - DC Power, Plant 1)\n",
    "\n",
    "if TRAIN_MODELS == True:\n",
    "    # Clear existing models\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Build model\n",
    "    model = keras_helpers.build_multilayer_perceptron()\n",
    "\n",
    "    # Name model\n",
    "    model_type = \"MLP_DC_Plant1\"\n",
    "    model_id = keras_helpers.name_model(model_type)\n",
    "    filepath_full = keras_helpers.make_save_string(model_id)\n",
    "\n",
    "    # Set save and earlystop callbacks\n",
    "    earlystop_cb = keras.callbacks.EarlyStopping(patience = 5)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = filepath_full, save_best_only = True)\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train_pt1, y_train_pt1, epochs = 20, validation_data = (X_test_pt1, y_test_pt1), callbacks =[checkpoint_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 73\n",
      "Trainable params: 73\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "MLP_DC_Plant1 rmse (Eval): 60.852316475907756\n",
      "MLP_DC_Plant1 mae (Eval): 27.97568432308068\n",
      "MLP_DC_Plant1 r2 (Eval): 0.9767674629339826\n"
     ]
    }
   ],
   "source": [
    "# Evaluate MLP Model (DC Power, Plant 1)\n",
    "\n",
    "if TRAIN_MODELS == False:\n",
    "    filepath_full = r'C:\\Developer\\solar-power-generation-project\\Models\\WJ_MLP_DC_2021_01_13-16_10_50.h5'\n",
    "\n",
    "# Load model\n",
    "model = keras.models.load_model(filepath_full)\n",
    "\n",
    "# Summarise model\n",
    "model.summary()\n",
    "\n",
    "# Make predictions\n",
    "dc_pred_eval = model.predict(dc_evaluation_data_pt1)\n",
    "\n",
    "# Determine model prediction stats\n",
    "model_name = \"MLP_DC_Plant1\"\n",
    "model_evaluation.evaluate_model(model_name, dc_eval_label_data_pt1, dc_pred_eval)\n",
    "rmse, mae, r2 = model_evaluation.return_model_evaluation_stats(dc_eval_label_data_pt1, dc_pred_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "c:\\Developer\\solar-power-generation-project\\Models\\TensorBoard\\run_2021_06_10-15_38_34\n"
     ]
    }
   ],
   "source": [
    "# Setup tensorboard for logging \n",
    "x = tensorboard_helpers.get_run_logdir()\n",
    "\n",
    "# Print tensorboard directory\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 20, LR: 0.001\n",
      "479/479 [==============================] - 0s 809us/step - loss: 3497.5195\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 20, LR: 0.001\n",
      "479/479 [==============================] - 0s 784us/step - loss: 3112.4565\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 20, LR: 0.001\n",
      "479/479 [==============================] - 0s 783us/step - loss: 3362.1572\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 80, LR: 0.1\n",
      "479/479 [==============================] - 0s 867us/step - loss: nan\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 80, LR: 0.1\n",
      "479/479 [==============================] - 0s 887us/step - loss: 162480.5938\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 80, LR: 0.1\n",
      "479/479 [==============================] - 0s 907us/step - loss: nan\n",
      "Building Model ...\n",
      "Hidden Layers: 4, Neurons: 40, LR: 0.1\n",
      "479/479 [==============================] - 0s 801us/step - loss: 6303.4365\n",
      "Building Model ...\n",
      "Hidden Layers: 4, Neurons: 40, LR: 0.1\n",
      "479/479 [==============================] - 0s 771us/step - loss: 8318.8408\n",
      "Building Model ...\n",
      "Hidden Layers: 4, Neurons: 40, LR: 0.1\n",
      "479/479 [==============================] - 0s 739us/step - loss: 2893.1873\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 5, LR: 0.0001\n",
      "479/479 [==============================] - 0s 789us/step - loss: 3543.4404\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 5, LR: 0.0001\n",
      "479/479 [==============================] - 0s 768us/step - loss: 3011.9790\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 5, LR: 0.0001\n",
      "479/479 [==============================] - 0s 880us/step - loss: 160803.8906\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 10, LR: 0.1\n",
      "479/479 [==============================] - 0s 797us/step - loss: 160666.3438\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 10, LR: 0.1\n",
      "479/479 [==============================] - 0s 769us/step - loss: 161493.4531\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 10, LR: 0.1\n",
      "479/479 [==============================] - 0s 771us/step - loss: 163732.4688\n",
      "Building Model ...\n",
      "Hidden Layers: 20, Neurons: 10, LR: 0.1\n",
      "479/479 [==============================] - 0s 843us/step - loss: 161608.9062\n",
      "Building Model ...\n",
      "Hidden Layers: 20, Neurons: 10, LR: 0.1\n",
      "479/479 [==============================] - 0s 855us/step - loss: 162244.7188\n",
      "Building Model ...\n",
      "Hidden Layers: 20, Neurons: 10, LR: 0.1\n",
      "479/479 [==============================] - 0s 873us/step - loss: 162065.7344\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 20, LR: 0.1\n",
      "479/479 [==============================] - 0s 987us/step - loss: 160674.5781\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 20, LR: 0.1\n",
      "479/479 [==============================] - 0s 922us/step - loss: 162360.2969\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 20, LR: 0.1\n",
      "479/479 [==============================] - 0s 826us/step - loss: 161462.2656\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 100, LR: 0.001\n",
      "479/479 [==============================] - 1s 3ms/step - loss: 5252.1958\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 100, LR: 0.001\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 4971.7827\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 100, LR: 0.001\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 3693.6838\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 60, LR: 0.01\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 4571.4189\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 60, LR: 0.01\n",
      "479/479 [==============================] - 0s 914us/step - loss: 3633.5967\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 60, LR: 0.01\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 5649.4673\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 5, LR: 0.0001\n",
      "479/479 [==============================] - 0s 834us/step - loss: 3557.8621\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 5, LR: 0.0001\n",
      "479/479 [==============================] - 0s 810us/step - loss: 2965.9326\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 5, LR: 0.0001\n",
      "479/479 [==============================] - 0s 789us/step - loss: 2785.8982\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 5, LR: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Optimised MLP (Target - DC Power, Plant 1)\n",
    "\n",
    "if TRAIN_MODELS == True:\n",
    "    \n",
    "    # Clear existing models\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Establish parameter distribution for tuning\n",
    "    param_distribs = {\n",
    "        \"n_hidden\": (4, 8, 12, 16, 20),\n",
    "        \"n_neurons\": (5, 10, 20, 40, 60, 80, 100),\n",
    "        \"learning_rate\": (1e-1, 1e-2, 1e-3, 1e-4),\n",
    "    }\n",
    "\n",
    "    # Build model\n",
    "    wrapped_model = keras_helpers.wrap_model()\n",
    "\n",
    "    # Initialise random search\n",
    "    rnd_search_cv = RandomizedSearchCV(wrapped_model, param_distribs, n_iter = 10, cv = 3)\n",
    "\n",
    "    # Name model\n",
    "    model_type = \"MLP_Opt_DC_Plant1\"\n",
    "    model_id = keras_helpers.name_model(model_type)\n",
    "    filepath_full = keras_helpers.make_save_string(model_id)\n",
    "\n",
    "    # Set save and earlystop callbacks\n",
    "    earlystop_cb = keras.callbacks.EarlyStopping(patience = 3)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = filepath_full, save_best_only = True)\n",
    "\n",
    "    # Set TensorBoard callback for logging\n",
    "    tb_logdir = tensorboard_helpers.get_run_logdir()\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(tb_logdir)\n",
    "\n",
    "    # Train model\n",
    "    rnd_search_cv.fit(X_train_pt1, y_train_pt1, epochs = 100, validation_data = (X_test_pt1, y_test_pt1), callbacks = [checkpoint_cb, earlystop_cb, tensorboard_cb], verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_285 (Dense)            (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_286 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_287 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_288 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_289 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_290 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_291 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_292 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_293 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_294 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_295 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_296 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_297 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_298 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_299 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_300 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_301 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 152,001\n",
      "Trainable params: 152,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "MLP_Opt_DC_pt1 rmse (Eval): 54.2822401529965\n",
      "MLP_Opt_DC_pt1 mae (Eval): 22.605743012804734\n",
      "MLP_Opt_DC_pt1 r2 (Eval): 0.9815133621989935\n"
     ]
    }
   ],
   "source": [
    "# Evaluate MLP Model (DC Power, Plant 1)\n",
    "\n",
    "if TRAIN_MODELS == False:\n",
    "    filepath_full = r'C:\\Developer\\solar-power-generation-project\\Models\\WJ_MLP_Opt_DC_Plant1_2021_06_10-11_34_55.h5'\n",
    "\n",
    "wrapped_model = keras.models.load_model(filepath_full)\n",
    "\n",
    "# Summarise model\n",
    "wrapped_model.summary()\n",
    "\n",
    "# Make predictions\n",
    "dc_pred_eval = wrapped_model.predict(dc_evaluation_data_pt1)\n",
    "\n",
    "model_name = \"MLP_Opt_DC_pt1\"\n",
    "model_evaluation.evaluate_model(model_name, dc_eval_label_data_pt1, dc_pred_eval)\n",
    "rmse, mae, r2 = model_evaluation.return_model_evaluation_stats(dc_eval_label_data_pt1, dc_pred_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.78718932 0.86385524 0.75714748]\n [0.40111725 0.13940226 0.        ]\n [0.366359   0.24734289 0.16542722]\n ...\n [0.17626336 0.06610678 0.        ]\n [0.19348786 0.04786465 0.        ]\n [0.30564703 0.10208519 0.        ]]\n16031    1196.980000\n4052        0.000000\n71148     285.164286\n71234     140.678571\n24593     896.435714\n            ...     \n14020     872.093333\n50199      57.906667\n65768       0.000000\n50783       0.000000\n12524       0.000000\nName: DC_POWER, Length: 45957, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create train and test arrays (plant 2)\n",
    "X_train_pt2, X_test_pt2, y_train_pt2, y_test_pt2 = train_test_split(dc_power_training_data_pt2, dc_label_data_pt2, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(X_train_pt2)\n",
    "print(y_train_pt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Building Model ...\n",
      "Hidden Layers: 2, Neurons: 6, LR: 0.001\n",
      "Epoch 1/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 199260.8374 - val_loss: 188264.5312\n",
      "Epoch 2/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 179267.1196 - val_loss: 139403.8750\n",
      "Epoch 3/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 120203.3654 - val_loss: 77343.1016\n",
      "Epoch 4/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 68039.2063 - val_loss: 53710.2930\n",
      "Epoch 5/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 51220.3296 - val_loss: 50347.7266\n",
      "Epoch 6/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 49203.5143 - val_loss: 49140.3711\n",
      "Epoch 7/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 48315.5818 - val_loss: 48765.1250\n",
      "Epoch 8/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 46926.3703 - val_loss: 48611.1016\n",
      "Epoch 9/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 47093.8528 - val_loss: 48571.6211\n",
      "Epoch 10/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 47525.0004 - val_loss: 48550.0156\n",
      "Epoch 11/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 47165.9106 - val_loss: 48511.7930\n",
      "Epoch 12/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 47042.8276 - val_loss: 48494.4102\n",
      "Epoch 13/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 47143.0621 - val_loss: 48462.7617\n",
      "Epoch 14/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 46599.2099 - val_loss: 48447.5117\n",
      "Epoch 15/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 46465.1894 - val_loss: 48420.3789\n",
      "Epoch 16/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 47786.1846 - val_loss: 48395.4570\n",
      "Epoch 17/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 47091.9435 - val_loss: 48376.5586\n",
      "Epoch 18/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 46543.9441 - val_loss: 48367.6016\n",
      "Epoch 19/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 48089.7633 - val_loss: 48336.2148\n",
      "Epoch 20/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 46603.2909 - val_loss: 48319.8203\n"
     ]
    }
   ],
   "source": [
    "# Initial MLP (Target - DC Power, Plant 2)\n",
    "\n",
    "if TRAIN_MODELS == True:\n",
    "    \n",
    "    # Clear existing models\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Build model\n",
    "    model = keras_helpers.build_multilayer_perceptron()\n",
    "\n",
    "    # Name model\n",
    "    model_type = \"MLP_DC_Plant2\"\n",
    "    model_id = keras_helpers.name_model(model_type)\n",
    "    filepath_full = keras_helpers.make_save_string(model_id)\n",
    "\n",
    "    # Set save and earlystop callbacks\n",
    "    earlystop_cb = keras.callbacks.EarlyStopping(patience = 5)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = filepath_full, save_best_only = True)\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train_pt2, y_train_pt2, epochs = 20, validation_data = (X_test_pt2, y_test_pt2), callbacks =[checkpoint_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 73\n",
      "Trainable params: 73\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "MLP_DC rmse (Eval): 220.21751981349564\n",
      "MLP_DC mae (Eval): 100.6863230268892\n",
      "MLP_DC r2 (Eval): 0.6487816689527413\n"
     ]
    }
   ],
   "source": [
    "# Evaluate MLP Model (DC Power, Plant 2)\n",
    "\n",
    "if TRAIN_MODELS == False:\n",
    "    filepath_full = r'C:\\Developer\\solar-power-generation-project\\Models\\WJ_MLP_DC_2021_01_13-16_10_50.h5'\n",
    "\n",
    "# Load model\n",
    "model = keras.models.load_model(filepath_full)\n",
    "\n",
    "# Summarise model\n",
    "model.summary()\n",
    "\n",
    "# Make predictions\n",
    "dc_pred_eval = model.predict(dc_evaluation_data_pt2)\n",
    "\n",
    "# Determine model prediction stats\n",
    "model_name = \"MLP_DC\"\n",
    "model_evaluation.evaluate_model(model_name, dc_eval_label_data_pt2, dc_pred_eval)\n",
    "rmse, mae, r2 = model_evaluation.return_model_evaluation_stats(dc_eval_label_data_pt2, dc_pred_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "c:\\Developer\\solar-power-generation-project\\Models\\TensorBoard\\run_2021_06_10-15_58_20\n"
     ]
    }
   ],
   "source": [
    "# Setup tensorboard for logging \n",
    "x = tensorboard_helpers.get_run_logdir()\n",
    "\n",
    "# Print tensorboard directory\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 80, LR: 0.1\n",
      "479/479 [==============================] - 0s 867us/step - loss: 51110.5547\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 80, LR: 0.1\n",
      "479/479 [==============================] - 0s 864us/step - loss: 137943.2656\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 80, LR: 0.1\n",
      "479/479 [==============================] - 0s 873us/step - loss: 137857.8438\n",
      "Building Model ...\n",
      "Hidden Layers: 4, Neurons: 60, LR: 0.0001\n",
      "479/479 [==============================] - 0s 773us/step - loss: 46360.1797\n",
      "Building Model ...\n",
      "Hidden Layers: 4, Neurons: 60, LR: 0.0001\n",
      "479/479 [==============================] - 0s 790us/step - loss: 45711.6406\n",
      "Building Model ...\n",
      "Hidden Layers: 4, Neurons: 60, LR: 0.0001\n",
      "479/479 [==============================] - 0s 791us/step - loss: 48241.8047\n",
      "Building Model ...\n",
      "Hidden Layers: 4, Neurons: 20, LR: 0.01\n",
      "479/479 [==============================] - 0s 763us/step - loss: 48049.1328\n",
      "Building Model ...\n",
      "Hidden Layers: 4, Neurons: 20, LR: 0.01\n",
      "479/479 [==============================] - 0s 760us/step - loss: 45929.9453\n",
      "Building Model ...\n",
      "Hidden Layers: 4, Neurons: 20, LR: 0.01\n",
      "479/479 [==============================] - 0s 737us/step - loss: 48019.6914\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 5, LR: 0.001\n",
      "479/479 [==============================] - 0s 790us/step - loss: 48728.8047\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 5, LR: 0.001\n",
      "479/479 [==============================] - 0s 793us/step - loss: 162977.8125\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 5, LR: 0.001\n",
      "479/479 [==============================] - 0s 793us/step - loss: 137121.1406\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 60, LR: 0.0001\n",
      "479/479 [==============================] - 0s 911us/step - loss: 46378.8008\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 60, LR: 0.0001\n",
      "479/479 [==============================] - 0s 950us/step - loss: 45842.4336\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 60, LR: 0.0001\n",
      "479/479 [==============================] - 0s 915us/step - loss: 48198.0039\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 100, LR: 0.01\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 47038.5469\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 100, LR: 0.01\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 47803.9062\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 100, LR: 0.01\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 48835.8359\n",
      "Building Model ...\n",
      "Hidden Layers: 4, Neurons: 40, LR: 0.1\n",
      "479/479 [==============================] - 0s 793us/step - loss: 47775.2578\n",
      "Building Model ...\n",
      "Hidden Layers: 4, Neurons: 40, LR: 0.1\n",
      "479/479 [==============================] - 0s 808us/step - loss: 48896.9023\n",
      "Building Model ...\n",
      "Hidden Layers: 4, Neurons: 40, LR: 0.1\n",
      "479/479 [==============================] - 0s 782us/step - loss: 48671.5312\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 100, LR: 0.0001\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 46170.0938\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 100, LR: 0.0001\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 54645.6016\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 100, LR: 0.0001\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 51396.9375\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 100, LR: 0.1\n",
      "479/479 [==============================] - 1s 1ms/step - loss: nan\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 100, LR: 0.1\n",
      "479/479 [==============================] - 1s 1ms/step - loss: nan\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 100, LR: 0.1\n",
      "479/479 [==============================] - 1s 1ms/step - loss: nan\n",
      "Building Model ...\n",
      "Hidden Layers: 4, Neurons: 60, LR: 0.1\n",
      "479/479 [==============================] - 0s 781us/step - loss: 47897.1992\n",
      "Building Model ...\n",
      "Hidden Layers: 4, Neurons: 60, LR: 0.1\n",
      "479/479 [==============================] - 0s 795us/step - loss: 48850.5078\n",
      "Building Model ...\n",
      "Hidden Layers: 4, Neurons: 60, LR: 0.1\n",
      "479/479 [==============================] - 0s 802us/step - loss: 48697.8516\n",
      "Building Model ...\n",
      "Hidden Layers: 4, Neurons: 60, LR: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Optimised MLP (Target - DC Power, Plant 2)\n",
    "\n",
    "if TRAIN_MODELS == True:\n",
    "    \n",
    "    # Clear existing models\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Establish parameter distribution for tuning\n",
    "    param_distribs = {\n",
    "        \"n_hidden\": (4, 8, 12, 16),\n",
    "        \"n_neurons\": (5, 10, 20, 40, 60, 80, 100),\n",
    "        \"learning_rate\": (1e-1, 1e-2, 1e-3, 1e-4),\n",
    "    }\n",
    "\n",
    "    # Build model\n",
    "    wrapped_model = keras_helpers.wrap_model()\n",
    "\n",
    "    # Initialise random search\n",
    "    rnd_search_cv = RandomizedSearchCV(wrapped_model, param_distribs, n_iter = 10, cv = 3)\n",
    "\n",
    "    # Name model\n",
    "    model_type = \"MLP_Opt_DC_Plant1\"\n",
    "    model_id = keras_helpers.name_model(model_type)\n",
    "    filepath_full = keras_helpers.make_save_string(model_id)\n",
    "\n",
    "    # Set save and earlystop callbacks\n",
    "    earlystop_cb = keras.callbacks.EarlyStopping(patience = 3)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = filepath_full, save_best_only = True)\n",
    "\n",
    "    # Set TensorBoard callback for logging\n",
    "    tb_logdir = tensorboard_helpers.get_run_logdir()\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(tb_logdir)\n",
    "\n",
    "    # Train model\n",
    "    rnd_search_cv.fit(X_train_pt2, y_train_pt2, epochs = 100, validation_data = (X_test_pt2, y_test_pt2), callbacks = [checkpoint_cb, earlystop_cb, tensorboard_cb], verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_201 (Dense)            (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_204 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_213 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 152,001\n",
      "Trainable params: 152,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "MLP_Opt_DC_pt2 rmse (Eval): 217.74400041203404\n",
      "MLP_Opt_DC_pt2 mae (Eval): 97.85508301662642\n",
      "MLP_Opt_DC_pt2 r2 (Eval): 0.6566272428322941\n"
     ]
    }
   ],
   "source": [
    "# Evaluate MLP Model (DC Power, Plant 2)\n",
    "\n",
    "if TRAIN_MODELS == False:\n",
    "    filepath_full = r'C:\\Developer\\solar-power-generation-project\\Models\\WJ_MLP_Opt_DC_2021_01_13-15_30_27.h5'\n",
    "\n",
    "wrapped_model = keras.models.load_model(filepath_full)\n",
    "\n",
    "# Summarise model\n",
    "wrapped_model.summary()\n",
    "\n",
    "# Make predictions\n",
    "dc_pred_eval = wrapped_model.predict(dc_evaluation_data_pt2)\n",
    "\n",
    "model_name = \"MLP_Opt_DC_pt2\"\n",
    "model_evaluation.evaluate_model(model_name, dc_eval_label_data_pt2, dc_pred_eval)\n",
    "rmse, mae, r2 = model_evaluation.return_model_evaluation_stats(dc_eval_label_data_pt2, dc_pred_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}