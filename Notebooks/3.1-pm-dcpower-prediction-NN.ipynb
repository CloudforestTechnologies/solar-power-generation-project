{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36664bitd546b3131dc04b45b27adb02c244c21c",
   "display_name": "Python 3.6.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "3f92393cf9312ed24f4ccae2fdf5dee1635074d2034ccfaec2d070f8b1ae4f04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "keras version = 2.4.0\nnumpy version = 1.19.4\nsklearn version = 0.22.2.post1\ntensorflow version = 2.4.1\n"
     ]
    }
   ],
   "source": [
    "# Module Importations\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "\n",
    "# Print versioning information\n",
    "print('keras version =', keras.__version__)\n",
    "print('numpy version =', np.__version__)  \n",
    "print('sklearn version =', sklearn.__version__)\n",
    "print('tensorflow version =', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[keras_helpers]Tensorflow version: 2.4.1\n[keras_helpers]keras version = 2.4.0\n"
     ]
    }
   ],
   "source": [
    "# Custom Module Imports\n",
    "from Source.data import load_data\n",
    "from Source.data import split_data\n",
    "from Source.models import model_evaluation\n",
    "from Source.models import keras_helpers\n",
    "from Source.models import tensorboard_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TRAIN_MODELS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading pickled dataframe started ...\n",
      "Loading pickled dataframe complete ...\n",
      "Loading pickled dataframe started ...\n",
      "Loading pickled dataframe complete ...\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df_plant1 = load_data.load_pickled_data(\"df_plant1_feat_eng.pkl\")\n",
    "df_plant2 = load_data.load_pickled_data(\"df_plant2_feat_eng.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 71808 entries, 0 to 71806\nData columns (total 20 columns):\n #   Column           Non-Null Count  Dtype         \n---  ------           --------------  -----         \n 0   DATE_TIME        71808 non-null  datetime64[ns]\n 1   PLANT_ID         71808 non-null  object        \n 2   SOURCE_KEY       71808 non-null  object        \n 3   DC_POWER         71808 non-null  float64       \n 4   DAILY_YIELD      71808 non-null  float64       \n 5   AMB_TEMP         71808 non-null  float64       \n 6   MOD_TEMP         71808 non-null  float64       \n 7   IRRADIATION      71808 non-null  float64       \n 8   DATE             71808 non-null  object        \n 9   TIME_OF_DAY      71808 non-null  object        \n 10  HOUR             71808 non-null  int64         \n 11  DAY              71808 non-null  int64         \n 12  WEEKDAY          71808 non-null  object        \n 13  MONTH            71808 non-null  int64         \n 14  YEAR             71808 non-null  int64         \n 15  AVG_HR_DC        71808 non-null  float64       \n 16  AVG_HR_YIELD     71808 non-null  float64       \n 17  AVG_DAILY_DC     71808 non-null  float64       \n 18  AVG_DAILY_YIELD  71808 non-null  float64       \n 19  DC-IRR_RATIO     71808 non-null  float64       \ndtypes: datetime64[ns](1), float64(10), int64(4), object(5)\nmemory usage: 11.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_plant1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 71808 entries, 0 to 71807\nData columns (total 4 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   DC_POWER     71808 non-null  float64\n 1   AMB_TEMP     71808 non-null  float64\n 2   MOD_TEMP     71808 non-null  float64\n 3   IRRADIATION  71808 non-null  float64\ndtypes: float64(4)\nmemory usage: 2.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Drop unrequired data columns\n",
    "\n",
    "# Identify columns to drop\n",
    "cols_to_keep = ['DC_POWER', 'AMB_TEMP', 'MOD_TEMP', 'IRRADIATION', 'TIME_FLOAT']\n",
    "cols_to_drop = []\n",
    "\n",
    "for col in df_plant1.columns:\n",
    "    if col not in cols_to_keep:\n",
    "        cols_to_drop.append(col)\n",
    "\n",
    "for df in [df_plant1, df_plant2]:\n",
    "    df.drop(cols_to_drop, axis = 1, inplace = True)\n",
    "\n",
    "df_plant2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original Data Items: 71808\n",
      "Training Data Items: 57447\n",
      "Evaluation Data Items: 14361\n",
      "Original Data Items: 71808\n",
      "Training Data Items: 57447\n",
      "Evaluation Data Items: 14361\n"
     ]
    }
   ],
   "source": [
    "# Split data into training / evaluation sets\n",
    "training_set_plant1, evaluation_set_plant1 = split_data.split_train_eval(df_plant1, 0.2)\n",
    "training_set_plant2, evaluation_set_plant2 = split_data.split_train_eval(df_plant2, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DC Power Target datasets\n",
    "\n",
    "# Modify training sets\n",
    "dc_power_training_data_pt1 = training_set_plant1.drop('DC_POWER', axis = 1)\n",
    "dc_label_data_pt1 = training_set_plant1['DC_POWER'].copy()\n",
    "\n",
    "dc_power_training_data_pt2 = training_set_plant2.drop('DC_POWER', axis = 1)\n",
    "dc_label_data_pt2 = training_set_plant2['DC_POWER'].copy()\n",
    "\n",
    "# Modify evaluation sets\n",
    "dc_evaluation_data_pt1 = evaluation_set_plant1.drop('DC_POWER', axis = 1)\n",
    "dc_eval_label_data_pt1 = evaluation_set_plant1['DC_POWER'].copy()\n",
    "\n",
    "dc_evaluation_data_pt2 = evaluation_set_plant2.drop('DC_POWER', axis = 1)\n",
    "dc_eval_label_data_pt2 = evaluation_set_plant2['DC_POWER'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Plant 1:\n",
      "Fit Train: (57447, 3)\n",
      "Fit Label: (57447,)\n",
      "Eval Train: (14361, 3)\n",
      "Eval Label: (14361,)\n",
      "Plant 2:\n",
      "Fit Train: (57447, 3)\n",
      "Fit Label: (57447,)\n",
      "Eval Train: (14361, 3)\n",
      "Eval Label: (14361,)\n"
     ]
    }
   ],
   "source": [
    "# Check shape of arrays\n",
    "print('Plant 1:')\n",
    "print('Fit Train:', dc_power_training_data_pt1.shape)\n",
    "print('Fit Label:', dc_label_data_pt1.shape)\n",
    "print('Eval Train:', dc_evaluation_data_pt1.shape)\n",
    "print('Eval Label:', dc_eval_label_data_pt1.shape)\n",
    "\n",
    "print('Plant 2:')\n",
    "print('Fit Train:', dc_power_training_data_pt2.shape)\n",
    "print('Fit Label:', dc_label_data_pt2.shape)\n",
    "print('Eval Train:', dc_evaluation_data_pt2.shape)\n",
    "print('Eval Label:', dc_eval_label_data_pt2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise Inputs\n",
    "normalise_inputs = True\n",
    "normalise_outputs = False\n",
    "\n",
    "normaliser = MinMaxScaler()\n",
    "\n",
    "if normalise_inputs == True:\n",
    "\n",
    "    # Transform training sets\n",
    "    dc_power_training_data_pt1 = normaliser.fit_transform(dc_power_training_data_pt1)\n",
    "    dc_power_training_data_pt2 = normaliser.fit_transform(dc_power_training_data_pt2)\n",
    "\n",
    "    # Transform evaluation sets\n",
    "    dc_evaluation_data_pt1 = normaliser.fit_transform(dc_evaluation_data_pt1)\n",
    "    dc_evaluation_data_pt2 = normaliser.fit_transform(dc_evaluation_data_pt2)\n",
    "\n",
    "if normalise_outputs == True:\n",
    "\n",
    "    # Transform training sets\n",
    "    dc_label_data_pt1 = normaliser.fit_transform(dc_label_data_pt1)\n",
    "    dc_label_data_pt2 = normaliser.fit_transform(dc_label_data_pt2)\n",
    "\n",
    "    # Transform evaluation sets\n",
    "    dc_eval_label_data_pt1 = normaliser.fit_transform(dc_eval_label_data_pt1)\n",
    "    dc_eval_label_data_pt2 = normaliser.fit_transform(dc_eval_label_data_pt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.69418927, 0.39836143, 0.24685468],\n",
       "       [0.10297219, 0.06348367, 0.02010156],\n",
       "       [0.10195445, 0.0510256 , 0.        ],\n",
       "       ...,\n",
       "       [0.3994604 , 0.20367104, 0.07955333],\n",
       "       [0.31878711, 0.09578908, 0.        ],\n",
       "       [0.45269604, 0.48094315, 0.44556097]])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Check values after normalisation\n",
    "dc_power_training_data_pt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.77310878 0.77031963 0.62255649]\n [0.31338184 0.08745068 0.        ]\n [0.26876718 0.23906034 0.09710624]\n ...\n [0.11465821 0.06056427 0.        ]\n [0.15250767 0.05541926 0.        ]\n [0.25835535 0.07128375 0.        ]]\n16030    936.842857\n4052       0.000000\n71148    178.350000\n71233    154.514286\n24592    414.100000\n            ...    \n14020    560.000000\n50198     31.471429\n65767      0.000000\n50797      0.000000\n12524      0.000000\nName: DC_POWER, Length: 45957, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create train and test arrays (plant 1)\n",
    "X_train_pt1, X_test_pt1, y_train_pt1, y_test_pt1 = train_test_split(dc_power_training_data_pt1, dc_label_data_pt1, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(X_train_pt1)\n",
    "print(y_train_pt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Building Model ...\n",
      "Hidden Layers: 2, Neurons: 6, LR: 0.001\n",
      "Epoch 1/20\n",
      "1437/1437 [==============================] - 3s 2ms/step - loss: 244161.9698 - val_loss: 171518.1094\n",
      "Epoch 2/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 136685.8997 - val_loss: 62973.9766\n",
      "Epoch 3/20\n",
      "1437/1437 [==============================] - 3s 2ms/step - loss: 53023.3885 - val_loss: 26594.2344\n",
      "Epoch 4/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 19246.8284 - val_loss: 8780.0723\n",
      "Epoch 5/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 7643.8439 - val_loss: 6619.6387\n",
      "Epoch 6/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 6020.3356 - val_loss: 5531.0571\n",
      "Epoch 7/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 4874.6056 - val_loss: 4872.6143\n",
      "Epoch 8/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 4148.5682 - val_loss: 4558.2637\n",
      "Epoch 9/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 4061.5805 - val_loss: 4426.1777\n",
      "Epoch 10/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3795.1100 - val_loss: 4373.6572\n",
      "Epoch 11/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3819.9318 - val_loss: 4349.0522\n",
      "Epoch 12/20\n",
      "1437/1437 [==============================] - 1s 972us/step - loss: 3692.0462 - val_loss: 4337.6289\n",
      "Epoch 13/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3713.9473 - val_loss: 4311.4849\n",
      "Epoch 14/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3672.7404 - val_loss: 4293.1030\n",
      "Epoch 15/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3579.1174 - val_loss: 4280.9619\n",
      "Epoch 16/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3800.4794 - val_loss: 4261.2764\n",
      "Epoch 17/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3660.5518 - val_loss: 4243.4209\n",
      "Epoch 18/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3745.1423 - val_loss: 4226.9316\n",
      "Epoch 19/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3609.1998 - val_loss: 4237.5171\n",
      "Epoch 20/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3599.0276 - val_loss: 4200.6177\n"
     ]
    }
   ],
   "source": [
    "# Initial MLP (Target - DC Power, Plant 1)\n",
    "\n",
    "if TRAIN_MODELS == True:\n",
    "    # Clear existing models\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Build model\n",
    "    model = keras_helpers.build_multilayer_perceptron()\n",
    "\n",
    "    # Name model\n",
    "    model_type = \"MLP_DC_Plant1\"\n",
    "    model_id = keras_helpers.name_model(model_type)\n",
    "    filepath_full = keras_helpers.make_save_string(model_id)\n",
    "\n",
    "    # Set save and earlystop callbacks\n",
    "    earlystop_cb = keras.callbacks.EarlyStopping(patience = 5)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = filepath_full, save_best_only = True)\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train_pt1, y_train_pt1, epochs = 20, validation_data = (X_test_pt1, y_test_pt1), callbacks =[checkpoint_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 73\n",
      "Trainable params: 73\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "MLP_DC_Plant1 rmse (Eval): 59.35426433426009\n",
      "MLP_DC_Plant1 mae (Eval): 26.787312447595937\n",
      "MLP_DC_Plant1 r2 (Eval): 0.9778972525587872\n"
     ]
    }
   ],
   "source": [
    "# Evaluate MLP Model (DC Power, Plant 1)\n",
    "\n",
    "if TRAIN_MODELS == False:\n",
    "    filepath_full = r'C:\\Developer\\solar-power-generation-project\\Models\\WJ_MLP_DC_2021_01_13-16_10_50.h5'\n",
    "\n",
    "# Load model\n",
    "model = keras.models.load_model(filepath_full)\n",
    "\n",
    "# Summarise model\n",
    "model.summary()\n",
    "\n",
    "# Make predictions\n",
    "dc_pred_eval = model.predict(dc_evaluation_data_pt1)\n",
    "\n",
    "# Determine model prediction stats\n",
    "model_name = \"MLP_DC_Plant1\"\n",
    "model_evaluation.evaluate_model(model_name, dc_eval_label_data_pt1, dc_pred_eval)\n",
    "rmse, mae, r2 = model_evaluation.return_model_evaluation_stats(dc_eval_label_data_pt1, dc_pred_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "c:\\Developer\\solar-power-generation-project\\Models\\TensorBoard\\run_2021_06_10-14_00_52\n"
     ]
    }
   ],
   "source": [
    "# Setup tensorboard for logging \n",
    "x = tensorboard_helpers.get_run_logdir()\n",
    "\n",
    "# Print tensorboard directory\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 20, LR: 0.001\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 4694.4902\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 20, LR: 0.001\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 2990.0566\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 20, LR: 0.001\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 3122.4788\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 80, LR: 0.1\n",
      "479/479 [==============================] - 1s 1ms/step - loss: nan\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 80, LR: 0.1\n",
      "479/479 [==============================] - 1s 1ms/step - loss: nan\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 80, LR: 0.1\n",
      "479/479 [==============================] - 1s 1ms/step - loss: nan\n",
      "Building Model ...\n",
      "Hidden Layers: 4, Neurons: 40, LR: 0.1\n",
      "479/479 [==============================] - 0s 788us/step - loss: 5452.6772\n",
      "Building Model ...\n",
      "Hidden Layers: 4, Neurons: 40, LR: 0.1\n",
      "479/479 [==============================] - 0s 793us/step - loss: 5607.8579\n",
      "Building Model ...\n",
      "Hidden Layers: 4, Neurons: 40, LR: 0.1\n",
      "479/479 [==============================] - 0s 791us/step - loss: 4878.2720\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 5, LR: 0.0001\n",
      "479/479 [==============================] - 0s 855us/step - loss: 3556.9795\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 5, LR: 0.0001\n",
      "479/479 [==============================] - 0s 880us/step - loss: 161493.7344\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 5, LR: 0.0001\n",
      "479/479 [==============================] - 0s 853us/step - loss: 2957.9561\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 10, LR: 0.1\n",
      "479/479 [==============================] - 0s 833us/step - loss: 162054.8594\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 10, LR: 0.1\n",
      "479/479 [==============================] - 0s 837us/step - loss: 161617.1719\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 10, LR: 0.1\n",
      "479/479 [==============================] - 0s 857us/step - loss: 160812.5469\n",
      "Building Model ...\n",
      "Hidden Layers: 20, Neurons: 10, LR: 0.1\n",
      "479/479 [==============================] - 0s 924us/step - loss: 161720.3750\n",
      "Building Model ...\n",
      "Hidden Layers: 20, Neurons: 10, LR: 0.1\n",
      "479/479 [==============================] - 0s 906us/step - loss: 164089.2500\n",
      "Building Model ...\n",
      "Hidden Layers: 20, Neurons: 10, LR: 0.1\n",
      "479/479 [==============================] - 0s 988us/step - loss: 163569.6562\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 20, LR: 0.1\n",
      "479/479 [==============================] - 0s 917us/step - loss: 162909.9375\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 20, LR: 0.1\n",
      "479/479 [==============================] - 0s 914us/step - loss: 161687.2812\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 20, LR: 0.1\n",
      "479/479 [==============================] - 0s 895us/step - loss: 161485.1250\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 100, LR: 0.001\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 8855.2305\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 100, LR: 0.001\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 4266.7588\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 100, LR: 0.001\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 3060.0854\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 60, LR: 0.01\n",
      "479/479 [==============================] - 0s 943us/step - loss: 18126.9688\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 60, LR: 0.01\n",
      "479/479 [==============================] - 0s 987us/step - loss: 9007.1387\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 60, LR: 0.01\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 6731.5122\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 5, LR: 0.0001\n",
      "479/479 [==============================] - 0s 729us/step - loss: 3790.1318\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 5, LR: 0.0001\n",
      "479/479 [==============================] - 0s 760us/step - loss: 3001.9844\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 5, LR: 0.0001\n",
      "479/479 [==============================] - 0s 772us/step - loss: 2698.5608\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 5, LR: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Optimised MLP (Target - DC Power, Plant 1)\n",
    "\n",
    "if TRAIN_MODELS == True:\n",
    "    \n",
    "    # Clear existing models\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Establish parameter distribution for tuning\n",
    "    param_distribs = {\n",
    "        \"n_hidden\": (4, 8, 12, 16, 20),\n",
    "        \"n_neurons\": (5, 10, 20, 40, 60, 80, 100),\n",
    "        \"learning_rate\": (1e-1, 1e-2, 1e-3, 1e-4),\n",
    "    }\n",
    "\n",
    "    # Build model\n",
    "    wrapped_model = keras_helpers.wrap_model()\n",
    "\n",
    "    # Initialise random search\n",
    "    rnd_search_cv = RandomizedSearchCV(wrapped_model, param_distribs, n_iter = 10, cv = 3)\n",
    "\n",
    "    # Name model\n",
    "    model_type = \"MLP_Opt_DC_Plant1\"\n",
    "    model_id = keras_helpers.name_model(model_type)\n",
    "    filepath_full = keras_helpers.make_save_string(model_id)\n",
    "\n",
    "    # Set save and earlystop callbacks\n",
    "    earlystop_cb = keras.callbacks.EarlyStopping(patience = 3)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = filepath_full, save_best_only = True)\n",
    "\n",
    "    # Set TensorBoard callback for logging\n",
    "    tb_logdir = tensorboard_helpers.get_run_logdir()\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(tb_logdir)\n",
    "\n",
    "    # Train model\n",
    "    rnd_search_cv.fit(X_train_pt1, y_train_pt1, epochs = 100, validation_data = (X_test_pt1, y_test_pt1), callbacks = [checkpoint_cb, earlystop_cb, tensorboard_cb], verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_405 (Dense)            (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "dense_406 (Dense)            (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_407 (Dense)            (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_408 (Dense)            (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_409 (Dense)            (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_410 (Dense)            (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_411 (Dense)            (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_412 (Dense)            (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_413 (Dense)            (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 236\n",
      "Trainable params: 236\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "MLP_Opt_DC_pt1 rmse (Eval): 54.71250485453789\n",
      "MLP_Opt_DC_pt1 mae (Eval): 22.047762884681138\n",
      "MLP_Opt_DC_pt1 r2 (Eval): 0.9812191344112421\n"
     ]
    }
   ],
   "source": [
    "# Evaluate MLP Model (DC Power, Plant 1)\n",
    "\n",
    "if TRAIN_MODELS == False:\n",
    "    filepath_full = r'C:\\Developer\\solar-power-generation-project\\Models\\WJ_MLP_Opt_DC_Plant1_2021_06_10-11_34_55.h5'\n",
    "\n",
    "wrapped_model = keras.models.load_model(filepath_full)\n",
    "\n",
    "# Summarise model\n",
    "wrapped_model.summary()\n",
    "\n",
    "# Make predictions\n",
    "dc_pred_eval = wrapped_model.predict(dc_evaluation_data_pt1)\n",
    "\n",
    "model_name = \"MLP_Opt_DC_pt1\"\n",
    "model_evaluation.evaluate_model(model_name, dc_eval_label_data_pt1, dc_pred_eval)\n",
    "rmse, mae, r2 = model_evaluation.return_model_evaluation_stats(dc_eval_label_data_pt1, dc_pred_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test arrays (plant 2)\n",
    "X_train_pt2, X_test_pt2, y_train_pt2, y_test_pt2 = train_test_split(dc_power_training_data_pt2, dc_label_data_pt2, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(X_train_pt2)\n",
    "print(y_train_pt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Building Model ...\nHidden Layers: 2, Neurons: 6, LR: 0.001\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X_train_pt2' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-22b1c94b2655>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# Train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_pt2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_pt2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test_pt2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_pt2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint_cb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearlystop_cb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_pt2' is not defined"
     ]
    }
   ],
   "source": [
    "# Initial MLP (Target - DC Power, Plant 2)\n",
    "\n",
    "if TRAIN_MODELS == True:\n",
    "    \n",
    "    # Clear existing models\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Build model\n",
    "    model = keras_helpers.build_multilayer_perceptron()\n",
    "\n",
    "    # Name model\n",
    "    model_type = \"MLP_DC_Plant2\"\n",
    "    model_id = keras_helpers.name_model(model_type)\n",
    "    filepath_full = keras_helpers.make_save_string(model_id)\n",
    "\n",
    "    # Set save and earlystop callbacks\n",
    "    earlystop_cb = keras.callbacks.EarlyStopping(patience = 5)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = filepath_full, save_best_only = True)\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train_pt2, y_train_pt2, epochs = 20, validation_data = (X_test_pt2, y_test_pt2), callbacks =[checkpoint_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate MLP Model (DC Power, Plant 2)\n",
    "\n",
    "if TRAIN_MODELS == False:\n",
    "    filepath_full = r'C:\\Developer\\solar-power-generation-project\\Models\\WJ_MLP_DC_2021_01_13-16_10_50.h5'\n",
    "\n",
    "# Load model\n",
    "model = keras.models.load_model(filepath_full)\n",
    "\n",
    "# Summarise model\n",
    "model.summary()\n",
    "\n",
    "# Make predictions\n",
    "dc_pred_eval = model.predict(dc_evaluation_data_pt2)\n",
    "\n",
    "# Determine model prediction stats\n",
    "model_name = \"MLP_DC\"\n",
    "model_evaluation.evaluate_model(model_name, dc_eval_label_data_pt2, dc_pred_eval)\n",
    "rmse, mae, r2 = model_evaluation.return_model_evaluation_stats(dc_eval_label_data_pt2, dc_pred_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup tensorboard for logging \n",
    "x = tensorboard_helpers.get_run_logdir()\n",
    "\n",
    "# Print tensorboard directory\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimised MLP (Target - DC Power, Plant 2)\n",
    "\n",
    "if TRAIN_MODELS == True:\n",
    "    \n",
    "    # Clear existing models\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Establish parameter distribution for tuning\n",
    "    param_distribs = {\n",
    "        \"n_hidden\": (4, 8, 12, 16),\n",
    "        \"n_neurons\": np.arange(1, 100),\n",
    "        \"learning_rate\": (1e-1, 1e-2, 1e-3, 1e-4),\n",
    "    }\n",
    "\n",
    "    # Build model\n",
    "    wrapped_model = keras_helpers.wrap_model()\n",
    "\n",
    "    # Initialise random search\n",
    "    rnd_search_cv = RandomizedSearchCV(wrapped_model, param_distribs, n_iter = 10, cv = 3)\n",
    "\n",
    "    # Name model\n",
    "    model_type = \"MLP_Opt_DC_Plant1\"\n",
    "    model_id = keras_helpers.name_model(model_type)\n",
    "    filepath_full = keras_helpers.make_save_string(model_id)\n",
    "\n",
    "    # Set save and earlystop callbacks\n",
    "    earlystop_cb = keras.callbacks.EarlyStopping(patience = 3)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = filepath_full, save_best_only = True)\n",
    "\n",
    "    # Set TensorBoard callback for logging\n",
    "    tb_logdir = tensorboard_helpers.get_run_logdir()\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(tb_logdir)\n",
    "\n",
    "    # Train model\n",
    "    rnd_search_cv.fit(X_train_pt2, y_train_pt2, epochs = 100, validation_data = (X_test_pt2, y_test_pt2), callbacks = [checkpoint_cb, earlystop_cb, tensorboard_cb], verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate MLP Model (DC Power, Plant 2)\n",
    "\n",
    "if TRAIN_MODELS == False:\n",
    "    filepath_full = r'C:\\Developer\\solar-power-generation-project\\Models\\WJ_MLP_Opt_DC_2021_01_13-15_30_27.h5'\n",
    "\n",
    "wrapped_model = keras.models.load_model(filepath_full)\n",
    "\n",
    "# Summarise model\n",
    "wrapped_model.summary()\n",
    "\n",
    "# Make predictions\n",
    "dc_pred_eval = wrapped_model.predict(dc_evaluation_data)\n",
    "\n",
    "model_name = \"MLP_Opt_DC_pt2\"\n",
    "model_evaluation.evaluate_model(model_name, dc_eval_label_data_pt2, dc_pred_eval)\n",
    "rmse, mae, r2 = model_evaluation.return_model_evaluation_stats(dc_eval_label_data_pt2, dc_pred_eval)"
   ]
  }
 ]
}