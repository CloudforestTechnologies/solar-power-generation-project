{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36664bitd546b3131dc04b45b27adb02c244c21c",
   "display_name": "Python 3.6.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "3f92393cf9312ed24f4ccae2fdf5dee1635074d2034ccfaec2d070f8b1ae4f04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "keras version = 2.4.0\nnumpy version = 1.19.4\nsklearn version = 0.22.2.post1\ntensorflow version = 2.4.1\n"
     ]
    }
   ],
   "source": [
    "# Module Importations\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "\n",
    "# Print versioning information\n",
    "print('keras version =', keras.__version__)\n",
    "print('numpy version =', np.__version__)  \n",
    "print('sklearn version =', sklearn.__version__)\n",
    "print('tensorflow version =', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[keras_helpers]Tensorflow version: 2.4.1\n[keras_helpers]keras version = 2.4.0\n"
     ]
    }
   ],
   "source": [
    "# Custom Module Imports\n",
    "from Source.data import load_data\n",
    "from Source.data import split_data\n",
    "from Source.models import model_evaluation\n",
    "from Source.models import keras_helpers\n",
    "from Source.models import tensorboard_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TRAIN_MODELS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading pickled dataframe started ...\n",
      "Loading pickled dataframe complete ...\n",
      "Loading pickled dataframe started ...\n",
      "Loading pickled dataframe complete ...\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df_plant1 = load_data.load_pickled_data(\"df_plant1_feat_eng.pkl\")\n",
    "df_plant2 = load_data.load_pickled_data(\"df_plant2_feat_eng.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 71808 entries, 0 to 71806\nData columns (total 20 columns):\n #   Column           Non-Null Count  Dtype         \n---  ------           --------------  -----         \n 0   DATE_TIME        71808 non-null  datetime64[ns]\n 1   PLANT_ID         71808 non-null  object        \n 2   SOURCE_KEY       71808 non-null  object        \n 3   DC_POWER         71808 non-null  float64       \n 4   DAILY_YIELD      71808 non-null  float64       \n 5   AMB_TEMP         71808 non-null  float64       \n 6   MOD_TEMP         71808 non-null  float64       \n 7   IRRADIATION      71808 non-null  float64       \n 8   DATE             71808 non-null  object        \n 9   TIME_OF_DAY      71808 non-null  object        \n 10  HOUR             71808 non-null  int64         \n 11  DAY              71808 non-null  int64         \n 12  WEEKDAY          71808 non-null  object        \n 13  MONTH            71808 non-null  int64         \n 14  YEAR             71808 non-null  int64         \n 15  AVG_HR_DC        71808 non-null  float64       \n 16  AVG_HR_YIELD     71808 non-null  float64       \n 17  AVG_DAILY_DC     71808 non-null  float64       \n 18  AVG_DAILY_YIELD  71808 non-null  float64       \n 19  DC-IRR_RATIO     71808 non-null  float64       \ndtypes: datetime64[ns](1), float64(10), int64(4), object(5)\nmemory usage: 11.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_plant1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 71808 entries, 0 to 71807\nData columns (total 4 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   DC_POWER     71808 non-null  float64\n 1   AMB_TEMP     71808 non-null  float64\n 2   MOD_TEMP     71808 non-null  float64\n 3   IRRADIATION  71808 non-null  float64\ndtypes: float64(4)\nmemory usage: 2.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Drop unrequired data columns\n",
    "\n",
    "# Identify columns to drop\n",
    "cols_to_keep = ['DC_POWER', 'AMB_TEMP', 'MOD_TEMP', 'IRRADIATION', 'TIME_FLOAT']\n",
    "cols_to_drop = []\n",
    "\n",
    "for col in df_plant1.columns:\n",
    "    if col not in cols_to_keep:\n",
    "        cols_to_drop.append(col)\n",
    "\n",
    "for df in [df_plant1, df_plant2]:\n",
    "    df.drop(cols_to_drop, axis = 1, inplace = True)\n",
    "\n",
    "df_plant2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original Data Items: 71808\n",
      "Training Data Items: 57447\n",
      "Evaluation Data Items: 14361\n",
      "Original Data Items: 71808\n",
      "Training Data Items: 57447\n",
      "Evaluation Data Items: 14361\n"
     ]
    }
   ],
   "source": [
    "# Split data into training / evaluation sets\n",
    "training_set_plant1, evaluation_set_plant1 = split_data.split_train_eval(df_plant1, 0.2)\n",
    "training_set_plant2, evaluation_set_plant2 = split_data.split_train_eval(df_plant2, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DC Power Target datasets\n",
    "\n",
    "# Modify training sets\n",
    "dc_power_training_data_pt1 = training_set_plant1.drop('DC_POWER', axis = 1)\n",
    "dc_label_data_pt1 = training_set_plant1['DC_POWER'].copy()\n",
    "\n",
    "dc_power_training_data_pt2 = training_set_plant2.drop('DC_POWER', axis = 1)\n",
    "dc_label_data_pt2 = training_set_plant2['DC_POWER'].copy()\n",
    "\n",
    "# Modify evaluation sets\n",
    "dc_evaluation_data_pt1 = evaluation_set_plant1.drop('DC_POWER', axis = 1)\n",
    "dc_eval_label_data_pt1 = evaluation_set_plant1['DC_POWER'].copy()\n",
    "\n",
    "dc_evaluation_data_pt2 = evaluation_set_plant2.drop('DC_POWER', axis = 1)\n",
    "dc_eval_label_data_pt2 = evaluation_set_plant2['DC_POWER'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Plant 1:\nFit Train: (57447, 3)\nFit Label: (57447,)\nEval Train: (14361, 3)\nEval Label: (14361,)\nPlant 2:\nFit Train: (57447, 3)\nFit Label: (57447,)\nEval Train: (14361, 3)\nEval Label: (14361,)\n"
     ]
    }
   ],
   "source": [
    "# Check shape of arrays\n",
    "print('Plant 1:')\n",
    "print('Fit Train:', dc_power_training_data_pt1.shape)\n",
    "print('Fit Label:', dc_label_data_pt1.shape)\n",
    "print('Eval Train:', dc_evaluation_data_pt1.shape)\n",
    "print('Eval Label:', dc_eval_label_data_pt1.shape)\n",
    "\n",
    "print('Plant 2:')\n",
    "print('Fit Train:', dc_power_training_data_pt2.shape)\n",
    "print('Fit Label:', dc_label_data_pt2.shape)\n",
    "print('Eval Train:', dc_evaluation_data_pt2.shape)\n",
    "print('Eval Label:', dc_eval_label_data_pt2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise Inputs\n",
    "normalise_inputs = True\n",
    "normalise_outputs = False\n",
    "\n",
    "normaliser = MinMaxScaler()\n",
    "\n",
    "if normalise_inputs == True:\n",
    "\n",
    "    # Transform training sets\n",
    "    dc_power_training_data_pt1 = normaliser.fit_transform(dc_power_training_data_pt1)\n",
    "    dc_power_training_data_pt2 = normaliser.fit_transform(dc_power_training_data_pt2)\n",
    "\n",
    "    # Transform evaluation sets\n",
    "    dc_evaluation_data_pt1 = normaliser.fit_transform(dc_evaluation_data_pt1)\n",
    "    dc_evaluation_data_pt2 = normaliser.fit_transform(dc_evaluation_data_pt2)\n",
    "\n",
    "if normalise_outputs == True:\n",
    "\n",
    "    # Transform training sets\n",
    "    dc_label_data_pt1 = normaliser.fit_transform(dc_label_data_pt1)\n",
    "    dc_label_data_pt2 = normaliser.fit_transform(dc_label_data_pt2)\n",
    "\n",
    "    # Transform evaluation sets\n",
    "    dc_eval_label_data_pt1 = normaliser.fit_transform(dc_eval_label_data_pt1)\n",
    "    dc_eval_label_data_pt2 = normaliser.fit_transform(dc_eval_label_data_pt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.69418927, 0.39836143, 0.24685468],\n",
       "       [0.10297219, 0.06348367, 0.02010156],\n",
       "       [0.10195445, 0.0510256 , 0.        ],\n",
       "       ...,\n",
       "       [0.3994604 , 0.20367104, 0.07955333],\n",
       "       [0.31878711, 0.09578908, 0.        ],\n",
       "       [0.45269604, 0.48094315, 0.44556097]])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Check values after normalisation\n",
    "dc_power_training_data_pt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.77310878 0.77031963 0.62255649]\n",
      " [0.31338184 0.08745068 0.        ]\n",
      " [0.26876718 0.23906034 0.09710624]\n",
      " ...\n",
      " [0.11465821 0.06056427 0.        ]\n",
      " [0.15250767 0.05541926 0.        ]\n",
      " [0.25835535 0.07128375 0.        ]]\n",
      "16030    936.842857\n",
      "4052       0.000000\n",
      "71148    178.350000\n",
      "71233    154.514286\n",
      "24592    414.100000\n",
      "            ...    \n",
      "14020    560.000000\n",
      "50198     31.471429\n",
      "65767      0.000000\n",
      "50797      0.000000\n",
      "12524      0.000000\n",
      "Name: DC_POWER, Length: 45957, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create train and test arrays (plant 1)\n",
    "X_train_pt1, X_test_pt1, y_train_pt1, y_test_pt1 = train_test_split(dc_power_training_data_pt1, dc_label_data_pt1, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(X_train_pt1)\n",
    "print(y_train_pt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Building Model ...\n",
      "Hidden Layers: 2, Neurons: 6, LR: 0.001\n",
      "Epoch 1/20\n",
      "1437/1437 [==============================] - 3s 1ms/step - loss: 250292.3343 - val_loss: 228765.3906\n",
      "Epoch 2/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 215120.9175 - val_loss: 151647.5312\n",
      "Epoch 3/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 129083.5534 - val_loss: 79704.8672\n",
      "Epoch 4/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 72196.4320 - val_loss: 53380.8281\n",
      "Epoch 5/20\n",
      "1437/1437 [==============================] - 2s 2ms/step - loss: 46712.8011 - val_loss: 30725.6777\n",
      "Epoch 6/20\n",
      "1437/1437 [==============================] - 2s 2ms/step - loss: 25523.1400 - val_loss: 13370.3105\n",
      "Epoch 7/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 10659.0232 - val_loss: 8260.7764\n",
      "Epoch 8/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 7406.4637 - val_loss: 6955.7256\n",
      "Epoch 9/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 5964.7642 - val_loss: 6139.0718\n",
      "Epoch 10/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 5936.8710 - val_loss: 5521.9326\n",
      "Epoch 11/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 5082.0182 - val_loss: 5042.1631\n",
      "Epoch 12/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 4617.9474 - val_loss: 4730.6660\n",
      "Epoch 13/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 4291.6932 - val_loss: 4527.2168\n",
      "Epoch 14/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 4225.7193 - val_loss: 4416.0547\n",
      "Epoch 15/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 4001.5167 - val_loss: 4357.8296\n",
      "Epoch 16/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3736.0061 - val_loss: 4324.9976\n",
      "Epoch 17/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3928.7167 - val_loss: 4305.9355\n",
      "Epoch 18/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3961.6213 - val_loss: 4299.5933\n",
      "Epoch 19/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3656.0683 - val_loss: 4290.9990\n",
      "Epoch 20/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 3703.1986 - val_loss: 4274.3604\n"
     ]
    }
   ],
   "source": [
    "# Initial MLP (Target - DC Power, Plant 1)\n",
    "\n",
    "if TRAIN_MODELS == True:\n",
    "    # Clear existing models\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Build model\n",
    "    model = keras_helpers.build_multilayer_perceptron()\n",
    "\n",
    "    # Name model\n",
    "    model_type = \"MLP_DC_Plant1\"\n",
    "    model_id = keras_helpers.name_model(model_type)\n",
    "    filepath_full = keras_helpers.make_save_string(model_id)\n",
    "\n",
    "    # Set save and earlystop callbacks\n",
    "    earlystop_cb = keras.callbacks.EarlyStopping(patience = 5)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = filepath_full, save_best_only = True)\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train_pt1, y_train_pt1, epochs = 20, validation_data = (X_test_pt1, y_test_pt1), callbacks =[checkpoint_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 73\n",
      "Trainable params: 73\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "MLP_DC_Plant1 rmse (Eval): 59.95899219697316\n",
      "MLP_DC_Plant1 mae (Eval): 27.270555798860315\n",
      "MLP_DC_Plant1 r2 (Eval): 0.9774445727885336\n"
     ]
    }
   ],
   "source": [
    "# Evaluate MLP Model (DC Power, Plant 1)\n",
    "\n",
    "if TRAIN_MODELS == False:\n",
    "    filepath_full = r'C:\\Developer\\solar-power-generation-project\\Models\\WJ_MLP_DC_2021_01_13-16_10_50.h5'\n",
    "\n",
    "# Load model\n",
    "model = keras.models.load_model(filepath_full)\n",
    "\n",
    "# Summarise model\n",
    "model.summary()\n",
    "\n",
    "# Make predictions\n",
    "dc_pred_eval = model.predict(dc_evaluation_data_pt1)\n",
    "\n",
    "# Determine model prediction stats\n",
    "model_name = \"MLP_DC_Plant1\"\n",
    "model_evaluation.evaluate_model(model_name, dc_eval_label_data_pt1, dc_pred_eval)\n",
    "rmse, mae, r2 = model_evaluation.return_model_evaluation_stats(dc_eval_label_data_pt1, dc_pred_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "c:\\Developer\\solar-power-generation-project\\Models\\TensorBoard\\run_2021_06_10-14_45_51\n"
     ]
    }
   ],
   "source": [
    "# Setup tensorboard for logging \n",
    "x = tensorboard_helpers.get_run_logdir()\n",
    "\n",
    "# Print tensorboard directory\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 20, LR: 0.001\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 3552.6003\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 20, LR: 0.001\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 3012.4507\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 20, LR: 0.001\n",
      "479/479 [==============================] - 0s 904us/step - loss: 2697.1465\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 80, LR: 0.1\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 160779.6250\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 80, LR: 0.1\n",
      "479/479 [==============================] - 1s 1ms/step - loss: nan\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 80, LR: 0.1\n",
      "479/479 [==============================] - 0s 1000us/step - loss: 163493.2812\n",
      "Building Model ...\n",
      "Hidden Layers: 4, Neurons: 40, LR: 0.1\n",
      "479/479 [==============================] - 0s 955us/step - loss: 9248.6943\n",
      "Building Model ...\n",
      "Hidden Layers: 4, Neurons: 40, LR: 0.1\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 3095.2485\n",
      "Building Model ...\n",
      "Hidden Layers: 4, Neurons: 40, LR: 0.1\n",
      "479/479 [==============================] - 0s 981us/step - loss: 13456.0938\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 5, LR: 0.0001\n",
      "479/479 [==============================] - 0s 937us/step - loss: 249660.6406\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 5, LR: 0.0001\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 161493.4375\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 5, LR: 0.0001\n",
      "479/479 [==============================] - 0s 788us/step - loss: 160799.8906\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 10, LR: 0.1\n",
      "479/479 [==============================] - 0s 817us/step - loss: 160664.2500\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 10, LR: 0.1\n",
      "479/479 [==============================] - 0s 875us/step - loss: 162005.2500\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 10, LR: 0.1\n",
      "479/479 [==============================] - 1s 3ms/step - loss: 161005.0938\n",
      "Building Model ...\n",
      "Hidden Layers: 20, Neurons: 10, LR: 0.1\n",
      "479/479 [==============================] - 1s 2ms/step - loss: 162231.2500\n",
      "Building Model ...\n",
      "Hidden Layers: 20, Neurons: 10, LR: 0.1\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 162173.2344\n",
      "Building Model ...\n",
      "Hidden Layers: 20, Neurons: 10, LR: 0.1\n",
      "479/479 [==============================] - 0s 884us/step - loss: 162689.7500\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 20, LR: 0.1\n",
      "479/479 [==============================] - 0s 945us/step - loss: 160965.4219\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 20, LR: 0.1\n",
      "479/479 [==============================] - 0s 871us/step - loss: 162454.0312\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 20, LR: 0.1\n",
      "479/479 [==============================] - 0s 979us/step - loss: 169062.3125\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 100, LR: 0.001\n",
      "479/479 [==============================] - 1s 2ms/step - loss: 5726.0845\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 100, LR: 0.001\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 3297.8442\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 100, LR: 0.001\n",
      "479/479 [==============================] - 1s 2ms/step - loss: 4764.0029\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 60, LR: 0.01\n",
      "479/479 [==============================] - 0s 978us/step - loss: 5280.9722\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 60, LR: 0.01\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 3520.2791\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 60, LR: 0.01\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 8659.6953\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 5, LR: 0.0001\n",
      "479/479 [==============================] - 0s 814us/step - loss: 3667.1904\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 5, LR: 0.0001\n",
      "479/479 [==============================] - 0s 816us/step - loss: 3144.9392\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 5, LR: 0.0001\n",
      "479/479 [==============================] - 0s 827us/step - loss: 2755.7036\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 20, LR: 0.001\n"
     ]
    }
   ],
   "source": [
    "# Optimised MLP (Target - DC Power, Plant 1)\n",
    "\n",
    "if TRAIN_MODELS == True:\n",
    "    \n",
    "    # Clear existing models\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Establish parameter distribution for tuning\n",
    "    param_distribs = {\n",
    "        \"n_hidden\": (4, 8, 12, 16, 20),\n",
    "        \"n_neurons\": (5, 10, 20, 40, 60, 80, 100),\n",
    "        \"learning_rate\": (1e-1, 1e-2, 1e-3, 1e-4),\n",
    "    }\n",
    "\n",
    "    # Build model\n",
    "    wrapped_model = keras_helpers.wrap_model()\n",
    "\n",
    "    # Initialise random search\n",
    "    rnd_search_cv = RandomizedSearchCV(wrapped_model, param_distribs, n_iter = 10, cv = 3)\n",
    "\n",
    "    # Name model\n",
    "    model_type = \"MLP_Opt_DC_Plant1\"\n",
    "    model_id = keras_helpers.name_model(model_type)\n",
    "    filepath_full = keras_helpers.make_save_string(model_id)\n",
    "\n",
    "    # Set save and earlystop callbacks\n",
    "    earlystop_cb = keras.callbacks.EarlyStopping(patience = 3)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = filepath_full, save_best_only = True)\n",
    "\n",
    "    # Set TensorBoard callback for logging\n",
    "    tb_logdir = tensorboard_helpers.get_run_logdir()\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(tb_logdir)\n",
    "\n",
    "    # Train model\n",
    "    rnd_search_cv.fit(X_train_pt1, y_train_pt1, epochs = 100, validation_data = (X_test_pt1, y_test_pt1), callbacks = [checkpoint_cb, earlystop_cb, tensorboard_cb], verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_414 (Dense)            (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_415 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_416 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_417 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_418 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_419 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_420 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_421 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_422 (Dense)            (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 3,041\n",
      "Trainable params: 3,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "MLP_Opt_DC_pt1 rmse (Eval): 54.910606358214864\n",
      "MLP_Opt_DC_pt1 mae (Eval): 23.238881831177757\n",
      "MLP_Opt_DC_pt1 r2 (Eval): 0.9810828857311089\n"
     ]
    }
   ],
   "source": [
    "# Evaluate MLP Model (DC Power, Plant 1)\n",
    "\n",
    "if TRAIN_MODELS == False:\n",
    "    filepath_full = r'C:\\Developer\\solar-power-generation-project\\Models\\WJ_MLP_Opt_DC_Plant1_2021_06_10-11_34_55.h5'\n",
    "\n",
    "wrapped_model = keras.models.load_model(filepath_full)\n",
    "\n",
    "# Summarise model\n",
    "wrapped_model.summary()\n",
    "\n",
    "# Make predictions\n",
    "dc_pred_eval = wrapped_model.predict(dc_evaluation_data_pt1)\n",
    "\n",
    "model_name = \"MLP_Opt_DC_pt1\"\n",
    "model_evaluation.evaluate_model(model_name, dc_eval_label_data_pt1, dc_pred_eval)\n",
    "rmse, mae, r2 = model_evaluation.return_model_evaluation_stats(dc_eval_label_data_pt1, dc_pred_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.78718932 0.86385524 0.75714748]\n [0.40111725 0.13940226 0.        ]\n [0.366359   0.24734289 0.16542722]\n ...\n [0.17626336 0.06610678 0.        ]\n [0.19348786 0.04786465 0.        ]\n [0.30564703 0.10208519 0.        ]]\n16031    1196.980000\n4052        0.000000\n71148     285.164286\n71234     140.678571\n24593     896.435714\n            ...     \n14020     872.093333\n50199      57.906667\n65768       0.000000\n50783       0.000000\n12524       0.000000\nName: DC_POWER, Length: 45957, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create train and test arrays (plant 2)\n",
    "X_train_pt2, X_test_pt2, y_train_pt2, y_test_pt2 = train_test_split(dc_power_training_data_pt2, dc_label_data_pt2, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(X_train_pt2)\n",
    "print(y_train_pt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Building Model ...\n",
      "Hidden Layers: 2, Neurons: 6, LR: 0.001\n",
      "Epoch 1/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 197515.2842 - val_loss: 150300.2344\n",
      "Epoch 2/20\n",
      "1437/1437 [==============================] - 1s 1ms/step - loss: 124684.7806 - val_loss: 79558.6719\n",
      "Epoch 3/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 72511.7871 - val_loss: 58683.9023\n",
      "Epoch 4/20\n",
      "1437/1437 [==============================] - 1s 1ms/step - loss: 55345.7499 - val_loss: 53198.1328\n",
      "Epoch 5/20\n",
      "1437/1437 [==============================] - 1s 1ms/step - loss: 51637.2639 - val_loss: 51309.4453\n",
      "Epoch 6/20\n",
      "1437/1437 [==============================] - 1s 1ms/step - loss: 49608.9868 - val_loss: 50231.6680\n",
      "Epoch 7/20\n",
      "1437/1437 [==============================] - 1s 1ms/step - loss: 49110.8256 - val_loss: 49751.2109\n",
      "Epoch 8/20\n",
      "1437/1437 [==============================] - 1s 1ms/step - loss: 48454.0136 - val_loss: 49670.0117\n",
      "Epoch 9/20\n",
      "1437/1437 [==============================] - 1s 985us/step - loss: 48680.8842 - val_loss: 49496.8164\n",
      "Epoch 10/20\n",
      "1437/1437 [==============================] - 1s 1ms/step - loss: 48120.5373 - val_loss: 49365.6680\n",
      "Epoch 11/20\n",
      "1437/1437 [==============================] - 1s 1ms/step - loss: 47568.0505 - val_loss: 49279.5781\n",
      "Epoch 12/20\n",
      "1437/1437 [==============================] - 1s 1ms/step - loss: 48287.3719 - val_loss: 49183.6641\n",
      "Epoch 13/20\n",
      "1437/1437 [==============================] - 1s 1ms/step - loss: 47109.2527 - val_loss: 49105.7188\n",
      "Epoch 14/20\n",
      "1437/1437 [==============================] - 1s 1ms/step - loss: 46812.3192 - val_loss: 49037.7031\n",
      "Epoch 15/20\n",
      "1437/1437 [==============================] - 1s 1ms/step - loss: 47561.6704 - val_loss: 48960.3828\n",
      "Epoch 16/20\n",
      "1437/1437 [==============================] - 1s 1ms/step - loss: 47611.6635 - val_loss: 48905.2344\n",
      "Epoch 17/20\n",
      "1437/1437 [==============================] - 2s 1ms/step - loss: 47945.1083 - val_loss: 48837.7969\n",
      "Epoch 18/20\n",
      "1437/1437 [==============================] - 1s 1ms/step - loss: 47560.5454 - val_loss: 48882.0625\n",
      "Epoch 19/20\n",
      "1437/1437 [==============================] - 1s 1ms/step - loss: 48049.1302 - val_loss: 48757.1758\n",
      "Epoch 20/20\n",
      "1437/1437 [==============================] - 1s 991us/step - loss: 47814.5405 - val_loss: 48760.9102\n"
     ]
    }
   ],
   "source": [
    "# Initial MLP (Target - DC Power, Plant 2)\n",
    "\n",
    "if TRAIN_MODELS == True:\n",
    "    \n",
    "    # Clear existing models\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Build model\n",
    "    model = keras_helpers.build_multilayer_perceptron()\n",
    "\n",
    "    # Name model\n",
    "    model_type = \"MLP_DC_Plant2\"\n",
    "    model_id = keras_helpers.name_model(model_type)\n",
    "    filepath_full = keras_helpers.make_save_string(model_id)\n",
    "\n",
    "    # Set save and earlystop callbacks\n",
    "    earlystop_cb = keras.callbacks.EarlyStopping(patience = 5)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = filepath_full, save_best_only = True)\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train_pt2, y_train_pt2, epochs = 20, validation_data = (X_test_pt2, y_test_pt2), callbacks =[checkpoint_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 73\n",
      "Trainable params: 73\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "MLP_DC rmse (Eval): 221.17277241850837\n",
      "MLP_DC mae (Eval): 101.48850922253169\n",
      "MLP_DC r2 (Eval): 0.645728052769732\n"
     ]
    }
   ],
   "source": [
    "# Evaluate MLP Model (DC Power, Plant 2)\n",
    "\n",
    "if TRAIN_MODELS == False:\n",
    "    filepath_full = r'C:\\Developer\\solar-power-generation-project\\Models\\WJ_MLP_DC_2021_01_13-16_10_50.h5'\n",
    "\n",
    "# Load model\n",
    "model = keras.models.load_model(filepath_full)\n",
    "\n",
    "# Summarise model\n",
    "model.summary()\n",
    "\n",
    "# Make predictions\n",
    "dc_pred_eval = model.predict(dc_evaluation_data_pt2)\n",
    "\n",
    "# Determine model prediction stats\n",
    "model_name = \"MLP_DC\"\n",
    "model_evaluation.evaluate_model(model_name, dc_eval_label_data_pt2, dc_pred_eval)\n",
    "rmse, mae, r2 = model_evaluation.return_model_evaluation_stats(dc_eval_label_data_pt2, dc_pred_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "c:\\Developer\\solar-power-generation-project\\Models\\TensorBoard\\run_2021_06_10-15_04_28\n"
     ]
    }
   ],
   "source": [
    "# Setup tensorboard for logging \n",
    "x = tensorboard_helpers.get_run_logdir()\n",
    "\n",
    "# Print tensorboard directory\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 32, LR: 0.1\n",
      "479/479 [==============================] - 0s 819us/step - loss: 136784.1250\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 32, LR: 0.1\n",
      "479/479 [==============================] - 0s 807us/step - loss: 137901.9531\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 32, LR: 0.1\n",
      "479/479 [==============================] - 0s 829us/step - loss: 137481.3750\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 31, LR: 0.1\n",
      "479/479 [==============================] - 0s 787us/step - loss: 53435.0039\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 31, LR: 0.1\n",
      "479/479 [==============================] - 0s 790us/step - loss: 138245.2344\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 31, LR: 0.1\n",
      "479/479 [==============================] - 0s 797us/step - loss: 137153.3125\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 85, LR: 0.001\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 47196.8945\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 85, LR: 0.001\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 51515.8438\n",
      "Building Model ...\n",
      "Hidden Layers: 16, Neurons: 85, LR: 0.001\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 63371.1875\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 33, LR: 0.01\n",
      "479/479 [==============================] - 0s 810us/step - loss: 50207.6836\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 33, LR: 0.01\n",
      "479/479 [==============================] - 0s 807us/step - loss: 46445.2461\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 33, LR: 0.01\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 48223.0820\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 67, LR: 0.1\n",
      "479/479 [==============================] - 0s 879us/step - loss: 136925.4688\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 67, LR: 0.1\n",
      "479/479 [==============================] - 0s 883us/step - loss: 138172.0156\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 67, LR: 0.1\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 138238.1406\n",
      "Building Model ...\n",
      "Hidden Layers: 4, Neurons: 85, LR: 0.0001\n",
      "479/479 [==============================] - 0s 962us/step - loss: 46509.9492\n",
      "Building Model ...\n",
      "Hidden Layers: 4, Neurons: 85, LR: 0.0001\n",
      "479/479 [==============================] - 0s 823us/step - loss: 45614.1328\n",
      "Building Model ...\n",
      "Hidden Layers: 4, Neurons: 85, LR: 0.0001\n",
      "479/479 [==============================] - 0s 864us/step - loss: 48519.5625\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 88, LR: 0.01\n",
      "479/479 [==============================] - 0s 895us/step - loss: 49557.6406\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 88, LR: 0.01\n",
      "479/479 [==============================] - 0s 817us/step - loss: 48344.2539\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 88, LR: 0.01\n",
      "479/479 [==============================] - 0s 880us/step - loss: 48060.2656\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 80, LR: 0.01\n",
      "479/479 [==============================] - 0s 850us/step - loss: 49229.8828\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 80, LR: 0.01\n",
      "479/479 [==============================] - 0s 954us/step - loss: 49713.4336\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 80, LR: 0.01\n",
      "479/479 [==============================] - 0s 936us/step - loss: 47841.8359\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 10, LR: 0.0001\n",
      "479/479 [==============================] - 0s 793us/step - loss: 46514.9414\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 10, LR: 0.0001\n",
      "479/479 [==============================] - 0s 733us/step - loss: 45690.7461\n",
      "Building Model ...\n",
      "Hidden Layers: 8, Neurons: 10, LR: 0.0001\n",
      "479/479 [==============================] - 0s 894us/step - loss: 48080.2969\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 45, LR: 0.1\n",
      "479/479 [==============================] - 0s 816us/step - loss: 136775.1875\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 45, LR: 0.1\n",
      "479/479 [==============================] - 0s 790us/step - loss: 138269.3125\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 45, LR: 0.1\n",
      "479/479 [==============================] - 0s 914us/step - loss: 140009.7188\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x0000021C89EBF780>, as the constructor either does not set or modifies parameter n_neurons",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-f01efaef27dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# Train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mrnd_search_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_pt2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_pt2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test_pt2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_pt2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcheckpoint_cb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearlystop_cb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensorboard_cb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Developer\\Python\\Python366\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m             \u001b[1;31m# of the params are estimators as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[1;32m--> 736\u001b[1;33m                 **self.best_params_))\n\u001b[0m\u001b[0;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Developer\\Python\\Python366\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     80\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0;32m     81\u001b[0m                                \u001b[1;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m                                (estimator, name))\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x0000021C89EBF780>, as the constructor either does not set or modifies parameter n_neurons"
     ]
    }
   ],
   "source": [
    "# Optimised MLP (Target - DC Power, Plant 2)\n",
    "\n",
    "if TRAIN_MODELS == True:\n",
    "    \n",
    "    # Clear existing models\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Establish parameter distribution for tuning\n",
    "    param_distribs = {\n",
    "        \"n_hidden\": (4, 8, 12, 16),\n",
    "        \"n_neurons\": (5, 10, 20, 40, 60, 80, 100),\n",
    "        \"learning_rate\": (1e-1, 1e-2, 1e-3, 1e-4),\n",
    "    }\n",
    "\n",
    "    # Build model\n",
    "    wrapped_model = keras_helpers.wrap_model()\n",
    "\n",
    "    # Initialise random search\n",
    "    rnd_search_cv = RandomizedSearchCV(wrapped_model, param_distribs, n_iter = 10, cv = 3)\n",
    "\n",
    "    # Name model\n",
    "    model_type = \"MLP_Opt_DC_Plant1\"\n",
    "    model_id = keras_helpers.name_model(model_type)\n",
    "    filepath_full = keras_helpers.make_save_string(model_id)\n",
    "\n",
    "    # Set save and earlystop callbacks\n",
    "    earlystop_cb = keras.callbacks.EarlyStopping(patience = 3)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = filepath_full, save_best_only = True)\n",
    "\n",
    "    # Set TensorBoard callback for logging\n",
    "    tb_logdir = tensorboard_helpers.get_run_logdir()\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(tb_logdir)\n",
    "\n",
    "    # Train model\n",
    "    rnd_search_cv.fit(X_train_pt2, y_train_pt2, epochs = 100, validation_data = (X_test_pt2, y_test_pt2), callbacks = [checkpoint_cb, earlystop_cb, tensorboard_cb], verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate MLP Model (DC Power, Plant 2)\n",
    "\n",
    "if TRAIN_MODELS == False:\n",
    "    filepath_full = r'C:\\Developer\\solar-power-generation-project\\Models\\WJ_MLP_Opt_DC_2021_01_13-15_30_27.h5'\n",
    "\n",
    "wrapped_model = keras.models.load_model(filepath_full)\n",
    "\n",
    "# Summarise model\n",
    "wrapped_model.summary()\n",
    "\n",
    "# Make predictions\n",
    "dc_pred_eval = wrapped_model.predict(dc_evaluation_data)\n",
    "\n",
    "model_name = \"MLP_Opt_DC_pt2\"\n",
    "model_evaluation.evaluate_model(model_name, dc_eval_label_data_pt2, dc_pred_eval)\n",
    "rmse, mae, r2 = model_evaluation.return_model_evaluation_stats(dc_eval_label_data_pt2, dc_pred_eval)"
   ]
  }
 ]
}