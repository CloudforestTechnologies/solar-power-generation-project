{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "keras version = 2.4.0\nnumpy version = 1.19.4\nsklearn version = 0.22.2.post1\ntensorflow version = 2.4.1\n"
     ]
    }
   ],
   "source": [
    "# Module Importations\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "\n",
    "# Print versioning information\n",
    "print('keras version =', keras.__version__)\n",
    "print('numpy version =', np.__version__)  \n",
    "print('sklearn version =', sklearn.__version__)\n",
    "print('tensorflow version =', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[keras_helpers]Tensorflow version: 2.4.1\n[keras_helpers]keras version = 2.4.0\n"
     ]
    }
   ],
   "source": [
    "# Custom Module Imports\n",
    "from Source.data import load_data\n",
    "from Source.data import split_data\n",
    "from Source.models import model_evaluation\n",
    "from Source.models import keras_helpers\n",
    "from Source.models import tensorboard_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TRAIN_MODELS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading pickled dataframe started ...\n",
      "Loading pickled dataframe complete ...\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df_plant1 = load_data.load_pickled_data(\"df_plant1_feat_eng.pkl\")\n",
    "df_plant2 = load_data.load_pickled_data(\"df_plant2_feat_eng.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plant1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 DATE_TIME  PLANT_ID       SOURCE_KEY  DC_POWER  AC_POWER  \\\n0      2020-05-15 00:00:00   4135001  1BY6WEcLGh8j5v7       0.0       0.0   \n1      2020-05-15 00:00:00   4135001  1IF53ai7Xc0U56Y       0.0       0.0   \n2      2020-05-15 00:00:00   4135001  3PZuoBAID5Wc2HD       0.0       0.0   \n3      2020-05-15 00:00:00   4135001  7JYdWkrLSPkdwr4       0.0       0.0   \n4      2020-05-15 00:00:00   4135001  McdE0feGgRqW7Ca       0.0       0.0   \n...                    ...       ...              ...       ...       ...   \n137551 2020-06-17 23:45:00   4135001  uHbuxQJl8lW7ozc       0.0       0.0   \n137552 2020-06-17 23:45:00   4135001  wCURE6d3bPkepu2       0.0       0.0   \n137553 2020-06-17 23:45:00   4135001  z9Y9gH1T5YWrNuG       0.0       0.0   \n137554 2020-06-17 23:45:00   4135001  zBIq5rxdHJRwDNY       0.0       0.0   \n137555 2020-06-17 23:45:00   4135001  zVJPv84UY57bAof       0.0       0.0   \n\n        DAILY_YIELD  TOTAL_YIELD CELL_NO  TIME_OF_DAY   AMB_TEMP   MOD_TEMP  \\\n0             0.000    6259559.0      01     0.000000  25.184316  22.857507   \n1             0.000    6183645.0      02     0.000000  25.184316  22.857507   \n2             0.000    6987759.0      03     0.000000  25.184316  22.857507   \n3             0.000    7602960.0      03     0.000000  25.184316  22.857507   \n4             0.000    7158964.0      05     0.000000  25.184316  22.857507   \n...             ...          ...     ...          ...        ...        ...   \n137551     5967.000    7287002.0      17     0.989583  23.202871  22.535908   \n137552     5147.625    7028601.0      18     0.989583  23.202871  22.535908   \n137553     5819.000    7251204.0      19     0.989583  23.202871  22.535908   \n137554     5817.000    6583369.0      20     0.989583  23.202871  22.535908   \n137555     5910.000    7363272.0      21     0.989583  23.202871  22.535908   \n\n        IRRADIATION   PLANT  \n0               0.0  plant1  \n1               0.0  plant1  \n2               0.0  plant1  \n3               0.0  plant1  \n4               0.0  plant1  \n...             ...     ...  \n137551          0.0  plant2  \n137552          0.0  plant2  \n137553          0.0  plant2  \n137554          0.0  plant2  \n137555          0.0  plant2  \n\n[137556 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop unrequired data columns\n",
    "\n",
    "# Identify columns to drop\n",
    "cols_to_keep = ['DC_POWER', 'AMB_TEMP', 'MOD_TEMP', 'IRRADIATION', 'TIME_FLOAT']\n",
    "cols_to_drop = []\n",
    "\n",
    "for col in df_plant1.columns:\n",
    "    if col not in cols_to_keep:\n",
    "        cols_to_drop.append(col)\n",
    "\n",
    "for df in [df_plant1, df_plant2]:\n",
    "    df.drop(cols_to_drop, axis = 1, inplace = True)\n",
    "\n",
    "df_plant2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original Data Items: 137556\nTraining Data Items: 110045\nEvaluation Data Items: 27511\n"
     ]
    }
   ],
   "source": [
    "# Split data into training / evaluation sets\n",
    "training_set_plant1, evaluation_set_plant1 = split_data.split_train_eval(df_plant1, 0.2)\n",
    "training_set_plant2, evaluation_set_plant2 = split_data.split_train_eval(df_plant2, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 110045 entries, 99361 to 121958\nData columns (total 6 columns):\n #   Column       Non-Null Count   Dtype  \n---  ------       --------------   -----  \n 0   CELL_NO      110045 non-null  int64  \n 1   TIME_OF_DAY  110045 non-null  float64\n 2   AMB_TEMP     110045 non-null  float64\n 3   MOD_TEMP     110045 non-null  float64\n 4   IRRADIATION  110045 non-null  float64\n 5   PLANT        110045 non-null  int64  \ndtypes: float64(4), int64(2)\nmemory usage: 5.9 MB\nNone\n99361        0.000000\n113108    3576.750000\n53656        0.000000\n46387     9456.625000\n116927       0.000000\n             ...     \n110268       0.000000\n119879    7230.250000\n103694       0.000000\n131932    1900.857143\n121958    7665.750000\nName: DC_POWER, Length: 110045, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create DC Power Target datasets\n",
    "\n",
    "# Modify training sets\n",
    "dc_power_training_data_pt1 = training_set_plant1.drop('DC_POWER', axis = 1)\n",
    "dc_label_data_pt1 = training_set_plant1['DC_POWER'].copy()\n",
    "\n",
    "dc_power_training_data_pt2 = training_set_plant2.drop('DC_POWER', axis = 1)\n",
    "dc_label_data_pt2 = training_set_plant2['DC_POWER'].copy()\n",
    "\n",
    "# Modify evaluation sets\n",
    "dc_evaluation_data_pt1 = evaluation_set_plant1.drop('DC_POWER', axis = 1)\n",
    "dc_eval_label_data_pt1 = evaluation_set_plant1['DC_POWER'].copy()\n",
    "\n",
    "dc_evaluation_data_pt2 = evaluation_set_plant2.drop('DC_POWER', axis = 1)\n",
    "dc_eval_label_data_pt2 = evaluation_set_plant2['DC_POWER'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "        CELL_NO  TIME_OF_DAY   AMB_TEMP   MOD_TEMP  IRRADIATION  PLANT\n26727         6     0.614583  32.965332  46.834515     0.537781      1\n131564       14     0.135417  24.157297  23.330549     0.000000      2\n39111        13     0.854167  23.664010  21.192350     0.000000      1\n85370        14     0.729167  37.208696  39.745883     0.128514      2\n52462         8     0.250000  21.767090  19.326091     0.009079      1\n...         ...          ...        ...        ...          ...    ...\n129940       18     0.364583  27.568193  35.298639     0.336816      2\n49470         8     0.833333  24.800704  21.858350     0.000000      1\n44627        11     0.510417  29.854372  53.016915     0.688047      1\n90334        14     0.114583  25.172858  24.225251     0.000000      2\n115964       12     0.750000  31.154428  31.562370     0.068103      2\n\n[88036 rows x 6 columns]\n26727     8246.714286\n131564       0.000000\n39111        0.000000\n85370     2074.500000\n52462      102.285714\n             ...     \n129940    5305.000000\n49470        0.000000\n44627     8769.250000\n90334        0.000000\n115964     665.571429\nName: DC_POWER, Length: 88036, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create train and test arrays\n",
    "X_train, X_test, y_train, y_test = train_test_split(dc_power_training_data, dc_label_data, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Building Model ...\n",
      "Hidden Layers: 2, Neurons: 6, LR: 0.001\n",
      "Epoch 1/20\n",
      "2752/2752 [==============================] - 4s 1ms/step - loss: 25335308.4214 - val_loss: 14827994.0000\n",
      "Epoch 2/20\n",
      "2752/2752 [==============================] - 3s 917us/step - loss: 12773082.0854 - val_loss: 10360139.0000\n",
      "Epoch 3/20\n",
      "2752/2752 [==============================] - 3s 975us/step - loss: 10029928.8641 - val_loss: 8566308.0000\n",
      "Epoch 4/20\n",
      "2752/2752 [==============================] - 3s 1ms/step - loss: 7998315.0941 - val_loss: 6134981.0000\n",
      "Epoch 5/20\n",
      "2752/2752 [==============================] - 3s 1ms/step - loss: 5420263.4306 - val_loss: 3870666.5000\n",
      "Epoch 6/20\n",
      "2752/2752 [==============================] - 3s 941us/step - loss: 3510392.8145 - val_loss: 2628508.2500\n",
      "Epoch 7/20\n",
      "2752/2752 [==============================] - 3s 970us/step - loss: 2487680.7047 - val_loss: 2201938.7500\n",
      "Epoch 8/20\n",
      "2752/2752 [==============================] - 3s 1ms/step - loss: 2204089.8673 - val_loss: 2115218.0000\n",
      "Epoch 9/20\n",
      "2752/2752 [==============================] - 3s 965us/step - loss: 2103188.2160 - val_loss: 2095637.2500\n",
      "Epoch 10/20\n",
      "2752/2752 [==============================] - 3s 1000us/step - loss: 2098156.2376 - val_loss: 2087223.1250\n",
      "Epoch 11/20\n",
      "2752/2752 [==============================] - 3s 995us/step - loss: 2124964.4127 - val_loss: 2074584.1250\n",
      "Epoch 12/20\n",
      "2752/2752 [==============================] - 4s 2ms/step - loss: 2073631.2360 - val_loss: 2067386.8750\n",
      "Epoch 13/20\n",
      "2752/2752 [==============================] - 3s 1ms/step - loss: 2103915.6483 - val_loss: 2057597.1250\n",
      "Epoch 14/20\n",
      "2752/2752 [==============================] - 3s 1ms/step - loss: 2090545.4228 - val_loss: 2050374.3750\n",
      "Epoch 15/20\n",
      "2752/2752 [==============================] - 3s 1ms/step - loss: 2067816.4965 - val_loss: 2043061.8750\n",
      "Epoch 16/20\n",
      "2752/2752 [==============================] - 3s 997us/step - loss: 2104774.1248 - val_loss: 2036634.5000\n",
      "Epoch 17/20\n",
      "2752/2752 [==============================] - 3s 1ms/step - loss: 2045683.6418 - val_loss: 2032173.6250\n",
      "Epoch 18/20\n",
      "2752/2752 [==============================] - 3s 998us/step - loss: 2030972.0509 - val_loss: 2025832.3750\n",
      "Epoch 19/20\n",
      "2752/2752 [==============================] - 3s 1ms/step - loss: 2022621.1395 - val_loss: 2019444.3750\n",
      "Epoch 20/20\n",
      "2752/2752 [==============================] - 3s 1ms/step - loss: 2071131.0617 - val_loss: 2015898.2500\n"
     ]
    }
   ],
   "source": [
    "# Initial MLP (Target - DC Power)\n",
    "\n",
    "if TRAIN_MODELS == True:\n",
    "    # Clear existing models\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Build model\n",
    "    model = keras_helpers.build_multilayer_perceptron()\n",
    "\n",
    "    # Name model\n",
    "    model_type = \"MLP_DC\"\n",
    "    model_id = keras_helpers.name_model(model_type)\n",
    "    filepath_full = keras_helpers.make_save_string(model_id)\n",
    "\n",
    "    # Set save and earlystop callbacks\n",
    "    earlystop_cb = keras.callbacks.EarlyStopping(patience = 5)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = filepath_full, save_best_only = True)\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train, epochs = 20, validation_data =(X_test, y_test), callbacks =[checkpoint_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "MLP_DC rmse (Eval): 1403.2688175198489\n",
      "MLP_DC mae (Eval): 779.0881403648866\n",
      "MLP_DC r2 (Eval): 0.879328176811617\n",
      "MLP_DC % Acc: 89.20562448061655\n"
     ]
    }
   ],
   "source": [
    "# Evaluate MLP Model\n",
    "\n",
    "if TRAIN_MODELS == False:\n",
    "    filepath_full = r'C:\\Developer\\solar-power-generation-project\\Models\\WJ_MLP_DC_2021_01_13-16_10_50.h5'\n",
    "\n",
    "# Load model\n",
    "model = keras.models.load_model(filepath_full)\n",
    "\n",
    "# Summarise model\n",
    "model.summary()\n",
    "\n",
    "# Make predictions\n",
    "dc_pred_eval = model.predict(dc_evaluation_data)\n",
    "\n",
    "# Determine model prediction stats\n",
    "model_name = \"MLP_DC\"\n",
    "model_evaluation.evaluate_model(model_name, dc_eval_label_data, dc_pred_eval)\n",
    "\n",
    "# Calculate indicative accuracy\n",
    "rmse, mae, r2 = model_evaluation.return_model_evaluation_stats(dc_eval_label_data, dc_pred_eval)\n",
    "\n",
    "print(model_name, \"% Acc:\", ((1-(rmse/DC_Power_Range))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "c:\\Developer\\solar-power-generation-project\\Models\\TensorBoard\\run_2021_01_28-11_40_26\n"
     ]
    }
   ],
   "source": [
    "# Setup tensorboard for logging \n",
    "x = tensorboard_helpers.get_run_logdir()\n",
    "\n",
    "# Print tensorboard directory\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 19, LR: 0.1\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1485793268.4237 - val_loss: 16257935.0000\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 16449885.0547 - val_loss: 17790320.0000\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 16558739.3856 - val_loss: 16429694.0000\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 16419100.0904 - val_loss: 16574621.0000\n",
      "918/918 [==============================] - 1s 814us/step - loss: 16817056.0000\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 19, LR: 0.1\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 90304549.8257 - val_loss: 16450160.0000\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 16539768.5087 - val_loss: 16117428.0000\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 16475480.8094 - val_loss: 16133619.0000\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 16581331.7576 - val_loss: 16394467.0000\n",
      "Epoch 5/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 16412154.9254 - val_loss: 16438892.0000\n",
      "918/918 [==============================] - 1s 806us/step - loss: 16535337.0000\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 19, LR: 0.1\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 5s 2ms/step - loss: 667667762.5664 - val_loss: 16888256.0000\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 16550040.9777 - val_loss: 16163301.0000\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 16573849.2843 - val_loss: 16097271.0000\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 16422004.3159 - val_loss: 16225161.0000\n",
      "Epoch 5/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 16498935.6792 - val_loss: 16115190.0000\n",
      "Epoch 6/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 16396861.0387 - val_loss: 16220717.0000\n",
      "918/918 [==============================] - 1s 983us/step - loss: 16495913.0000\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 36, LR: 0.01\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 5s 2ms/step - loss: 7325525.0286 - val_loss: 11589274.0000\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 2827037.6204 - val_loss: 1719510.7500\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 2327694.5810 - val_loss: 2627617.7500\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 2185573.8641 - val_loss: 1778201.2500\n",
      "Epoch 5/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 2068259.4439 - val_loss: 5995727.5000\n",
      "918/918 [==============================] - 1s 1ms/step - loss: 6160132.0000\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 36, LR: 0.01\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 5s 2ms/step - loss: 6922706.1392 - val_loss: 2559843.0000\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 2705803.9106 - val_loss: 4043408.0000\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 2188508.4459 - val_loss: 8497499.0000\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 2086034.2750 - val_loss: 4145592.2500\n",
      "918/918 [==============================] - 1s 1ms/step - loss: 4202353.0000\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 36, LR: 0.01\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 5s 2ms/step - loss: 10927721.5833 - val_loss: 1927646.2500\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 5s 3ms/step - loss: 2721316.0491 - val_loss: 9321292.0000\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 2315443.0069 - val_loss: 2888016.7500\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 2010179.1874 - val_loss: 2630493.0000\n",
      "918/918 [==============================] - 1s 998us/step - loss: 2704219.7500\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 22, LR: 0.001\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 5s 2ms/step - loss: 6243301.2717 - val_loss: 1850717.7500\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1965403.4622 - val_loss: 2586828.5000\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1877708.7206 - val_loss: 2035568.7500\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1801947.5005 - val_loss: 2012089.7500\n",
      "918/918 [==============================] - 1s 987us/step - loss: 2037904.3750\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 22, LR: 0.001\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 5848206.0745 - val_loss: 2812030.0000\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1910564.2501 - val_loss: 2728262.7500\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1870958.7579 - val_loss: 1732305.7500\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1846331.0267 - val_loss: 1744272.1250\n",
      "Epoch 5/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1809193.1450 - val_loss: 1755538.6250\n",
      "Epoch 6/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1828719.1874 - val_loss: 1661691.2500\n",
      "Epoch 7/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1778788.8097 - val_loss: 1677659.1250\n",
      "Epoch 8/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1736620.6907 - val_loss: 2119829.5000\n",
      "Epoch 9/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1694842.2475 - val_loss: 1595189.2500\n",
      "Epoch 10/100\n",
      "1835/1835 [==============================] - 5s 3ms/step - loss: 1668737.7140 - val_loss: 1549427.2500\n",
      "Epoch 11/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1655790.0734 - val_loss: 1516204.2500\n",
      "Epoch 12/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1636375.0866 - val_loss: 1632033.5000\n",
      "Epoch 13/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1646704.7926 - val_loss: 1537918.2500\n",
      "Epoch 14/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1589665.9389 - val_loss: 2086694.3750\n",
      "918/918 [==============================] - 1s 990us/step - loss: 2095786.8750\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 22, LR: 0.001\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 5428489.3431 - val_loss: 2784544.2500\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1892414.5687 - val_loss: 1913693.6250\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1821289.0089 - val_loss: 2092517.2500\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1796979.9935 - val_loss: 1779225.2500\n",
      "Epoch 5/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1741943.3673 - val_loss: 1741384.3750\n",
      "Epoch 6/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1774323.3095 - val_loss: 1670352.2500\n",
      "Epoch 7/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1713620.1428 - val_loss: 2603047.2500\n",
      "Epoch 8/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1661124.2546 - val_loss: 1595432.6250\n",
      "Epoch 9/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1658066.1406 - val_loss: 2152848.7500\n",
      "Epoch 10/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1571969.5394 - val_loss: 1466245.0000\n",
      "Epoch 11/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1523537.9476 - val_loss: 2098903.7500\n",
      "Epoch 12/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1525380.5740 - val_loss: 2140773.2500\n",
      "Epoch 13/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1505978.4995 - val_loss: 1541799.7500\n",
      "918/918 [==============================] - 2s 2ms/step - loss: 1596566.8750\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 82, LR: 0.01\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 6s 2ms/step - loss: 3162216792.7092 - val_loss: 8421873.0000\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 2689772.2101 - val_loss: 5131850.0000\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 2201689.1367 - val_loss: 2726874.5000\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 2009750.5737 - val_loss: 2820310.0000\n",
      "Epoch 5/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1938642.3403 - val_loss: 2246456.0000\n",
      "Epoch 6/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1872894.1521 - val_loss: 1777532.3750\n",
      "Epoch 7/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1863507.0714 - val_loss: 2193441.5000\n",
      "Epoch 8/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1828627.7330 - val_loss: 1653228.8750\n",
      "Epoch 9/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1759995.5844 - val_loss: 1542659.6250\n",
      "Epoch 10/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1757345.9034 - val_loss: 1648212.3750\n",
      "Epoch 11/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1685580.5921 - val_loss: 1634935.5000\n",
      "Epoch 12/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1674133.2148 - val_loss: 2260050.7500\n",
      "918/918 [==============================] - 1s 950us/step - loss: 2339304.7500\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 82, LR: 0.01\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 5s 2ms/step - loss: 23478565.0163 - val_loss: 2622601.0000\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 6s 3ms/step - loss: 2830241.6206 - val_loss: 1997175.2500\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 2420948.7079 - val_loss: 1973002.2500\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 2171515.8905 - val_loss: 2508776.0000\n",
      "Epoch 5/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1982890.2638 - val_loss: 1840866.2500\n",
      "Epoch 6/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1910682.8901 - val_loss: 3696376.0000\n",
      "Epoch 7/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1818571.6833 - val_loss: 1794331.5000\n",
      "Epoch 8/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1879256.2089 - val_loss: 1566942.1250\n",
      "Epoch 9/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1745536.8202 - val_loss: 1545480.3750\n",
      "Epoch 10/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1830124.7180 - val_loss: 1642585.7500\n",
      "Epoch 11/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1735949.7154 - val_loss: 1754712.5000\n",
      "Epoch 12/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1772504.1217 - val_loss: 2149209.0000\n",
      "918/918 [==============================] - 1s 957us/step - loss: 2152786.5000\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 82, LR: 0.01\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 5s 2ms/step - loss: 21889897.1585 - val_loss: 20657142.0000\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 2823688.5831 - val_loss: 3084392.2500\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 2297998.6911 - val_loss: 4725355.5000\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 5s 3ms/step - loss: 2173907.2360 - val_loss: 1808136.7500\n",
      "Epoch 5/100\n",
      "1835/1835 [==============================] - 5s 3ms/step - loss: 1987218.9826 - val_loss: 2103295.7500\n",
      "Epoch 6/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1890455.3144 - val_loss: 2054625.3750\n",
      "Epoch 7/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1892733.0740 - val_loss: 2690290.5000\n",
      "918/918 [==============================] - 1s 928us/step - loss: 2777854.5000\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 70, LR: 0.0001\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 5s 2ms/step - loss: 12823944.8388 - val_loss: 1898138.6250\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1938993.4578 - val_loss: 1937611.3750\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1876230.3355 - val_loss: 2327941.7500\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1903574.2507 - val_loss: 1918764.2500\n",
      "918/918 [==============================] - 1s 908us/step - loss: 1940047.5000\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 70, LR: 0.0001\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 5s 2ms/step - loss: 11865874.7655 - val_loss: 1903121.7500\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1958009.3839 - val_loss: 1857140.6250\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1923604.5408 - val_loss: 1834330.7500\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1871719.5895 - val_loss: 2028984.5000\n",
      "Epoch 5/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1868031.2213 - val_loss: 1845459.0000\n",
      "Epoch 6/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1820628.3420 - val_loss: 1795659.8750\n",
      "Epoch 7/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1816722.0063 - val_loss: 1847663.1250\n",
      "Epoch 8/100\n",
      "1835/1835 [==============================] - 6s 3ms/step - loss: 1814812.7693 - val_loss: 1908174.3750\n",
      "Epoch 9/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1814317.7703 - val_loss: 1756582.7500\n",
      "Epoch 10/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1786642.2574 - val_loss: 1744097.6250\n",
      "Epoch 11/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1817568.1903 - val_loss: 1713861.0000\n",
      "Epoch 12/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1762242.9237 - val_loss: 1698566.2500\n",
      "Epoch 13/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1745923.4792 - val_loss: 1762517.0000\n",
      "Epoch 14/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1755660.6167 - val_loss: 1658886.7500\n",
      "Epoch 15/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1738912.9822 - val_loss: 1655027.2500\n",
      "Epoch 16/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1728618.7120 - val_loss: 1683230.6250\n",
      "Epoch 17/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1748268.4536 - val_loss: 1776123.3750\n",
      "Epoch 18/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1714211.5148 - val_loss: 1624518.0000\n",
      "Epoch 19/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1687209.0298 - val_loss: 1639541.3750\n",
      "Epoch 20/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1674684.8432 - val_loss: 1595532.2500\n",
      "Epoch 21/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1655918.9998 - val_loss: 1680873.0000\n",
      "Epoch 22/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1674530.2228 - val_loss: 1624173.0000\n",
      "Epoch 23/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1639491.5906 - val_loss: 1554473.7500\n",
      "Epoch 24/100\n",
      "1835/1835 [==============================] - 5s 3ms/step - loss: 1593727.0733 - val_loss: 1542440.1250\n",
      "Epoch 25/100\n",
      "1835/1835 [==============================] - 6s 3ms/step - loss: 1618483.2891 - val_loss: 2075046.0000\n",
      "Epoch 26/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1592651.7673 - val_loss: 1526110.7500\n",
      "Epoch 27/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1598464.0359 - val_loss: 1576351.7500\n",
      "Epoch 28/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1600716.6917 - val_loss: 1616856.6250\n",
      "Epoch 29/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1578301.0208 - val_loss: 1486113.6250\n",
      "Epoch 30/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1548136.4686 - val_loss: 1436774.0000\n",
      "Epoch 31/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1542979.2131 - val_loss: 1606334.5000\n",
      "Epoch 32/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1483027.6139 - val_loss: 1889204.7500\n",
      "Epoch 33/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1553484.3787 - val_loss: 1429408.3750\n",
      "Epoch 34/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1489565.2124 - val_loss: 1939121.8750\n",
      "Epoch 35/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1472781.0611 - val_loss: 1785575.5000\n",
      "Epoch 36/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1513710.3313 - val_loss: 1409626.7500\n",
      "Epoch 37/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1504153.9827 - val_loss: 1443218.0000\n",
      "Epoch 38/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1518857.1958 - val_loss: 1425806.1250\n",
      "Epoch 39/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1455826.7842 - val_loss: 1425870.3750\n",
      "918/918 [==============================] - 2s 2ms/step - loss: 1440474.2500\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 70, LR: 0.0001\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 6s 2ms/step - loss: 12208621.0662 - val_loss: 1938098.6250\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1963820.8994 - val_loss: 1961016.2500\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1890980.4692 - val_loss: 1879173.1250\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1835894.7480 - val_loss: 1811255.8750\n",
      "Epoch 5/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1824283.0145 - val_loss: 1769236.0000\n",
      "Epoch 6/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1835970.0028 - val_loss: 1912577.6250\n",
      "Epoch 7/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1772562.4428 - val_loss: 1856212.7500\n",
      "Epoch 8/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1768960.6260 - val_loss: 2066637.8750\n",
      "918/918 [==============================] - 1s 841us/step - loss: 2119794.0000\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 63, LR: 0.01\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 5s 2ms/step - loss: 11719123.4646 - val_loss: 5657178.5000\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 2804094.9183 - val_loss: 3523137.2500\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 2277055.4345 - val_loss: 4002866.7500\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 2088133.8133 - val_loss: 1875079.8750\n",
      "Epoch 5/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1997894.8657 - val_loss: 2023077.8750\n",
      "Epoch 6/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1878754.5669 - val_loss: 2117235.7500\n",
      "Epoch 7/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1846946.4794 - val_loss: 1806659.2500\n",
      "Epoch 8/100\n",
      "1835/1835 [==============================] - 5s 3ms/step - loss: 1762863.4243 - val_loss: 2174297.2500\n",
      "Epoch 9/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1761478.4831 - val_loss: 1760816.2500\n",
      "Epoch 10/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1761294.5701 - val_loss: 1609606.8750\n",
      "Epoch 11/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1735288.1408 - val_loss: 1565243.8750\n",
      "Epoch 12/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1747729.7074 - val_loss: 1669202.3750\n",
      "Epoch 13/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1656454.9493 - val_loss: 1523720.7500\n",
      "Epoch 14/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1663675.4148 - val_loss: 1507559.5000\n",
      "Epoch 15/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1653163.8156 - val_loss: 1739981.5000\n",
      "Epoch 16/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1650002.4349 - val_loss: 1909199.3750\n",
      "Epoch 17/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1634900.0226 - val_loss: 1615381.0000\n",
      "918/918 [==============================] - 1s 893us/step - loss: 1671453.6250\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 63, LR: 0.01\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 5s 2ms/step - loss: 19212623.0942 - val_loss: 17403846.0000\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 2653860.2416 - val_loss: 1856539.0000\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 2233226.3152 - val_loss: 2191185.0000\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 2104568.7871 - val_loss: 3141966.0000\n",
      "Epoch 5/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1953227.4985 - val_loss: 2862487.2500\n",
      "918/918 [==============================] - 1s 910us/step - loss: 2886325.7500\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 63, LR: 0.01\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 6s 2ms/step - loss: 131305880.8736 - val_loss: 1967106.0000\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 5s 3ms/step - loss: 2727874.1454 - val_loss: 13447147.0000\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 2313036.5376 - val_loss: 11288806.0000\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 2114108.0515 - val_loss: 1957204.0000\n",
      "Epoch 5/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1978342.3922 - val_loss: 2196469.2500\n",
      "Epoch 6/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1939622.8457 - val_loss: 2072627.8750\n",
      "Epoch 7/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1774627.8561 - val_loss: 1610897.6250\n",
      "Epoch 8/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1768366.4004 - val_loss: 1776925.7500\n",
      "Epoch 9/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1768590.8382 - val_loss: 1758717.7500\n",
      "Epoch 10/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1693957.0042 - val_loss: 1541733.1250\n",
      "Epoch 11/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1730016.5629 - val_loss: 2248900.2500\n",
      "Epoch 12/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1664861.9043 - val_loss: 1714169.2500\n",
      "Epoch 13/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1671255.4914 - val_loss: 1690835.6250\n",
      "918/918 [==============================] - 1s 852us/step - loss: 1740714.7500\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 91, LR: 0.0001\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 5s 2ms/step - loss: 12431792.6590 - val_loss: 2037560.3750\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1936192.9309 - val_loss: 1958462.7500\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1881260.2979 - val_loss: 1851171.8750\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 6s 3ms/step - loss: 1873096.6350 - val_loss: 1926834.2500\n",
      "Epoch 5/100\n",
      "1835/1835 [==============================] - 5s 3ms/step - loss: 1849189.1395 - val_loss: 1889864.0000\n",
      "Epoch 6/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1831182.7505 - val_loss: 1996769.6250\n",
      "918/918 [==============================] - 1s 990us/step - loss: 2014040.7500\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 91, LR: 0.0001\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 5s 2ms/step - loss: 11180628.3143 - val_loss: 2554686.0000\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1966269.4993 - val_loss: 1883159.2500\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1922306.7306 - val_loss: 2219371.0000\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1902231.9769 - val_loss: 1896405.7500\n",
      "Epoch 5/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1877646.0422 - val_loss: 1875285.7500\n",
      "Epoch 6/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1868285.8633 - val_loss: 1871395.7500\n",
      "Epoch 7/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1853470.1489 - val_loss: 1822411.7500\n",
      "Epoch 8/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1800515.5780 - val_loss: 1804794.6250\n",
      "Epoch 9/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1871957.3325 - val_loss: 1788201.8750\n",
      "Epoch 10/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1776143.2740 - val_loss: 1759990.6250\n",
      "Epoch 11/100\n",
      "1835/1835 [==============================] - 6s 3ms/step - loss: 1790971.9954 - val_loss: 1743046.6250\n",
      "Epoch 12/100\n",
      "1835/1835 [==============================] - 5s 3ms/step - loss: 1799649.0345 - val_loss: 1794501.3750\n",
      "Epoch 13/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1765875.9540 - val_loss: 2330665.2500\n",
      "Epoch 14/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1768771.0837 - val_loss: 1803702.6250\n",
      "918/918 [==============================] - 1s 1ms/step - loss: 1811031.1250\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 91, LR: 0.0001\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 6s 2ms/step - loss: 10474461.9668 - val_loss: 2083319.1250\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1919337.2770 - val_loss: 2312256.5000\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1923420.0342 - val_loss: 2194230.5000\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 5s 3ms/step - loss: 1874569.4999 - val_loss: 2133817.7500\n",
      "918/918 [==============================] - 1s 1ms/step - loss: 2185477.0000\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 59, LR: 0.0001\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 5s 2ms/step - loss: 13364407.8208 - val_loss: 2037605.6250\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1977964.3044 - val_loss: 1915187.1250\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1940940.7421 - val_loss: 1975148.8750\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1887110.7327 - val_loss: 1877553.7500\n",
      "Epoch 5/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1848592.3000 - val_loss: 1901850.8750\n",
      "Epoch 6/100\n",
      "1835/1835 [==============================] - 5s 3ms/step - loss: 1847363.9242 - val_loss: 1792303.6250\n",
      "Epoch 7/100\n",
      "1835/1835 [==============================] - 5s 3ms/step - loss: 1891540.2525 - val_loss: 2188460.2500\n",
      "Epoch 8/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1871447.1904 - val_loss: 1782394.7500\n",
      "Epoch 9/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1788625.0685 - val_loss: 1807287.5000\n",
      "Epoch 10/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1764114.2784 - val_loss: 2040739.1250\n",
      "Epoch 11/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1784854.7676 - val_loss: 1717671.1250\n",
      "Epoch 12/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1773643.2613 - val_loss: 2348490.2500\n",
      "Epoch 13/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1747768.5771 - val_loss: 1718018.0000\n",
      "Epoch 14/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1710147.8670 - val_loss: 1662829.5000\n",
      "Epoch 15/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1675721.8938 - val_loss: 1629176.2500\n",
      "Epoch 16/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1675893.0687 - val_loss: 1798663.3750\n",
      "Epoch 17/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1679667.2685 - val_loss: 1598344.5000\n",
      "Epoch 18/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1666852.4867 - val_loss: 1603308.2500\n",
      "Epoch 19/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1648551.8845 - val_loss: 1685826.3750\n",
      "Epoch 20/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1687367.6593 - val_loss: 1853412.3750\n",
      "918/918 [==============================] - 1s 880us/step - loss: 1913322.0000\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 59, LR: 0.0001\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 5s 2ms/step - loss: 14618171.8704 - val_loss: 1968194.0000\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 6s 3ms/step - loss: 1991339.4947 - val_loss: 1983511.6250\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 7s 4ms/step - loss: 1980271.7269 - val_loss: 1852100.5000\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1922492.5185 - val_loss: 2089940.2500\n",
      "Epoch 5/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1863699.1366 - val_loss: 1806739.2500\n",
      "Epoch 6/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1855065.0635 - val_loss: 1796221.1250\n",
      "Epoch 7/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1833423.7363 - val_loss: 1783504.3750\n",
      "Epoch 8/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1835677.5697 - val_loss: 1769386.3750\n",
      "Epoch 9/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1826388.8440 - val_loss: 1742711.5000\n",
      "Epoch 10/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1803855.9451 - val_loss: 1737953.1250\n",
      "Epoch 11/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1764653.5912 - val_loss: 1716480.6250\n",
      "Epoch 12/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1768844.3642 - val_loss: 1795969.1250\n",
      "Epoch 13/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1777547.8892 - val_loss: 1691161.3750\n",
      "Epoch 14/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1753929.4104 - val_loss: 2126294.0000\n",
      "Epoch 15/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1727011.1799 - val_loss: 1737832.3750\n",
      "Epoch 16/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1709596.3231 - val_loss: 1679562.5000\n",
      "Epoch 17/100\n",
      "1835/1835 [==============================] - 5s 3ms/step - loss: 1741040.0029 - val_loss: 1624612.5000\n",
      "Epoch 18/100\n",
      "1835/1835 [==============================] - 5s 3ms/step - loss: 1709503.4891 - val_loss: 1875006.0000\n",
      "Epoch 19/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1709977.2702 - val_loss: 1592865.7500\n",
      "Epoch 20/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1663362.9065 - val_loss: 1582841.8750\n",
      "Epoch 21/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1664295.0153 - val_loss: 1581603.5000\n",
      "Epoch 22/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1659621.5793 - val_loss: 1580817.3750\n",
      "Epoch 23/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1631180.8326 - val_loss: 1573285.1250\n",
      "Epoch 24/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1641562.2894 - val_loss: 1548158.2500\n",
      "Epoch 25/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1582956.8144 - val_loss: 1565931.2500\n",
      "Epoch 26/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1627011.3459 - val_loss: 1731447.2500\n",
      "Epoch 27/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1558307.8552 - val_loss: 1710077.1250\n",
      "918/918 [==============================] - 1s 870us/step - loss: 1730274.2500\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 59, LR: 0.0001\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 5s 2ms/step - loss: 14728841.4619 - val_loss: 1911802.1250\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1917736.2147 - val_loss: 1858968.1250\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1898449.0003 - val_loss: 1837727.8750\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1920862.6317 - val_loss: 1985094.3750\n",
      "Epoch 5/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1856133.1680 - val_loss: 1932289.7500\n",
      "Epoch 6/100\n",
      "1835/1835 [==============================] - 6s 3ms/step - loss: 1841256.0269 - val_loss: 1797289.0000\n",
      "Epoch 7/100\n",
      "1835/1835 [==============================] - 5s 2ms/step - loss: 1837816.2661 - val_loss: 1777645.6250\n",
      "Epoch 8/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1754158.1185 - val_loss: 1760782.8750\n",
      "Epoch 9/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1763533.2862 - val_loss: 1952498.3750\n",
      "Epoch 10/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1798799.8625 - val_loss: 1749140.1250\n",
      "Epoch 11/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1760547.5230 - val_loss: 1913213.3750\n",
      "Epoch 12/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1744040.7493 - val_loss: 1707899.1250\n",
      "Epoch 13/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1768094.6373 - val_loss: 1721289.2500\n",
      "Epoch 14/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1755152.0129 - val_loss: 1676159.0000\n",
      "Epoch 15/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1744242.0955 - val_loss: 2323352.7500\n",
      "Epoch 16/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1724967.1984 - val_loss: 1716154.3750\n",
      "Epoch 17/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1669983.7045 - val_loss: 1690741.1250\n",
      "918/918 [==============================] - 1s 915us/step - loss: 1744242.2500\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 28, LR: 0.0001\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 20656378.9956 - val_loss: 2617603.2500\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 2186304.2645 - val_loss: 1919915.8750\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 3s 1ms/step - loss: 1906022.8045 - val_loss: 1866870.6250\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1916639.7399 - val_loss: 1839909.6250\n",
      "Epoch 5/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1867837.8260 - val_loss: 1849527.0000\n",
      "Epoch 6/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1912410.5464 - val_loss: 1823233.5000\n",
      "Epoch 7/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1847403.4737 - val_loss: 1788199.8750\n",
      "Epoch 8/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1834326.4972 - val_loss: 1861566.2500\n",
      "Epoch 9/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1766775.1991 - val_loss: 1854916.6250\n",
      "Epoch 10/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1781180.4776 - val_loss: 1779406.8750\n",
      "Epoch 11/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1787066.6991 - val_loss: 1746882.8750\n",
      "Epoch 12/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1775827.8553 - val_loss: 1752961.6250\n",
      "Epoch 13/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1777799.5731 - val_loss: 1709702.1250\n",
      "Epoch 14/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1733495.6239 - val_loss: 1728790.2500\n",
      "Epoch 15/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1763465.9922 - val_loss: 1843164.5000\n",
      "Epoch 16/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1774259.8947 - val_loss: 1703650.1250\n",
      "Epoch 17/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1698682.6961 - val_loss: 1714124.3750\n",
      "Epoch 18/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1691286.9454 - val_loss: 1656358.2500\n",
      "Epoch 19/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1677386.7445 - val_loss: 1703411.3750\n",
      "Epoch 20/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1727905.3505 - val_loss: 1748484.5000\n",
      "Epoch 21/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1675333.5784 - val_loss: 1640892.3750\n",
      "Epoch 22/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1695439.6950 - val_loss: 1656310.7500\n",
      "Epoch 23/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1678313.3382 - val_loss: 1620772.6250\n",
      "Epoch 24/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1616094.1294 - val_loss: 1647776.2500\n",
      "Epoch 25/100\n",
      "1835/1835 [==============================] - 5s 3ms/step - loss: 1622477.3791 - val_loss: 2044988.1250\n",
      "Epoch 26/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1662206.0560 - val_loss: 1580067.2500\n",
      "Epoch 27/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1619935.4569 - val_loss: 1727133.0000\n",
      "Epoch 28/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1630719.2128 - val_loss: 1565034.1250\n",
      "Epoch 29/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1655764.8083 - val_loss: 1581819.7500\n",
      "Epoch 30/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1634007.3873 - val_loss: 1568219.5000\n",
      "Epoch 31/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1616533.3130 - val_loss: 1608815.3750\n",
      "918/918 [==============================] - 1s 880us/step - loss: 1655203.7500\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 28, LR: 0.0001\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 19626251.1002 - val_loss: 3097995.5000\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 3s 1ms/step - loss: 2405328.6299 - val_loss: 1988240.0000\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 3s 1ms/step - loss: 1968175.6510 - val_loss: 1914508.6250\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 3s 1ms/step - loss: 1906375.9946 - val_loss: 1859966.6250\n",
      "Epoch 5/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1901945.9634 - val_loss: 1873632.0000\n",
      "Epoch 6/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1908678.6931 - val_loss: 1822913.5000\n",
      "Epoch 7/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1866469.4152 - val_loss: 1813800.0000\n",
      "Epoch 8/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1858600.3238 - val_loss: 1831010.2500\n",
      "Epoch 9/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1835680.9709 - val_loss: 1788011.6250\n",
      "Epoch 10/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1848960.3941 - val_loss: 1845005.6250\n",
      "Epoch 11/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1851804.9580 - val_loss: 1814397.8750\n",
      "Epoch 12/100\n",
      "1835/1835 [==============================] - 5s 3ms/step - loss: 1809110.5183 - val_loss: 1759932.0000\n",
      "Epoch 13/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1825301.6095 - val_loss: 1833979.7500\n",
      "Epoch 14/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1813865.9305 - val_loss: 1764077.0000\n",
      "Epoch 15/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1761102.1238 - val_loss: 1734465.5000\n",
      "Epoch 16/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1751550.6730 - val_loss: 1770566.8750\n",
      "Epoch 17/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1750038.2591 - val_loss: 1718240.2500\n",
      "Epoch 18/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1715383.0636 - val_loss: 1709381.8750\n",
      "Epoch 19/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1759300.8693 - val_loss: 1691625.5000\n",
      "Epoch 20/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1749927.9988 - val_loss: 1683872.0000\n",
      "Epoch 21/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1706103.2299 - val_loss: 1668327.5000\n",
      "Epoch 22/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1709432.5720 - val_loss: 1854242.0000\n",
      "Epoch 23/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1704179.9285 - val_loss: 1646782.3750\n",
      "Epoch 24/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1703530.0485 - val_loss: 1655589.6250\n",
      "Epoch 25/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1680997.1070 - val_loss: 1702068.6250\n",
      "Epoch 26/100\n",
      "1835/1835 [==============================] - 3s 1ms/step - loss: 1706400.0284 - val_loss: 1665694.8750\n",
      "918/918 [==============================] - 1s 786us/step - loss: 1683970.2500\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 28, LR: 0.0001\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 21038445.3382 - val_loss: 6754147.5000\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 4037999.4070 - val_loss: 2034501.3750\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1973125.7168 - val_loss: 1909755.1250\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 5s 3ms/step - loss: 1931482.3690 - val_loss: 1911619.1250\n",
      "Epoch 5/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1926882.4511 - val_loss: 1854672.6250\n",
      "Epoch 6/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1861351.6550 - val_loss: 1905415.5000\n",
      "Epoch 7/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1833316.1721 - val_loss: 1836185.8750\n",
      "Epoch 8/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1834209.1044 - val_loss: 1865926.8750\n",
      "Epoch 9/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1807421.3618 - val_loss: 1804826.8750\n",
      "Epoch 10/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1845275.7267 - val_loss: 1803872.1250\n",
      "Epoch 11/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1839916.3107 - val_loss: 1824115.6250\n",
      "Epoch 12/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1777078.9064 - val_loss: 1782288.3750\n",
      "Epoch 13/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1798011.9649 - val_loss: 1783387.2500\n",
      "Epoch 14/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1786476.2678 - val_loss: 1770635.3750\n",
      "Epoch 15/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1759834.2486 - val_loss: 1782838.6250\n",
      "Epoch 16/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1756795.9316 - val_loss: 1840900.6250\n",
      "Epoch 17/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1801473.0530 - val_loss: 1751060.8750\n",
      "Epoch 18/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1770743.8748 - val_loss: 1746488.7500\n",
      "Epoch 19/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1743814.1182 - val_loss: 1741743.5000\n",
      "Epoch 20/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1718529.3456 - val_loss: 1745939.5000\n",
      "Epoch 21/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1743118.1915 - val_loss: 1748131.6250\n",
      "Epoch 22/100\n",
      "1835/1835 [==============================] - 6s 4ms/step - loss: 1774879.3750 - val_loss: 1737059.6250\n",
      "Epoch 23/100\n",
      "1835/1835 [==============================] - 5s 3ms/step - loss: 1716382.2071 - val_loss: 1822772.1250\n",
      "Epoch 24/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1728846.5571 - val_loss: 1701565.6250\n",
      "Epoch 25/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1745076.6126 - val_loss: 1713116.7500\n",
      "Epoch 26/100\n",
      "1835/1835 [==============================] - 5s 3ms/step - loss: 1707706.9424 - val_loss: 1692141.3750\n",
      "Epoch 27/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1724125.9323 - val_loss: 1672422.1250\n",
      "Epoch 28/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1716288.5246 - val_loss: 1676933.1250\n",
      "Epoch 29/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1717194.8327 - val_loss: 1683999.7500\n",
      "Epoch 30/100\n",
      "1835/1835 [==============================] - 3s 2ms/step - loss: 1693090.8949 - val_loss: 1685804.5000\n",
      "918/918 [==============================] - 1s 965us/step - loss: 1737573.0000\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 70, LR: 0.001\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 6s 3ms/step - loss: 3853886.5535 - val_loss: 2361565.2500\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 2166067.6499 - val_loss: 1934191.8750\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 2030298.5525 - val_loss: 2391211.2500\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1975051.8152 - val_loss: 2032884.2500\n",
      "Epoch 5/100\n",
      "1835/1835 [==============================] - 5s 3ms/step - loss: 1876087.6171 - val_loss: 1866429.3750\n",
      "Epoch 6/100\n",
      "1835/1835 [==============================] - 8s 4ms/step - loss: 1792113.3868 - val_loss: 4469395.0000\n",
      "Epoch 7/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1816787.8310 - val_loss: 1685842.2500\n",
      "Epoch 8/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1698649.7407 - val_loss: 1507635.1250\n",
      "Epoch 9/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1649929.7547 - val_loss: 1841062.0000\n",
      "Epoch 10/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1603223.2157 - val_loss: 2341316.5000\n",
      "Epoch 11/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1619356.5895 - val_loss: 1916216.0000\n",
      "918/918 [==============================] - 1s 1ms/step - loss: 1991989.0000\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 70, LR: 0.001\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 5s 2ms/step - loss: 3875913.4261 - val_loss: 6851815.5000\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 2148706.4021 - val_loss: 4614153.5000\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 6s 3ms/step - loss: 2042624.9416 - val_loss: 2284876.5000\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 5s 3ms/step - loss: 1948196.4618 - val_loss: 1824865.6250\n",
      "Epoch 5/100\n",
      "1835/1835 [==============================] - 5s 3ms/step - loss: 1890601.3209 - val_loss: 1878002.3750\n",
      "Epoch 6/100\n",
      "1835/1835 [==============================] - 5s 3ms/step - loss: 1848819.7168 - val_loss: 2248451.7500\n",
      "Epoch 7/100\n",
      "1835/1835 [==============================] - 7s 4ms/step - loss: 1804087.4200 - val_loss: 2321160.2500\n",
      "918/918 [==============================] - 1s 1ms/step - loss: 2332165.7500\n",
      "Building Model ...\n",
      "Hidden Layers: 12, Neurons: 70, LR: 0.001\n",
      "Epoch 1/100\n",
      "1835/1835 [==============================] - 7s 3ms/step - loss: 3971336.0417 - val_loss: 3171734.5000\n",
      "Epoch 2/100\n",
      "1835/1835 [==============================] - 5s 2ms/step - loss: 2154372.5430 - val_loss: 2920583.2500\n",
      "Epoch 3/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 2021633.7654 - val_loss: 3640660.7500\n",
      "Epoch 4/100\n",
      "1835/1835 [==============================] - 6s 3ms/step - loss: 1938465.3214 - val_loss: 2241269.5000\n",
      "Epoch 5/100\n",
      "1835/1835 [==============================] - 5s 3ms/step - loss: 1868151.4467 - val_loss: 1754497.8750\n",
      "Epoch 6/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1811653.2975 - val_loss: 2871877.2500\n",
      "Epoch 7/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1778568.2446 - val_loss: 3354747.5000\n",
      "Epoch 8/100\n",
      "1835/1835 [==============================] - 4s 2ms/step - loss: 1709440.9406 - val_loss: 3939728.2500\n",
      "918/918 [==============================] - 1s 966us/step - loss: 4072039.7500\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000001F5E3C4FFD0>, as the constructor either does not set or modifies parameter n_neurons",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-00a467062745>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m# Train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mrnd_search_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcheckpoint_cb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearlystop_cb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensorboard_cb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Developer\\Python\\Python366\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m             \u001b[1;31m# of the params are estimators as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[1;32m--> 736\u001b[1;33m                 **self.best_params_))\n\u001b[0m\u001b[0;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Developer\\Python\\Python366\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     80\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0;32m     81\u001b[0m                                \u001b[1;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m                                (estimator, name))\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000001F5E3C4FFD0>, as the constructor either does not set or modifies parameter n_neurons"
     ]
    }
   ],
   "source": [
    "# Optimised MLP (Target - DC Power)\n",
    "\n",
    "if TRAIN_MODELS == True:\n",
    "    # Clear existing models\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Establish parameter distribution for tuning\n",
    "    param_distribs = {\n",
    "        \"n_hidden\":[12],\n",
    "        \"n_neurons\": np.arange(1, 100),\n",
    "        \"learning_rate\": [1e-1, 1e-2, 1e-3, 1e-4],\n",
    "    }\n",
    "\n",
    "    # Build model\n",
    "    wrapped_model = keras_helpers.wrap_model()\n",
    "\n",
    "    # Initialise random search\n",
    "    rnd_search_cv = RandomizedSearchCV(wrapped_model, param_distribs, n_iter = 10, cv = 3)\n",
    "\n",
    "    # Name model\n",
    "    model_type = \"MLP_Opt_DC\"\n",
    "    model_id = keras_helpers.name_model(model_type)\n",
    "    filepath_full = keras_helpers.make_save_string(model_id)\n",
    "\n",
    "    # Set save and earlystop callbacks\n",
    "    earlystop_cb = keras.callbacks.EarlyStopping(patience = 3)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = filepath_full, save_best_only = True)\n",
    "\n",
    "    # Set TensorBoard callback for logging\n",
    "    tb_logdir = tensorboard_helpers.get_run_logdir()\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(tb_logdir)\n",
    "\n",
    "    # Train model\n",
    "    rnd_search_cv.fit(X_train, y_train, epochs = 100, validation_data =(X_test, y_test), callbacks = [checkpoint_cb, earlystop_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_169 (Dense)            (None, 40)                280       \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 8,521\n",
      "Trainable params: 8,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "MLP_Opt_DC rmse (Eval): 1155.8620532143577\n",
      "MLP_Opt_DC mae (Eval): 545.58045225204\n",
      "MLP_Opt_DC r2 (Eval): 0.9181278609504048\n",
      "MLP_Opt_DC % Acc: 91.10875343681263\n"
     ]
    }
   ],
   "source": [
    "# Evaluate MLP Model\n",
    "\n",
    "if TRAIN_MODELS == False:\n",
    "    filepath_full = r'C:\\Developer\\solar-power-generation-project\\Models\\WJ_MLP_Opt_DC_2021_01_13-15_30_27.h5'\n",
    "\n",
    "wrapped_model = keras.models.load_model(filepath_full)\n",
    "\n",
    "# Summarise model\n",
    "wrapped_model.summary()\n",
    "\n",
    "# Make predictions\n",
    "dc_pred_eval = wrapped_model.predict(dc_evaluation_data)\n",
    "\n",
    "model_name = \"MLP_Opt_DC\"\n",
    "model_evaluation.evaluate_model(model_name, dc_eval_label_data, dc_pred_eval)\n",
    "\n",
    "# Calculate indicative accuracy\n",
    "rmse, mae, r2 = model_evaluation.return_model_evaluation_stats(dc_eval_label_data, dc_pred_eval)\n",
    "\n",
    "print(model_name, \"% Acc:\", ((1-(rmse/DC_Power_Range))*100))"
   ]
  }
 ]
}