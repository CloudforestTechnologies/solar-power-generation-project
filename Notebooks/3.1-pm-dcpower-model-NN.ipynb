{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "keras version = 2.4.0\nnumpy version = 1.19.4\nsklearn version = 0.22.2.post1\ntensorflow version = 2.4.1\n"
     ]
    }
   ],
   "source": [
    "# Module Importations\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "\n",
    "# Print versioning information\n",
    "print('keras version =', keras.__version__)\n",
    "print('numpy version =', np.__version__)  \n",
    "print('sklearn version =', sklearn.__version__)\n",
    "print('tensorflow version =', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[keras_helpers]Tensorflow version: 2.4.1\n[keras_helpers]keras version = 2.4.0\n"
     ]
    }
   ],
   "source": [
    "# Custom Module Imports\n",
    "from Source.data import load_data\n",
    "from Source.data import split_data\n",
    "from Source.models import model_evaluation\n",
    "from Source.models import keras_helpers\n",
    "from Source.models import tensorboard_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DC_Power_Range = 13000\n",
    "TRAIN_MODELS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading pickled dataframe started ...\n",
      "Loading pickled dataframe complete ...\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "original_dataset_df = load_data.load_pickled_data('full_data_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 DATE_TIME  PLANT_ID       SOURCE_KEY  DC_POWER  AC_POWER  \\\n0      2020-05-15 00:00:00   4135001  1BY6WEcLGh8j5v7       0.0       0.0   \n1      2020-05-15 00:00:00   4135001  1IF53ai7Xc0U56Y       0.0       0.0   \n2      2020-05-15 00:00:00   4135001  3PZuoBAID5Wc2HD       0.0       0.0   \n3      2020-05-15 00:00:00   4135001  7JYdWkrLSPkdwr4       0.0       0.0   \n4      2020-05-15 00:00:00   4135001  McdE0feGgRqW7Ca       0.0       0.0   \n...                    ...       ...              ...       ...       ...   \n137551 2020-06-17 23:45:00   4135001  uHbuxQJl8lW7ozc       0.0       0.0   \n137552 2020-06-17 23:45:00   4135001  wCURE6d3bPkepu2       0.0       0.0   \n137553 2020-06-17 23:45:00   4135001  z9Y9gH1T5YWrNuG       0.0       0.0   \n137554 2020-06-17 23:45:00   4135001  zBIq5rxdHJRwDNY       0.0       0.0   \n137555 2020-06-17 23:45:00   4135001  zVJPv84UY57bAof       0.0       0.0   \n\n        DAILY_YIELD  TOTAL_YIELD CELL_NO  TIME_OF_DAY   AMB_TEMP   MOD_TEMP  \\\n0             0.000    6259559.0      01     0.000000  25.184316  22.857507   \n1             0.000    6183645.0      02     0.000000  25.184316  22.857507   \n2             0.000    6987759.0      03     0.000000  25.184316  22.857507   \n3             0.000    7602960.0      03     0.000000  25.184316  22.857507   \n4             0.000    7158964.0      05     0.000000  25.184316  22.857507   \n...             ...          ...     ...          ...        ...        ...   \n137551     5967.000    7287002.0      17     0.989583  23.202871  22.535908   \n137552     5147.625    7028601.0      18     0.989583  23.202871  22.535908   \n137553     5819.000    7251204.0      19     0.989583  23.202871  22.535908   \n137554     5817.000    6583369.0      20     0.989583  23.202871  22.535908   \n137555     5910.000    7363272.0      21     0.989583  23.202871  22.535908   \n\n        IRRADIATION   PLANT  \n0               0.0  plant1  \n1               0.0  plant1  \n2               0.0  plant1  \n3               0.0  plant1  \n4               0.0  plant1  \n...             ...     ...  \n137551          0.0  plant2  \n137552          0.0  plant2  \n137553          0.0  plant2  \n137554          0.0  plant2  \n137555          0.0  plant2  \n\n[137556 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Data Munging - Convert time of day to float\n",
    "\n",
    "def convert_time_to_float(time):\n",
    "    return time.hour / 24.0 + time.minute / (24.0*60.0) + time.second / (24.0*60.0*60.0) + time.microsecond / (24.0*60.0*60.0*1000000.0)\n",
    "\n",
    "original_dataset_df['TIME_OF_DAY'] = original_dataset_df.apply(lambda row: convert_time_to_float(row['DATE_TIME']), axis = 1)\n",
    "\n",
    "print(original_dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 137556 entries, 0 to 137555\nData columns (total 13 columns):\n #   Column       Non-Null Count   Dtype         \n---  ------       --------------   -----         \n 0   DATE_TIME    137556 non-null  datetime64[ns]\n 1   PLANT_ID     137556 non-null  int64         \n 2   SOURCE_KEY   137556 non-null  object        \n 3   DC_POWER     137556 non-null  float64       \n 4   AC_POWER     137556 non-null  float64       \n 5   DAILY_YIELD  137556 non-null  float64       \n 6   TOTAL_YIELD  137556 non-null  float64       \n 7   CELL_NO      137556 non-null  object        \n 8   TIME_OF_DAY  137556 non-null  float64       \n 9   AMB_TEMP     137556 non-null  float64       \n 10  MOD_TEMP     137556 non-null  float64       \n 11  IRRADIATION  137556 non-null  float64       \n 12  PLANT        137556 non-null  int64         \ndtypes: datetime64[ns](1), float64(8), int64(2), object(2)\nmemory usage: 13.6+ MB\nNone\n"
     ]
    }
   ],
   "source": [
    "# Data Munging - Convert plant to int\n",
    "\n",
    "def convert_plant_to_int(plant):\n",
    "    \n",
    "    if plant == \"plant1\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 2    \n",
    "\n",
    "original_dataset_df['PLANT'] = original_dataset_df.apply(lambda row: convert_plant_to_int(row['PLANT']), axis = 1)\n",
    "\n",
    "print(original_dataset_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 137556 entries, 0 to 137555\nData columns (total 13 columns):\n #   Column       Non-Null Count   Dtype         \n---  ------       --------------   -----         \n 0   DATE_TIME    137556 non-null  datetime64[ns]\n 1   PLANT_ID     137556 non-null  int64         \n 2   SOURCE_KEY   137556 non-null  object        \n 3   DC_POWER     137556 non-null  float64       \n 4   AC_POWER     137556 non-null  float64       \n 5   DAILY_YIELD  137556 non-null  float64       \n 6   TOTAL_YIELD  137556 non-null  float64       \n 7   CELL_NO      137556 non-null  int64         \n 8   TIME_OF_DAY  137556 non-null  float64       \n 9   AMB_TEMP     137556 non-null  float64       \n 10  MOD_TEMP     137556 non-null  float64       \n 11  IRRADIATION  137556 non-null  float64       \n 12  PLANT        137556 non-null  int64         \ndtypes: datetime64[ns](1), float64(8), int64(3), object(1)\nmemory usage: 13.6+ MB\nNone\n"
     ]
    }
   ],
   "source": [
    "# Data Munging - Convert cell to int\n",
    "\n",
    "def convert_cellno_to_int(cell_no):\n",
    "    \n",
    "    cell_no = int(cell_no)\n",
    "    return cell_no\n",
    "\n",
    "original_dataset_df['CELL_NO'] = original_dataset_df.apply(lambda row: convert_cellno_to_int(row['CELL_NO']), axis = 1)\n",
    "\n",
    "print(original_dataset_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original Data Items: 137556\nTraining Data Items: 110045\nEvaluation Data Items: 27511\n"
     ]
    }
   ],
   "source": [
    "# Split into training / evaluation sets\n",
    "training_set, evaluation_set = split_data.split_train_eval(original_dataset_df, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "           DC_POWER  CELL_NO  TIME_OF_DAY   AMB_TEMP   MOD_TEMP  IRRADIATION  \\\n23464      0.000000        5     0.041667  23.478941  22.007802     0.000000   \n82416      0.000000       12     0.229167  23.216699  21.191993     0.000000   \n131200     0.000000        3     0.968750  24.652915  23.913763     0.000000   \n120917     0.000000       15     0.093750  24.696277  23.876865     0.000000   \n98459   3486.857143       17     0.364583  25.788373  28.674120     0.215449   \n\n        PLANT  \n23464       1  \n82416       2  \n131200      2  \n120917      2  \n98459       2  \n"
     ]
    }
   ],
   "source": [
    "# Drop unrequired data columns\n",
    "\n",
    "# Identify columns to drop \n",
    "columns_to_drop = ['DATE_TIME', 'PLANT_ID', 'SOURCE_KEY', 'AC_POWER', 'DAILY_YIELD', 'TOTAL_YIELD']\n",
    "\n",
    "training_set = training_set.drop(columns_to_drop, axis = 1)\n",
    "evaluation_set = evaluation_set.drop(columns_to_drop, axis = 1)\n",
    "\n",
    "print(evaluation_set.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 110045 entries, 99361 to 121958\nData columns (total 6 columns):\n #   Column       Non-Null Count   Dtype  \n---  ------       --------------   -----  \n 0   CELL_NO      110045 non-null  int64  \n 1   TIME_OF_DAY  110045 non-null  float64\n 2   AMB_TEMP     110045 non-null  float64\n 3   MOD_TEMP     110045 non-null  float64\n 4   IRRADIATION  110045 non-null  float64\n 5   PLANT        110045 non-null  int64  \ndtypes: float64(4), int64(2)\nmemory usage: 5.9 MB\nNone\n99361        0.000000\n113108    3576.750000\n53656        0.000000\n46387     9456.625000\n116927       0.000000\n             ...     \n110268       0.000000\n119879    7230.250000\n103694       0.000000\n131932    1900.857143\n121958    7665.750000\nName: DC_POWER, Length: 110045, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create DC Power Target datasets\n",
    "\n",
    "# Modify training set\n",
    "dc_power_training_data = training_set.drop('DC_POWER', axis = 1)\n",
    "dc_label_data = training_set['DC_POWER'].copy()\n",
    "\n",
    "print(dc_power_training_data.info())\n",
    "print(dc_label_data)\n",
    "\n",
    "# Modify evaluation set\n",
    "dc_evaluation_data = evaluation_set.drop('DC_POWER', axis = 1)\n",
    "dc_eval_label_data = evaluation_set['DC_POWER'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "        CELL_NO  TIME_OF_DAY   AMB_TEMP   MOD_TEMP  IRRADIATION  PLANT\n26727         6     0.614583  32.965332  46.834515     0.537781      1\n131564       14     0.135417  24.157297  23.330549     0.000000      2\n39111        13     0.854167  23.664010  21.192350     0.000000      1\n85370        14     0.729167  37.208696  39.745883     0.128514      2\n52462         8     0.250000  21.767090  19.326091     0.009079      1\n...         ...          ...        ...        ...          ...    ...\n129940       18     0.364583  27.568193  35.298639     0.336816      2\n49470         8     0.833333  24.800704  21.858350     0.000000      1\n44627        11     0.510417  29.854372  53.016915     0.688047      1\n90334        14     0.114583  25.172858  24.225251     0.000000      2\n115964       12     0.750000  31.154428  31.562370     0.068103      2\n\n[88036 rows x 6 columns]\n26727     8246.714286\n131564       0.000000\n39111        0.000000\n85370     2074.500000\n52462      102.285714\n             ...     \n129940    5305.000000\n49470        0.000000\n44627     8769.250000\n90334        0.000000\n115964     665.571429\nName: DC_POWER, Length: 88036, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create train and test arrays\n",
    "X_train, X_test, y_train, y_test = train_test_split(dc_power_training_data, dc_label_data, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial MLP (Target - DC Power)\n",
    "\n",
    "if TRAIN_MODELS == True:\n",
    "    # Clear existing models\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Build model\n",
    "    model = keras_helpers.build_multilayer_perceptron()\n",
    "\n",
    "    # Name model\n",
    "    model_type = \"MLP_DC\"\n",
    "    model_id = keras_helpers.name_model(model_type)\n",
    "    filepath_full = keras_helpers.make_save_string(model_id)\n",
    "\n",
    "    # Set save and earlystop callbacks\n",
    "    earlystop_cb = keras.callbacks.EarlyStopping(patience = 5)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = filepath_full, save_best_only = True)\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train, epochs = 5, validation_data =(X_test, y_test), callbacks =[checkpoint_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "MLP_DC rmse (Eval): 1215.4424267902286\n",
      "MLP_DC mae (Eval): 607.01389375947\n",
      "MLP_DC r2 (Eval): 0.9094699190186624\n",
      "MLP_DC % Acc: 90.6504428708444\n"
     ]
    }
   ],
   "source": [
    "# Evaluate MLP Model\n",
    "\n",
    "if TRAIN_MODELS == False:\n",
    "    filepath_full = r'C:\\Developer\\solar-power-generation-project\\Models\\WJ_MLP_DC_2021_01_13-16_10_50.h5'\n",
    "\n",
    "# Load model\n",
    "model = keras.models.load_model(filepath_full)\n",
    "\n",
    "# Summarise model\n",
    "model.summary()\n",
    "\n",
    "# Make predictions\n",
    "dc_pred_eval = model.predict(dc_evaluation_data)\n",
    "\n",
    "# Determine model prediction stats\n",
    "model_name = \"MLP_DC\"\n",
    "model_evaluation.evaluate_model(model_name, dc_eval_label_data, dc_pred_eval)\n",
    "\n",
    "# Calculate indicative accuracy\n",
    "rmse, mae, r2 = model_evaluation.return_model_evaluation_stats(dc_eval_label_data, dc_pred_eval)\n",
    "\n",
    "print(model_name, \"% Acc:\", ((1-(rmse/DC_Power_Range))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimised MLP (Target - DC Power)\n",
    "\n",
    "if TRAIN_MODELS == True:\n",
    "    # Clear existing models\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Establish parameter distribution for tuning\n",
    "    param_distribs = {\n",
    "        \"n_hidden\":[12],\n",
    "        \"n_neurons\": np.arange(1, 100),\n",
    "        \"learning_rate\": [1e-1, 1e-2, 1e-3, 1e-4],\n",
    "    }\n",
    "\n",
    "    # Build model\n",
    "    wrapped_model = keras_helpers.wrap_model()\n",
    "\n",
    "    # Initialise random search\n",
    "    rnd_search_cv = RandomizedSearchCV(wrapped_model, param_distribs, n_iter = 10, cv = 3)\n",
    "\n",
    "    # Name model\n",
    "    model_type = \"MLP_Opt_DC\"\n",
    "    model_id = keras_helpers.name_model(model_type)\n",
    "    filepath_full = keras_helpers.make_save_string(model_id)\n",
    "\n",
    "    # Set save and earlystop callbacks\n",
    "    earlystop_cb = keras.callbacks.EarlyStopping(patience = 3)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = filepath_full, save_best_only = True)\n",
    "\n",
    "    # Train model\n",
    "    rnd_search_cv.fit(X_train, y_train, epochs = 5, validation_data =(X_test, y_test), callbacks = [checkpoint_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_169 (Dense)            (None, 40)                280       \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 8,521\n",
      "Trainable params: 8,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "MLP_Opt_DC rmse (Eval): 1155.8620532143577\n",
      "MLP_Opt_DC mae (Eval): 545.58045225204\n",
      "MLP_Opt_DC r2 (Eval): 0.9181278609504048\n",
      "MLP_Opt_DC % Acc: 91.10875343681263\n"
     ]
    }
   ],
   "source": [
    "# Evaluate MLP Model\n",
    "\n",
    "if TRAIN_MODELS == False:\n",
    "    filepath_full = r'C:\\Developer\\solar-power-generation-project\\Models\\WJ_MLP_Opt_DC_2021_01_13-15_30_27.h5'\n",
    "\n",
    "wrapped_model = keras.models.load_model(filepath_full)\n",
    "\n",
    "# Summarise model\n",
    "wrapped_model.summary()\n",
    "\n",
    "# Make predictions\n",
    "dc_pred_eval = wrapped_model.predict(dc_evaluation_data)\n",
    "\n",
    "model_name = \"MLP_Opt_DC\"\n",
    "model_evaluation.evaluate_model(model_name, dc_eval_label_data, dc_pred_eval)\n",
    "\n",
    "# Calculate indicative accuracy\n",
    "rmse, mae, r2 = model_evaluation.return_model_evaluation_stats(dc_eval_label_data, dc_pred_eval)\n",
    "\n",
    "print(model_name, \"% Acc:\", ((1-(rmse/DC_Power_Range))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "c:\\Developer\\solar-power-generation-project\\Models\\TensorBoard\\run_2021_01_28-11_06_42\n"
     ]
    }
   ],
   "source": [
    "x = tensorboard_helpers.get_run_logdir()\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Building Model ...\n",
      "Hidden Layers: 2, Neurons: 6, LR: 0.001\n",
      "Epoch 1/5\n",
      "2752/2752 [==============================] - 4s 1ms/step - loss: 21568956.0966 - val_loss: 9851056.0000\n",
      "Epoch 2/5\n",
      "2752/2752 [==============================] - 3s 1ms/step - loss: 8754954.1413 - val_loss: 4624588.0000\n",
      "Epoch 3/5\n",
      "2752/2752 [==============================] - 3s 1ms/step - loss: 3615459.2020 - val_loss: 2195660.2500\n",
      "Epoch 4/5\n",
      "2752/2752 [==============================] - 3s 1ms/step - loss: 2171510.4092 - val_loss: 2025501.5000\n",
      "Epoch 5/5\n",
      "2752/2752 [==============================] - 5s 2ms/step - loss: 2033481.4206 - val_loss: 1939051.3750\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x163b018c1d0>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# Clear existing models\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Build model\n",
    "model = keras_helpers.build_multilayer_perceptron()\n",
    "\n",
    "# Name model\n",
    "model_type = \"MLP_DC\"\n",
    "model_id = keras_helpers.name_model(model_type)\n",
    "filepath_full = keras_helpers.make_save_string(model_id)\n",
    "\n",
    "# Set save and earlystop callbacks\n",
    "earlystop_cb = keras.callbacks.EarlyStopping(patience = 5)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = filepath_full, save_best_only = True)\n",
    "\n",
    "# Set TensorBoard callback for logging\n",
    "tb_logdir = tensorboard_helpers.get_run_logdir()\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(tb_logdir)\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs = 5, validation_data =(X_test, y_test), callbacks =[checkpoint_cb, earlystop_cb, tensorboard_cb])"
   ]
  }
 ]
}